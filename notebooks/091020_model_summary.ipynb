{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmikyu import gan, config, model\n",
    "from cosmikyu import nn as cnn\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import mlflow\n",
    "import torchsummary\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You have a CUDA device. You probably want to run with CUDA enabled\n",
      "====dcganwgp======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3          [-1, 128, 32, 32]         131,200\n",
      "         LeakyReLU-4          [-1, 128, 32, 32]               0\n",
      "            Conv2d-5          [-1, 256, 16, 16]         524,544\n",
      "         LeakyReLU-6          [-1, 256, 16, 16]               0\n",
      "            Conv2d-7            [-1, 512, 8, 8]       2,097,664\n",
      "         LeakyReLU-8            [-1, 512, 8, 8]               0\n",
      "            Conv2d-9           [-1, 1024, 4, 4]       8,389,632\n",
      "        LeakyReLU-10           [-1, 1024, 4, 4]               0\n",
      "          Reshape-11                [-1, 16384]               0\n",
      "           Linear-12                    [-1, 1]          16,385\n",
      "================================================================\n",
      "Total params: 11,164,609\n",
      "Trainable params: 11,164,609\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 7.88\n",
      "Params size (MB): 42.59\n",
      "Estimated Total Size (MB): 50.78\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 16384]       4,210,688\n",
      "           Reshape-2           [-1, 1024, 4, 4]               0\n",
      "       BatchNorm2d-3           [-1, 1024, 4, 4]           2,048\n",
      "         LeakyReLU-4           [-1, 1024, 4, 4]               0\n",
      "   ConvTranspose2d-5            [-1, 512, 8, 8]       8,389,120\n",
      "       BatchNorm2d-6            [-1, 512, 8, 8]           1,024\n",
      "         LeakyReLU-7            [-1, 512, 8, 8]               0\n",
      "   ConvTranspose2d-8          [-1, 256, 16, 16]       2,097,408\n",
      "       BatchNorm2d-9          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-10          [-1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-11          [-1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-13          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-14           [-1, 64, 64, 64]         131,136\n",
      "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
      "        LeakyReLU-16           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-17          [-1, 5, 128, 128]           5,125\n",
      "       ScaledTanh-18          [-1, 5, 128, 128]               0\n",
      "    LinearFeature-19          [-1, 5, 128, 128]              10\n",
      "================================================================\n",
      "Total params: 15,361,871\n",
      "Trainable params: 15,361,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 13.62\n",
      "Params size (MB): 58.60\n",
      "Estimated Total Size (MB): 72.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "LF = cnn.LinearFeature(5,5)\n",
    "latent_dim = 256\n",
    "shape = (5,128,128)\n",
    "\n",
    "DCGAN_WGP = gan.DCGAN_WGP(\"sehgal_dcganwgp\", shape, latent_dim, cuda=False, nconv_fcgen=64,\n",
    "                              nconv_fcdis=64, ngpu=4, nconv_layer_gen=5, nconv_layer_disc=5, kernal_size=4, stride=2,\n",
    "                                                        padding=1, output_padding=0, gen_act=[STanh, LF])\n",
    "\n",
    "print(\"====dcganwgp======\")\n",
    "torchsummary.summary(DCGAN_WGP.discriminator, shape, device=\"cpu\")\n",
    "torchsummary.summary(DCGAN_WGP.generator, (latent_dim,), device=\"cpu\")\n",
    "del DCGAN_WGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You have a CUDA device. You probably want to run with CUDA enabled\n",
      "====pixgan======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "            Conv2d-3           [1, 128, 32, 32]         131,200\n",
      "         LeakyReLU-4           [1, 128, 32, 32]               0\n",
      "            Conv2d-5           [1, 256, 16, 16]         524,544\n",
      "         LeakyReLU-6           [1, 256, 16, 16]               0\n",
      "            Conv2d-7             [1, 512, 8, 8]       2,097,664\n",
      "         LeakyReLU-8             [1, 512, 8, 8]               0\n",
      "            Conv2d-9            [1, 1024, 4, 4]       8,389,632\n",
      "        LeakyReLU-10            [1, 1024, 4, 4]               0\n",
      "          Reshape-11                 [1, 16384]               0\n",
      "           Linear-12                     [1, 1]          16,385\n",
      "================================================================\n",
      "Total params: 11,164,609\n",
      "Trainable params: 11,164,609\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 7.88\n",
      "Params size (MB): 42.59\n",
      "Estimated Total Size (MB): 50.78\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           1,088\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "          UNetDown-3            [1, 64, 64, 64]               0\n",
      "            Conv2d-4           [1, 128, 32, 32]         131,200\n",
      "       BatchNorm2d-5           [1, 128, 32, 32]             256\n",
      "         LeakyReLU-6           [1, 128, 32, 32]               0\n",
      "          UNetDown-7           [1, 128, 32, 32]               0\n",
      "            Conv2d-8           [1, 256, 16, 16]         524,544\n",
      "       BatchNorm2d-9           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-10           [1, 256, 16, 16]               0\n",
      "         UNetDown-11           [1, 256, 16, 16]               0\n",
      "           Conv2d-12             [1, 512, 8, 8]       2,097,664\n",
      "      BatchNorm2d-13             [1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-14             [1, 512, 8, 8]               0\n",
      "         UNetDown-15             [1, 512, 8, 8]               0\n",
      "           Conv2d-16             [1, 512, 4, 4]       4,194,816\n",
      "      BatchNorm2d-17             [1, 512, 4, 4]           1,024\n",
      "        LeakyReLU-18             [1, 512, 4, 4]               0\n",
      "         UNetDown-19             [1, 512, 4, 4]               0\n",
      "           Conv2d-20             [1, 512, 2, 2]       4,194,816\n",
      "      BatchNorm2d-21             [1, 512, 2, 2]           1,024\n",
      "        LeakyReLU-22             [1, 512, 2, 2]               0\n",
      "         UNetDown-23             [1, 512, 2, 2]               0\n",
      "           Conv2d-24             [1, 512, 1, 1]       4,194,816\n",
      "             ReLU-25             [1, 512, 1, 1]               0\n",
      "         UNetDown-26             [1, 512, 1, 1]               0\n",
      "  ConvTranspose2d-27             [1, 512, 2, 2]       4,194,816\n",
      "      BatchNorm2d-28             [1, 512, 2, 2]           1,024\n",
      "             ReLU-29             [1, 512, 2, 2]               0\n",
      "           UNetUP-30            [1, 1024, 2, 2]               0\n",
      "  ConvTranspose2d-31             [1, 512, 4, 4]       8,389,120\n",
      "      BatchNorm2d-32             [1, 512, 4, 4]           1,024\n",
      "             ReLU-33             [1, 512, 4, 4]               0\n",
      "           UNetUP-34            [1, 1024, 4, 4]               0\n",
      "  ConvTranspose2d-35             [1, 512, 8, 8]       8,389,120\n",
      "      BatchNorm2d-36             [1, 512, 8, 8]           1,024\n",
      "             ReLU-37             [1, 512, 8, 8]               0\n",
      "           UNetUP-38            [1, 1024, 8, 8]               0\n",
      "  ConvTranspose2d-39           [1, 256, 16, 16]       4,194,560\n",
      "      BatchNorm2d-40           [1, 256, 16, 16]             512\n",
      "             ReLU-41           [1, 256, 16, 16]               0\n",
      "           UNetUP-42           [1, 512, 16, 16]               0\n",
      "  ConvTranspose2d-43           [1, 128, 32, 32]       1,048,704\n",
      "      BatchNorm2d-44           [1, 128, 32, 32]             256\n",
      "             ReLU-45           [1, 128, 32, 32]               0\n",
      "           UNetUP-46           [1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-47            [1, 64, 64, 64]         262,208\n",
      "      BatchNorm2d-48            [1, 64, 64, 64]             128\n",
      "             ReLU-49            [1, 64, 64, 64]               0\n",
      "           UNetUP-50           [1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-51           [1, 4, 128, 128]           8,196\n",
      "           UNetUP-52           [1, 4, 128, 128]               0\n",
      "    LinearFeature-53           [1, 4, 128, 128]               8\n",
      "       ScaledTanh-54           [1, 4, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 41,833,484\n",
      "Trainable params: 41,833,484\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 34.46\n",
      "Params size (MB): 159.58\n",
      "Estimated Total Size (MB): 194.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "LF = cnn.LinearFeature(4,4, bias=True)\n",
    "shape = (5,128,128)\n",
    "PIXGAN = gan.PIXGAN_WGP(\"sehgal_pixgan_251020\", shape, nconv_fcgen=64,\n",
    "                          nconv_fcdis=64, cuda=False, ngpu=4, nconv_layer_gen=4, nconv_layer_disc=5, kernal_size=4, stride=2,\n",
    "                          padding=1, output_padding=0, gen_act=[LF,STanh], nin_channel=1, nout_channel=4, nthresh_layer_gen=3, nthresh_layer_disc=0, dropout_rate=0)\n",
    "\n",
    "print(\"====pixgan======\")\n",
    "torchsummary.summary(PIXGAN.discriminator, shape, batch_size=1, device=\"cpu\")\n",
    "torchsummary.summary(PIXGAN.generator, (1,)+shape[-2:], batch_size=1, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You have a CUDA device. You probably want to run with CUDA enabled\n",
      "====forse======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "            Conv2d-3           [1, 128, 32, 32]         131,200\n",
      "       BatchNorm2d-4           [1, 128, 32, 32]             256\n",
      "         LeakyReLU-5           [1, 128, 32, 32]               0\n",
      "            Conv2d-6           [1, 256, 16, 16]         524,544\n",
      "       BatchNorm2d-7           [1, 256, 16, 16]             512\n",
      "         LeakyReLU-8           [1, 256, 16, 16]               0\n",
      "            Conv2d-9           [1, 512, 15, 15]       2,097,664\n",
      "      BatchNorm2d-10           [1, 512, 15, 15]           1,024\n",
      "        LeakyReLU-11           [1, 512, 15, 15]               0\n",
      "           Conv2d-12             [1, 1, 14, 14]           8,193\n",
      "          Sigmoid-13             [1, 1, 14, 14]               0\n",
      "================================================================\n",
      "Total params: 2,768,577\n",
      "Trainable params: 2,768,577\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 11.14\n",
      "Params size (MB): 10.56\n",
      "Estimated Total Size (MB): 22.01\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "          UNetDown-3            [1, 64, 64, 64]               0\n",
      "            Conv2d-4           [1, 128, 32, 32]         131,200\n",
      "       BatchNorm2d-5           [1, 128, 32, 32]             256\n",
      "         LeakyReLU-6           [1, 128, 32, 32]               0\n",
      "          UNetDown-7           [1, 128, 32, 32]               0\n",
      "            Conv2d-8           [1, 256, 16, 16]         524,544\n",
      "       BatchNorm2d-9           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-10           [1, 256, 16, 16]               0\n",
      "         UNetDown-11           [1, 256, 16, 16]               0\n",
      "           Conv2d-12             [1, 512, 8, 8]       2,097,664\n",
      "      BatchNorm2d-13             [1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-14             [1, 512, 8, 8]               0\n",
      "         UNetDown-15             [1, 512, 8, 8]               0\n",
      "           Conv2d-16            [1, 1024, 4, 4]       8,389,632\n",
      "      BatchNorm2d-17            [1, 1024, 4, 4]           2,048\n",
      "        LeakyReLU-18            [1, 1024, 4, 4]               0\n",
      "         UNetDown-19            [1, 1024, 4, 4]               0\n",
      "  ConvTranspose2d-20             [1, 512, 8, 8]       8,389,120\n",
      "      BatchNorm2d-21             [1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-22             [1, 512, 8, 8]               0\n",
      "           UNetUP-23             [1, 512, 8, 8]               0\n",
      "  ConvTranspose2d-24           [1, 256, 16, 16]       2,097,408\n",
      "      BatchNorm2d-25           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-26           [1, 256, 16, 16]               0\n",
      "           UNetUP-27           [1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-28           [1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-29           [1, 128, 32, 32]             256\n",
      "        LeakyReLU-30           [1, 128, 32, 32]               0\n",
      "           UNetUP-31           [1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-32            [1, 64, 64, 64]         131,136\n",
      "      BatchNorm2d-33            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-34            [1, 64, 64, 64]               0\n",
      "           UNetUP-35            [1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-36           [1, 5, 128, 128]           5,125\n",
      "           UNetUP-37           [1, 5, 128, 128]               0\n",
      "    LinearFeature-38           [1, 5, 128, 128]              10\n",
      "    ScaledArcTanh-39           [1, 5, 128, 128]               0\n",
      "       ScaledTanh-40           [1, 5, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 22,301,199\n",
      "Trainable params: 22,301,199\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 31.62\n",
      "Params size (MB): 85.07\n",
      "Estimated Total Size (MB): 117.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#STanh = cnn.ScaledTanh(5., 2./5.)\n",
    "LF = cnn.LinearFeature(5,5, bias=True)\n",
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "Linear = torch.nn.Linear(5,5)\n",
    "shape = (5,128,128)\n",
    "FORSE = gan.FORSE(\"sehgal_forse_081020\", shape, nconv_fcgen=64,\n",
    "                          nconv_fcdis=64, cuda=False, ngpu=4, nconv_layer_gen=5, nconv_layer_disc=3, kernal_size=4, stride=2,\n",
    "                          padding=1, output_padding=0, gen_act=[LF,STanh], nin_channel=5, nout_channel=5, nthresh_layer_gen=0, nthresh_layer_disc=1, dropout_rate=0)\n",
    "\n",
    "\n",
    "print(\"====forse======\")\n",
    "torchsummary.summary(FORSE.discriminator, shape, batch_size=1, device=\"cpu\")\n",
    "torchsummary.summary(FORSE.generator, shape, batch_size=1, device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwhan89/.miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You have a CUDA device. You probably want to run with CUDA enabled\n",
      "====forse======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "            Conv2d-3           [1, 128, 32, 32]         131,200\n",
      "         LeakyReLU-4           [1, 128, 32, 32]               0\n",
      "            Conv2d-5           [1, 256, 16, 16]         524,544\n",
      "         LeakyReLU-6           [1, 256, 16, 16]               0\n",
      "            Conv2d-7             [1, 512, 8, 8]       2,097,664\n",
      "         LeakyReLU-8             [1, 512, 8, 8]               0\n",
      "            Conv2d-9            [1, 1024, 4, 4]       8,389,632\n",
      "        LeakyReLU-10            [1, 1024, 4, 4]               0\n",
      "          Reshape-11                 [1, 16384]               0\n",
      "           Linear-12                     [1, 1]          16,385\n",
      "================================================================\n",
      "Total params: 11,164,609\n",
      "Trainable params: 11,164,609\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 7.88\n",
      "Params size (MB): 42.59\n",
      "Estimated Total Size (MB): 50.78\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "          UNetDown-3            [1, 64, 64, 64]               0\n",
      "            Conv2d-4           [1, 128, 32, 32]         131,200\n",
      "       BatchNorm2d-5           [1, 128, 32, 32]             256\n",
      "         LeakyReLU-6           [1, 128, 32, 32]               0\n",
      "          UNetDown-7           [1, 128, 32, 32]               0\n",
      "            Conv2d-8           [1, 256, 16, 16]         524,544\n",
      "       BatchNorm2d-9           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-10           [1, 256, 16, 16]               0\n",
      "         UNetDown-11           [1, 256, 16, 16]               0\n",
      "           Conv2d-12             [1, 512, 8, 8]       2,097,664\n",
      "      BatchNorm2d-13             [1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-14             [1, 512, 8, 8]               0\n",
      "         UNetDown-15             [1, 512, 8, 8]               0\n",
      "           Conv2d-16            [1, 1024, 4, 4]       8,389,632\n",
      "      BatchNorm2d-17            [1, 1024, 4, 4]           2,048\n",
      "        LeakyReLU-18            [1, 1024, 4, 4]               0\n",
      "         UNetDown-19            [1, 1024, 4, 4]               0\n",
      "  ConvTranspose2d-20             [1, 512, 8, 8]       8,389,120\n",
      "      BatchNorm2d-21             [1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-22             [1, 512, 8, 8]               0\n",
      "           UNetUP-23             [1, 512, 8, 8]               0\n",
      "  ConvTranspose2d-24           [1, 256, 16, 16]       2,097,408\n",
      "      BatchNorm2d-25           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-26           [1, 256, 16, 16]               0\n",
      "           UNetUP-27           [1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-28           [1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-29           [1, 128, 32, 32]             256\n",
      "        LeakyReLU-30           [1, 128, 32, 32]               0\n",
      "           UNetUP-31           [1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-32            [1, 64, 64, 64]         131,136\n",
      "      BatchNorm2d-33            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-34            [1, 64, 64, 64]               0\n",
      "           UNetUP-35            [1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-36           [1, 5, 128, 128]           5,125\n",
      "           UNetUP-37           [1, 5, 128, 128]               0\n",
      "    LinearFeature-38           [1, 5, 128, 128]              10\n",
      "    ScaledArcTanh-39           [1, 5, 128, 128]               0\n",
      "       ScaledTanh-40           [1, 5, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 22,301,199\n",
      "Trainable params: 22,301,199\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 31.62\n",
      "Params size (MB): 85.07\n",
      "Estimated Total Size (MB): 117.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#STanh = cnn.ScaledTanh(5., 2./5.)\n",
    "LF = cnn.LinearFeature(5,5, bias=True)\n",
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "Linear = torch.nn.Linear(5,5)\n",
    "shape = (5,128,128)\n",
    "FORSE = gan.VAEGAN_WGP(\"sehgal_forse_081020\", shape, nconv_fcgen=64,\n",
    "                          nconv_fcdis=64, cuda=False, ngpu=4, nconv_layer_gen=5, nconv_layer_disc=5, kernal_size=4, stride=2,\n",
    "                          padding=1, output_padding=0, gen_act=[LF,STanh], nin_channel=5, nout_channel=5, nthresh_layer_gen=0, nthresh_layer_disc=0, dropout_rate=0)\n",
    "\n",
    "\n",
    "print(\"====forse======\")\n",
    "torchsummary.summary(FORSE.discriminator, shape, batch_size=1, device=\"cpu\")\n",
    "torchsummary.summary(FORSE.generator, shape, batch_size=1, device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====dc_wgp======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,664\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3          [-1, 128, 32, 32]         204,928\n",
      "         LeakyReLU-4          [-1, 128, 32, 32]               0\n",
      "            Conv2d-5          [-1, 256, 16, 16]         819,456\n",
      "         LeakyReLU-6          [-1, 256, 16, 16]               0\n",
      "            Conv2d-7            [-1, 512, 8, 8]       3,277,312\n",
      "         LeakyReLU-8            [-1, 512, 8, 8]               0\n",
      "            Conv2d-9            [-1, 512, 8, 8]       6,554,112\n",
      "      BatchNorm2d-10            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-11            [-1, 512, 8, 8]               0\n",
      "           Conv2d-12            [-1, 512, 8, 8]       6,554,112\n",
      "      BatchNorm2d-13            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-14            [-1, 512, 8, 8]               0\n",
      "           Conv2d-15              [-1, 1, 8, 8]          12,801\n",
      "================================================================\n",
      "Total params: 17,434,433\n",
      "Trainable params: 17,434,433\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 9.00\n",
      "Params size (MB): 66.51\n",
      "Estimated Total Size (MB): 75.88\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           4,864\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "          UNetDown-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]         204,928\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "         LeakyReLU-6          [-1, 128, 32, 32]               0\n",
      "          UNetDown-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8          [-1, 256, 16, 16]         819,456\n",
      "       BatchNorm2d-9          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-10          [-1, 256, 16, 16]               0\n",
      "         UNetDown-11          [-1, 256, 16, 16]               0\n",
      "           Conv2d-12            [-1, 256, 8, 8]       1,638,656\n",
      "      BatchNorm2d-13            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-14            [-1, 256, 8, 8]               0\n",
      "         UNetDown-15            [-1, 256, 8, 8]               0\n",
      "           Conv2d-16            [-1, 256, 4, 4]       1,638,656\n",
      "      BatchNorm2d-17            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-18            [-1, 256, 4, 4]               0\n",
      "         UNetDown-19            [-1, 256, 4, 4]               0\n",
      "           Conv2d-20            [-1, 256, 2, 2]       1,638,656\n",
      "      BatchNorm2d-21            [-1, 256, 2, 2]             512\n",
      "        LeakyReLU-22            [-1, 256, 2, 2]               0\n",
      "         UNetDown-23            [-1, 256, 2, 2]               0\n",
      "           Conv2d-24            [-1, 256, 1, 1]       1,638,656\n",
      "             ReLU-25            [-1, 256, 1, 1]               0\n",
      "         UNetDown-26            [-1, 256, 1, 1]               0\n",
      "  ConvTranspose2d-27            [-1, 256, 2, 2]       1,638,656\n",
      "      BatchNorm2d-28            [-1, 256, 2, 2]             512\n",
      "             ReLU-29            [-1, 256, 2, 2]               0\n",
      "           UNetUP-30            [-1, 512, 2, 2]               0\n",
      "  ConvTranspose2d-31            [-1, 256, 4, 4]       3,277,056\n",
      "      BatchNorm2d-32            [-1, 256, 4, 4]             512\n",
      "          Dropout-33            [-1, 256, 4, 4]               0\n",
      "             ReLU-34            [-1, 256, 4, 4]               0\n",
      "           UNetUP-35            [-1, 512, 4, 4]               0\n",
      "  ConvTranspose2d-36            [-1, 256, 8, 8]       3,277,056\n",
      "      BatchNorm2d-37            [-1, 256, 8, 8]             512\n",
      "          Dropout-38            [-1, 256, 8, 8]               0\n",
      "             ReLU-39            [-1, 256, 8, 8]               0\n",
      "           UNetUP-40            [-1, 512, 8, 8]               0\n",
      "  ConvTranspose2d-41          [-1, 256, 16, 16]       3,277,056\n",
      "      BatchNorm2d-42          [-1, 256, 16, 16]             512\n",
      "          Dropout-43          [-1, 256, 16, 16]               0\n",
      "             ReLU-44          [-1, 256, 16, 16]               0\n",
      "           UNetUP-45          [-1, 512, 16, 16]               0\n",
      "  ConvTranspose2d-46          [-1, 128, 32, 32]       1,638,528\n",
      "      BatchNorm2d-47          [-1, 128, 32, 32]             256\n",
      "             ReLU-48          [-1, 128, 32, 32]               0\n",
      "           UNetUP-49          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-50           [-1, 64, 64, 64]         409,664\n",
      "      BatchNorm2d-51           [-1, 64, 64, 64]             128\n",
      "             ReLU-52           [-1, 64, 64, 64]               0\n",
      "           UNetUP-53          [-1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-54          [-1, 3, 128, 128]           9,603\n",
      "             ReLU-55          [-1, 3, 128, 128]               0\n",
      "           UNetUP-56          [-1, 3, 128, 128]               0\n",
      "             Tanh-57          [-1, 3, 128, 128]               0\n",
      "             Tanh-58          [-1, 3, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 21,116,227\n",
      "Trainable params: 21,116,227\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 33.51\n",
      "Params size (MB): 80.55\n",
      "Estimated Total Size (MB): 114.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "shape = (6,128,128)\n",
    "genin_shape = (3,128,128)\n",
    "discin_shape = (6,128,128)\n",
    "unet_gen = model.UNET_Generator(\n",
    "    genin_shape,\n",
    "    nconv_layer=3,\n",
    "    nconv_fc=64,\n",
    "    ngpu=1,\n",
    "    kernal_size=5,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    output_padding=1,\n",
    "    normalize=True,\n",
    "    activation=torch.nn.Tanh(),\n",
    "    nin_channel = 3,\n",
    "    nout_channel = 3,\n",
    "    nthresh_layer = 4\n",
    ").to(device=\"cpu\")\n",
    "\n",
    "unet_disc = model.UNET_Discriminator(\n",
    "    shape=discin_shape,\n",
    "    nconv_layer=4,\n",
    "    nconv_fc=64,\n",
    "    ngpu=1,\n",
    "    kernal_size=5,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    normalize=False,\n",
    "    nthresh_layer=2\n",
    ").to(device=\"cpu\")\n",
    "\n",
    "print(\"====dc_wgp======\")\n",
    "torchsummary.summary(unet_disc, discin_shape, device=\"cpu\")\n",
    "torchsummary.summary(unet_gen, genin_shape, device=\"cpu\")\n",
    "#print(type(unet_disc.model))\n",
    "#torchsummary.summary(DCGAN_WGP.generator, (latent_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
