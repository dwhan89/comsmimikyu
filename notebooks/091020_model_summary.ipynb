{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from cosmikyu import gan, config, model\n",
    "from cosmikyu import nn as cnn\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import mlflow\n",
    "import torchsummary\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You have a CUDA device. You probably want to run with CUDA enabled\n",
      "====dc_wgp======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "          UNetDown-3            [1, 64, 64, 64]               0\n",
      "            Conv2d-4           [1, 128, 32, 32]         131,200\n",
      "       BatchNorm2d-5           [1, 128, 32, 32]             256\n",
      "         LeakyReLU-6           [1, 128, 32, 32]               0\n",
      "          UNetDown-7           [1, 128, 32, 32]               0\n",
      "            Conv2d-8           [1, 256, 16, 16]         524,544\n",
      "       BatchNorm2d-9           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-10           [1, 256, 16, 16]               0\n",
      "         UNetDown-11           [1, 256, 16, 16]               0\n",
      "           Conv2d-12             [1, 512, 8, 8]       2,097,664\n",
      "      BatchNorm2d-13             [1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-14             [1, 512, 8, 8]               0\n",
      "         UNetDown-15             [1, 512, 8, 8]               0\n",
      "  ConvTranspose2d-16           [1, 256, 16, 16]       2,097,408\n",
      "      BatchNorm2d-17           [1, 256, 16, 16]             512\n",
      "        LeakyReLU-18           [1, 256, 16, 16]               0\n",
      "           UNetUP-19           [1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-20           [1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-21           [1, 128, 32, 32]             256\n",
      "        LeakyReLU-22           [1, 128, 32, 32]               0\n",
      "           UNetUP-23           [1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-24            [1, 64, 64, 64]         131,136\n",
      "      BatchNorm2d-25            [1, 64, 64, 64]             128\n",
      "        LeakyReLU-26            [1, 64, 64, 64]               0\n",
      "           UNetUP-27            [1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-28           [1, 5, 128, 128]           5,125\n",
      "           UNetUP-29           [1, 5, 128, 128]               0\n",
      "    LinearFeature-30           [1, 5, 128, 128]              10\n",
      "    ScaledArcTanh-31           [1, 5, 128, 128]               0\n",
      "       ScaledTanh-32           [1, 5, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 5,519,375\n",
      "Trainable params: 5,519,375\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 30.12\n",
      "Params size (MB): 21.05\n",
      "Estimated Total Size (MB): 51.49\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2            [1, 64, 64, 64]               0\n",
      "            Conv2d-3           [1, 128, 32, 32]         131,200\n",
      "         LeakyReLU-4           [1, 128, 32, 32]               0\n",
      "            Conv2d-5           [1, 256, 16, 16]         524,544\n",
      "         LeakyReLU-6           [1, 256, 16, 16]               0\n",
      "            Conv2d-7             [1, 512, 8, 8]       2,097,664\n",
      "         LeakyReLU-8             [1, 512, 8, 8]               0\n",
      "           Reshape-9                 [1, 32768]               0\n",
      "           Linear-10                     [1, 1]          32,769\n",
      "================================================================\n",
      "Total params: 2,791,361\n",
      "Trainable params: 2,791,361\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 7.75\n",
      "Params size (MB): 10.65\n",
      "Estimated Total Size (MB): 18.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#STanh = cnn.ScaledTanh(5., 2./5.)\n",
    "LF = cnn.LinearFeature(5,5, bias=True)\n",
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "Linear = torch.nn.Linear(5,5)\n",
    "shape = (5,128,128)\n",
    "FORSE = gan.FORSE_WGP(\"sehgal_forse_081020\", shape, nconv_fcgen=64,\n",
    "                          nconv_fcdis=64, cuda=False, ngpu=4, nconv_layer_gen=4, nconv_layer_disc=4, kernal_size=4, stride=2,\n",
    "                          padding=1, output_padding=0, gen_act=[LF,STanh], nin_channel=5, nout_channel=5, nthresh_layer_gen=0, nthresh_layer_disc=0, dropout_rate=0)\n",
    "\n",
    "\n",
    "print(\"====dc_wgp======\")\n",
    "#print(unet_gen)\n",
    "#print(PIXGAN.generator)\n",
    "torchsummary.summary(FORSE.generator, (5,128,128), batch_size=1, device=\"cpu\")\n",
    "torchsummary.summary(FORSE.discriminator, (5,128,128), batch_size=1, device=\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "LF = cnn.LinearFeature(4,4, bias=True)\n",
    "shape = (5,128,128)\n",
    "PIXGAN = gan.PIXGAN_WGP(\"sehgal_pixgan_251020\", shape, nconv_fcgen=64,\n",
    "                          nconv_fcdis=64, cuda=False, ngpu=4, nconv_layer_gen=4, nconv_layer_disc=5, kernal_size=4, stride=2,\n",
    "                          padding=1, output_padding=0, gen_act=[LF,STanh], nin_channel=1, nout_channel=4, nthresh_layer_gen=3, nthresh_layer_disc=0, dropout_rate=0)\n",
    "\n",
    "\n",
    "print(\"====dc_wgp======\")\n",
    "#print(unet_gen)\n",
    "#print(PIXGAN.generator)\n",
    "torchsummary.summary(PIXGAN.discriminator, (5,128,128), batch_size=1, device=\"cpu\")\n",
    "torchsummary.summary(PIXGAN.generator, (1,128,128), batch_size=1, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You have a CUDA device. You probably want to run with CUDA enabled\n",
      "====cosmogan_wgp======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           5,184\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3          [-1, 128, 32, 32]         131,200\n",
      "         LeakyReLU-4          [-1, 128, 32, 32]               0\n",
      "            Conv2d-5          [-1, 256, 16, 16]         524,544\n",
      "         LeakyReLU-6          [-1, 256, 16, 16]               0\n",
      "            Conv2d-7            [-1, 512, 8, 8]       2,097,664\n",
      "         LeakyReLU-8            [-1, 512, 8, 8]               0\n",
      "            Conv2d-9           [-1, 1024, 4, 4]       8,389,632\n",
      "        LeakyReLU-10           [-1, 1024, 4, 4]               0\n",
      "          Reshape-11                [-1, 16384]               0\n",
      "           Linear-12                    [-1, 1]          16,385\n",
      "================================================================\n",
      "Total params: 11,164,609\n",
      "Trainable params: 11,164,609\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 7.88\n",
      "Params size (MB): 42.59\n",
      "Estimated Total Size (MB): 50.78\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 16384]       4,210,688\n",
      "           Reshape-2           [-1, 1024, 4, 4]               0\n",
      "       BatchNorm2d-3           [-1, 1024, 4, 4]           2,048\n",
      "         LeakyReLU-4           [-1, 1024, 4, 4]               0\n",
      "   ConvTranspose2d-5            [-1, 512, 8, 8]       8,389,120\n",
      "       BatchNorm2d-6            [-1, 512, 8, 8]           1,024\n",
      "         LeakyReLU-7            [-1, 512, 8, 8]               0\n",
      "   ConvTranspose2d-8          [-1, 256, 16, 16]       2,097,408\n",
      "       BatchNorm2d-9          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-10          [-1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-11          [-1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-12          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-13          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-14           [-1, 64, 64, 64]         131,136\n",
      "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
      "        LeakyReLU-16           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-17          [-1, 5, 128, 128]           5,125\n",
      "       ScaledTanh-18          [-1, 5, 128, 128]               0\n",
      "    LinearFeature-19          [-1, 5, 128, 128]              10\n",
      "================================================================\n",
      "Total params: 15,361,871\n",
      "Trainable params: 15,361,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 13.62\n",
      "Params size (MB): 58.60\n",
      "Estimated Total Size (MB): 72.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "STanh = cnn.ScaledTanh(30., 2./30.)\n",
    "LF = cnn.LinearFeature(5,5)\n",
    "latent_dim = 256\n",
    "shape = (5,128,128)\n",
    "\n",
    "DCGAN_WGP = gan.DCGAN_WGP(\"sehgal_dcganwgp\", shape, latent_dim, cuda=False, nconv_fcgen=64,\n",
    "                              nconv_fcdis=64, ngpu=4, nconv_layer_gen=5, nconv_layer_disc=5, kernal_size=4, stride=2,\n",
    "                                                        padding=1, output_padding=0, gen_act=[STanh, LF])\n",
    "\n",
    "print(\"====cosmogan_wgp======\")\n",
    "torchsummary.summary(DCGAN_WGP.discriminator, shape, device=\"cpu\")\n",
    "torchsummary.summary(DCGAN_WGP.generator, (latent_dim,), device=\"cpu\")\n",
    "del DCGAN_WGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====dc_wgp======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,664\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3          [-1, 128, 32, 32]         204,928\n",
      "         LeakyReLU-4          [-1, 128, 32, 32]               0\n",
      "            Conv2d-5          [-1, 256, 16, 16]         819,456\n",
      "         LeakyReLU-6          [-1, 256, 16, 16]               0\n",
      "            Conv2d-7            [-1, 512, 8, 8]       3,277,312\n",
      "         LeakyReLU-8            [-1, 512, 8, 8]               0\n",
      "            Conv2d-9            [-1, 512, 8, 8]       6,554,112\n",
      "      BatchNorm2d-10            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-11            [-1, 512, 8, 8]               0\n",
      "           Conv2d-12            [-1, 512, 8, 8]       6,554,112\n",
      "      BatchNorm2d-13            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-14            [-1, 512, 8, 8]               0\n",
      "           Conv2d-15              [-1, 1, 8, 8]          12,801\n",
      "================================================================\n",
      "Total params: 17,434,433\n",
      "Trainable params: 17,434,433\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 9.00\n",
      "Params size (MB): 66.51\n",
      "Estimated Total Size (MB): 75.88\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           4,864\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "          UNetDown-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]         204,928\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "         LeakyReLU-6          [-1, 128, 32, 32]               0\n",
      "          UNetDown-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8          [-1, 256, 16, 16]         819,456\n",
      "       BatchNorm2d-9          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-10          [-1, 256, 16, 16]               0\n",
      "         UNetDown-11          [-1, 256, 16, 16]               0\n",
      "           Conv2d-12            [-1, 256, 8, 8]       1,638,656\n",
      "      BatchNorm2d-13            [-1, 256, 8, 8]             512\n",
      "        LeakyReLU-14            [-1, 256, 8, 8]               0\n",
      "         UNetDown-15            [-1, 256, 8, 8]               0\n",
      "           Conv2d-16            [-1, 256, 4, 4]       1,638,656\n",
      "      BatchNorm2d-17            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-18            [-1, 256, 4, 4]               0\n",
      "         UNetDown-19            [-1, 256, 4, 4]               0\n",
      "           Conv2d-20            [-1, 256, 2, 2]       1,638,656\n",
      "      BatchNorm2d-21            [-1, 256, 2, 2]             512\n",
      "        LeakyReLU-22            [-1, 256, 2, 2]               0\n",
      "         UNetDown-23            [-1, 256, 2, 2]               0\n",
      "           Conv2d-24            [-1, 256, 1, 1]       1,638,656\n",
      "             ReLU-25            [-1, 256, 1, 1]               0\n",
      "         UNetDown-26            [-1, 256, 1, 1]               0\n",
      "  ConvTranspose2d-27            [-1, 256, 2, 2]       1,638,656\n",
      "      BatchNorm2d-28            [-1, 256, 2, 2]             512\n",
      "             ReLU-29            [-1, 256, 2, 2]               0\n",
      "           UNetUP-30            [-1, 512, 2, 2]               0\n",
      "  ConvTranspose2d-31            [-1, 256, 4, 4]       3,277,056\n",
      "      BatchNorm2d-32            [-1, 256, 4, 4]             512\n",
      "          Dropout-33            [-1, 256, 4, 4]               0\n",
      "             ReLU-34            [-1, 256, 4, 4]               0\n",
      "           UNetUP-35            [-1, 512, 4, 4]               0\n",
      "  ConvTranspose2d-36            [-1, 256, 8, 8]       3,277,056\n",
      "      BatchNorm2d-37            [-1, 256, 8, 8]             512\n",
      "          Dropout-38            [-1, 256, 8, 8]               0\n",
      "             ReLU-39            [-1, 256, 8, 8]               0\n",
      "           UNetUP-40            [-1, 512, 8, 8]               0\n",
      "  ConvTranspose2d-41          [-1, 256, 16, 16]       3,277,056\n",
      "      BatchNorm2d-42          [-1, 256, 16, 16]             512\n",
      "          Dropout-43          [-1, 256, 16, 16]               0\n",
      "             ReLU-44          [-1, 256, 16, 16]               0\n",
      "           UNetUP-45          [-1, 512, 16, 16]               0\n",
      "  ConvTranspose2d-46          [-1, 128, 32, 32]       1,638,528\n",
      "      BatchNorm2d-47          [-1, 128, 32, 32]             256\n",
      "             ReLU-48          [-1, 128, 32, 32]               0\n",
      "           UNetUP-49          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-50           [-1, 64, 64, 64]         409,664\n",
      "      BatchNorm2d-51           [-1, 64, 64, 64]             128\n",
      "             ReLU-52           [-1, 64, 64, 64]               0\n",
      "           UNetUP-53          [-1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-54          [-1, 3, 128, 128]           9,603\n",
      "             ReLU-55          [-1, 3, 128, 128]               0\n",
      "           UNetUP-56          [-1, 3, 128, 128]               0\n",
      "             Tanh-57          [-1, 3, 128, 128]               0\n",
      "             Tanh-58          [-1, 3, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 21,116,227\n",
      "Trainable params: 21,116,227\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 33.51\n",
      "Params size (MB): 80.55\n",
      "Estimated Total Size (MB): 114.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "shape = (6,128,128)\n",
    "genin_shape = (3,128,128)\n",
    "discin_shape = (6,128,128)\n",
    "unet_gen = model.UNET_Generator(\n",
    "    genin_shape,\n",
    "    nconv_layer=3,\n",
    "    nconv_fc=64,\n",
    "    ngpu=1,\n",
    "    kernal_size=5,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    output_padding=1,\n",
    "    normalize=True,\n",
    "    activation=torch.nn.Tanh(),\n",
    "    nin_channel = 3,\n",
    "    nout_channel = 3,\n",
    "    nthresh_layer = 4\n",
    ").to(device=\"cpu\")\n",
    "\n",
    "unet_disc = model.UNET_Discriminator(\n",
    "    shape=discin_shape,\n",
    "    nconv_layer=4,\n",
    "    nconv_fc=64,\n",
    "    ngpu=1,\n",
    "    kernal_size=5,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    normalize=False,\n",
    "    nthresh_layer=2\n",
    ").to(device=\"cpu\")\n",
    "\n",
    "print(\"====dc_wgp======\")\n",
    "torchsummary.summary(unet_disc, discin_shape, device=\"cpu\")\n",
    "torchsummary.summary(unet_gen, genin_shape, device=\"cpu\")\n",
    "#print(type(unet_disc.model))\n",
    "#torchsummary.summary(DCGAN_WGP.generator, (latent_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/dwhan89/.miniconda3/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/dwhan89/workspace/cosmikyu/cosmikyu/../output/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====cosmogan_wgp======\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           8,064\n",
      "         LeakyReLU-2           [-1, 64, 64, 64]               0\n",
      "            Conv2d-3          [-1, 128, 32, 32]         204,928\n",
      "         LeakyReLU-4          [-1, 128, 32, 32]               0\n",
      "            Conv2d-5          [-1, 256, 16, 16]         819,456\n",
      "         LeakyReLU-6          [-1, 256, 16, 16]               0\n",
      "            Conv2d-7            [-1, 512, 8, 8]       3,277,312\n",
      "         LeakyReLU-8            [-1, 512, 8, 8]               0\n",
      "            Conv2d-9           [-1, 1024, 4, 4]      13,108,224\n",
      "        LeakyReLU-10           [-1, 1024, 4, 4]               0\n",
      "          Reshape-11                [-1, 16384]               0\n",
      "           Linear-12                    [-1, 1]          16,385\n",
      "           Conv2d-13           [-1, 64, 64, 64]           8,064\n",
      "        LeakyReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15          [-1, 128, 32, 32]         204,928\n",
      "        LeakyReLU-16          [-1, 128, 32, 32]               0\n",
      "           Conv2d-17          [-1, 256, 16, 16]         819,456\n",
      "        LeakyReLU-18          [-1, 256, 16, 16]               0\n",
      "           Conv2d-19            [-1, 512, 8, 8]       3,277,312\n",
      "        LeakyReLU-20            [-1, 512, 8, 8]               0\n",
      "           Conv2d-21           [-1, 1024, 4, 4]      13,108,224\n",
      "        LeakyReLU-22           [-1, 1024, 4, 4]               0\n",
      "          Reshape-23                [-1, 16384]               0\n",
      "           Linear-24                    [-1, 1]          16,385\n",
      "================================================================\n",
      "Total params: 34,868,738\n",
      "Trainable params: 34,868,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.31\n",
      "Forward/backward pass size (MB): 15.75\n",
      "Params size (MB): 133.01\n",
      "Estimated Total Size (MB): 149.08\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 16384]       4,210,688\n",
      "            Linear-2                [-1, 16384]       4,210,688\n",
      "           Reshape-3           [-1, 1024, 4, 4]               0\n",
      "           Reshape-4           [-1, 1024, 4, 4]               0\n",
      "       BatchNorm2d-5           [-1, 1024, 4, 4]           2,048\n",
      "         LeakyReLU-6           [-1, 1024, 4, 4]               0\n",
      "   ConvTranspose2d-7            [-1, 512, 8, 8]      13,107,712\n",
      "       BatchNorm2d-8           [-1, 1024, 4, 4]           2,048\n",
      "       BatchNorm2d-9            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-10           [-1, 1024, 4, 4]               0\n",
      "        LeakyReLU-11            [-1, 512, 8, 8]               0\n",
      "  ConvTranspose2d-12          [-1, 256, 16, 16]       3,277,056\n",
      "  ConvTranspose2d-13            [-1, 512, 8, 8]      13,107,712\n",
      "      BatchNorm2d-14          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-15          [-1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-16          [-1, 128, 32, 32]         819,328\n",
      "      BatchNorm2d-17            [-1, 512, 8, 8]           1,024\n",
      "      BatchNorm2d-18          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-19            [-1, 512, 8, 8]               0\n",
      "        LeakyReLU-20          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-21          [-1, 256, 16, 16]       3,277,056\n",
      "  ConvTranspose2d-22           [-1, 64, 64, 64]         204,864\n",
      "      BatchNorm2d-23          [-1, 256, 16, 16]             512\n",
      "      BatchNorm2d-24           [-1, 64, 64, 64]             128\n",
      "        LeakyReLU-25          [-1, 256, 16, 16]               0\n",
      "        LeakyReLU-26           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-27          [-1, 128, 32, 32]         819,328\n",
      "  ConvTranspose2d-28          [-1, 5, 128, 128]           8,005\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "       ScaledTanh-30          [-1, 5, 128, 128]               0\n",
      "       ScaledTanh-31          [-1, 5, 128, 128]               0\n",
      "        LeakyReLU-32          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-33           [-1, 64, 64, 64]         204,864\n",
      "      BatchNorm2d-34           [-1, 64, 64, 64]             128\n",
      "        LeakyReLU-35           [-1, 64, 64, 64]               0\n",
      "  ConvTranspose2d-36          [-1, 5, 128, 128]           8,005\n",
      "       ScaledTanh-37          [-1, 5, 128, 128]               0\n",
      "       ScaledTanh-38          [-1, 5, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 43,263,242\n",
      "Trainable params: 43,263,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 27.25\n",
      "Params size (MB): 165.04\n",
      "Estimated Total Size (MB): 192.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwhan89/.miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DCGAN_Generator'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCGAN_WGP.generator.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
