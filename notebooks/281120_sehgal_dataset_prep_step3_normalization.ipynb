{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orphics import sehgal, maps\n",
    "import healpy as hp\n",
    "from pixell import utils, enmap, curvedsky, enplot, wcsutils\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lmdb\n",
    "from cosmikyu import datasets, transforms, config, stats\n",
    "from cosmikyu import utils as cutils\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config.default_data_dir\n",
    "sehgal_dir = os.path.join(data_dir, 'sehgal')\n",
    "def data_path(x):\n",
    "    return os.path.join(sehgal_dir, x)\n",
    "SDS_validation = datasets.SehgalDataSet(sehgal_dir, \"validation281220_fromcat\", transforms=[], dummy_label=False)\n",
    "data = np.zeros((5, 128, 128*len(SDS_validation)))\n",
    "compts = [\"kappa\", \"ksz\", \"tsz\", \"ir_pts\", \"rad_pts\"]\n",
    "\n",
    "for i in range(len(SDS_validation)):\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_validation[i]\n",
    "    \n",
    "def sehgal_path(x):\n",
    "    return os.path.join(sehgal_dir, x)\n",
    "\n",
    "#enplot.pshow(data[:,:128,:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zfact = 1\n",
    "def log_normalize(data):\n",
    "    emap = data[\"emap\"] \n",
    "    info = data[\"info\"]\n",
    "    loc = np.where(emap!=0)\n",
    "    std = np.std(emap[loc])\n",
    "    std = np.std(emap)\n",
    "\n",
    "    info[\"lognorm_std\"] = std.copy()\n",
    "    \n",
    "    loc = np.where(emap>=0)\n",
    "    emap[loc] = np.log(emap[loc]/std+1)\n",
    "    loc = np.where(emap<0)\n",
    "    emap[loc] = -1*np.log(np.abs(emap[loc]/std)+1)\n",
    "    data[\"emap\"] = emap\n",
    "    return data\n",
    "\n",
    "def meansub(data):\n",
    "    emap = data[\"emap\"] \n",
    "    info = data[\"info\"]\n",
    "    mean = np.mean(emap)\n",
    "    info[\"meansub_mean\"] = mean.copy()\n",
    "    data[\"emap\"] = emap - mean\n",
    "    return data\n",
    "\n",
    "\n",
    "def z_normalize(data, zfact = zfact, ignore_zero =False):\n",
    "    emap = data[\"emap\"] \n",
    "    info = data[\"info\"]\n",
    "    if not ignore_zero:\n",
    "        std = np.std(emap)\n",
    "        mean = emap.mean()\n",
    "    else:\n",
    "        loc = np.where(emap!=0)\n",
    "        std = np.std(emap[loc])\n",
    "        mean = emap[loc].mean()\n",
    "    info[\"znorm_mean\"] = mean\n",
    "    info[\"znorm_std\"] = std\n",
    "    info[\"znorm_zfact\"] = zfact\n",
    "    data[\"emap\"] = (emap-mean)/(std*zfact)\n",
    "    return data\n",
    "\n",
    "\n",
    "def shrink(data):\n",
    "    emap = data[\"emap\"] \n",
    "    info = data[\"info\"]\n",
    "    factor = np.max(np.abs(np.array([emap.min(), emap.max()])))*1.1\n",
    "    info[\"shrink_fact\"] = factor\n",
    "    data[\"emap\"]  = emap/factor\n",
    "    return data\n",
    "\n",
    "def minmax(data):\n",
    "    emap = data[\"emap\"] \n",
    "    info = data[\"info\"]\n",
    "    maxval, minval = emap.max(),emap.min()\n",
    "    #maxval = np.max(np.abs([maxval, minval]))\n",
    "    info[\"minmax_min\"] = minval\n",
    "    info[\"minmax_max\"] = maxval\n",
    "    valrange = (maxval-minval)\n",
    "    midval = (maxval+minval)/2\n",
    "    info[\"minmax_mean\"] = midval\n",
    "    data[\"emap\"] = (emap-midval)/valrange*2\n",
    "    return data\n",
    "\n",
    "\n",
    "freq_idx = 148\n",
    "ns = {\"kappa\": lambda x: (z_normalize(meansub(x))),\n",
    "      \"ksz\": lambda x: (z_normalize(meansub(x))),\n",
    "      \"ir_pts\": lambda x: (z_normalize(log_normalize(x),ignore_zero=True)),\n",
    "      \"rad_pts\": lambda x: (z_normalize(log_normalize(x),ignore_zero=True)),\n",
    "      \"tsz\": lambda x: (z_normalize(log_normalize(x),ignore_zero=True)),\n",
    "     }\n",
    "nbins = 10000\n",
    "\n",
    "norm_info_validation = {}\n",
    "compts = [\"kappa\", \"ksz\", \"tsz\", \"ir_pts\", \"rad_pts\"]\n",
    "\n",
    "for i, compt_idx in enumerate(compts[:]):\n",
    "    #if i < 2: continue\n",
    "    print(compt_idx)\n",
    "    storage = {}\n",
    "    storage[\"emap\"]  = data[i].copy()\n",
    "    storage[\"info\"]  = {}\n",
    "    minval, maxval, mean = storage[\"emap\"].min(), storage[\"emap\"].max(), storage[\"emap\"].mean()\n",
    "    print(minval, maxval, mean)\n",
    "    MB = stats.FastBINNER(minval, maxval, nbins)\n",
    "    bin_center, hist = MB.bin(data[i].copy())\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(bin_center, hist/np.sum(hist), label=compt_idx)\n",
    "    plt.legend()\n",
    "    plt.axvline(x=1, ls=\"--\", color=\"k\")\n",
    "    plt.axvline(x=-1, ls=\"--\", color=\"k\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "    \n",
    "    storage = ns[compt_idx](storage)\n",
    "    norm_info_validation[compt_idx] = storage[\"info\"]\n",
    "    MB = stats.FastBINNER(-30, 30, nbins)\n",
    "    print(np.min(storage[\"emap\"]), np.max(storage[\"emap\"]))\n",
    "    bin_center, hist = MB.bin(storage[\"emap\"])\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(bin_center, hist/np.sum(hist), label=compt_idx)\n",
    "    plt.axvline(x=1, ls=\"--\", color=\"k\")\n",
    "    plt.axvline(x=-1, ls=\"--\", color=\"k\")\n",
    "    plt.axhline(y=1e-5, ls=\"--\", color=\"k\")\n",
    "    plt.legend()\n",
    "    plt.xlim(-5,5)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in norm_info_validation.keys():  \n",
    "    print(idx, norm_info_validation[idx])\n",
    "\n",
    "np.savez(data_path(\"281220_logz_normalization_info_validation.npz\"), **norm_info_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_info_file = data_path(\"281220_logz_normalization_info_validation.npz\")\n",
    "SDN = transforms.SehgalDataNormalizerScaledLogZShrink(norm_info_file)\n",
    "SDS_test = datasets.SehgalDataSet(sehgal_dir, \"test281220_fromcat\", transforms=[SDN], dummy_label=False)\n",
    "\n",
    "nsample = len(SDS_test)\n",
    "data = np.zeros((5, 128, 128*nsample))\n",
    "SDS_test\n",
    "nbins = 10000\n",
    "for i in range(nsample):\n",
    "    if i % 5000 == 0: print(i)\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_test[i]\n",
    "print(data.min(), data.max(), data.mean())\n",
    "print(\"start binning\")\n",
    "MB = stats.FastMultBinner((-15,15), nbins, data.shape[0])\n",
    "MB.bin(data)\n",
    "    \n",
    "ret = MB.get_info()\n",
    "out = {}\n",
    "for key in range(5):\n",
    "    print(key)\n",
    "    out[SDN.channel_idxes[key]] = ret[key].copy()\n",
    "ret = out\n",
    "np.savez(sehgal_path(\"281220_normalized_histogram_test_{}.npz\".format(nbins)), **out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
