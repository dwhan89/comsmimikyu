{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from cosmikyu import visualization as covis\n",
    "from cosmikyu import gan, config\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import mlflow\n",
    "import torchsummary\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config.default_data_dir\n",
    "mnist_dir = os.path.join(data_dir, 'mnist')\n",
    "cuda = True\n",
    "shape = (1,32,32)\n",
    "latent_dim = 100\n",
    "sample_interval = 1000\n",
    "save_interval = 50000\n",
    "batch_size = 64\n",
    "nepochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        mnist_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.Resize(shape[-1]), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 8192]         827,392\n",
      "       BatchNorm2d-2            [-1, 128, 8, 8]             256\n",
      "          Upsample-3          [-1, 128, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]         147,584\n",
      "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-6          [-1, 128, 16, 16]               0\n",
      "          Upsample-7          [-1, 128, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          73,792\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11            [-1, 1, 32, 32]             577\n",
      "             Tanh-12            [-1, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 1,049,985\n",
      "Trainable params: 1,049,985\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.64\n",
      "Params size (MB): 4.01\n",
      "Estimated Total Size (MB): 7.65\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 16, 16]             160\n",
      "         LeakyReLU-2           [-1, 16, 16, 16]               0\n",
      "         Dropout2d-3           [-1, 16, 16, 16]               0\n",
      "            Conv2d-4             [-1, 32, 8, 8]           4,640\n",
      "         LeakyReLU-5             [-1, 32, 8, 8]               0\n",
      "         Dropout2d-6             [-1, 32, 8, 8]               0\n",
      "       BatchNorm2d-7             [-1, 32, 8, 8]              64\n",
      "            Conv2d-8             [-1, 64, 4, 4]          18,496\n",
      "         LeakyReLU-9             [-1, 64, 4, 4]               0\n",
      "        Dropout2d-10             [-1, 64, 4, 4]               0\n",
      "      BatchNorm2d-11             [-1, 64, 4, 4]             128\n",
      "           Conv2d-12            [-1, 128, 2, 2]          73,856\n",
      "        LeakyReLU-13            [-1, 128, 2, 2]               0\n",
      "        Dropout2d-14            [-1, 128, 2, 2]               0\n",
      "      BatchNorm2d-15            [-1, 128, 2, 2]             256\n",
      "           Linear-16                    [-1, 1]             513\n",
      "          Sigmoid-17                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 98,113\n",
      "Trainable params: 98,113\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.20\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 0.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "DCGAN = gan.DCGAN(\"mnist_dcgan_v2\", shape, latent_dim, cuda=True, ngpu=1)#, nconv_layer_gen=2, nconv_layer_disc=2, nconv_fcgen=32, nconv_fcdis=32)\n",
    "torchsummary.summary(DCGAN.generator, (100,))\n",
    "torchsummary.summary(DCGAN.discriminator, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "[Epoch 0/2] [Batch 0/938] [D loss: 0.693299] [G loss: 0.707946]\n",
      "saving states\n",
      "[Epoch 0/2] [Batch 1/938] [D loss: 0.693183] [G loss: 0.707466]\n",
      "[Epoch 0/2] [Batch 2/938] [D loss: 0.693235] [G loss: 0.706792]\n",
      "[Epoch 0/2] [Batch 3/938] [D loss: 0.693113] [G loss: 0.706293]\n",
      "[Epoch 0/2] [Batch 4/938] [D loss: 0.693210] [G loss: 0.705453]\n",
      "[Epoch 0/2] [Batch 5/938] [D loss: 0.693136] [G loss: 0.704937]\n",
      "[Epoch 0/2] [Batch 6/938] [D loss: 0.693059] [G loss: 0.704243]\n",
      "[Epoch 0/2] [Batch 7/938] [D loss: 0.692941] [G loss: 0.703679]\n",
      "[Epoch 0/2] [Batch 8/938] [D loss: 0.693007] [G loss: 0.703259]\n",
      "[Epoch 0/2] [Batch 9/938] [D loss: 0.692832] [G loss: 0.702785]\n",
      "[Epoch 0/2] [Batch 10/938] [D loss: 0.692876] [G loss: 0.702268]\n",
      "[Epoch 0/2] [Batch 11/938] [D loss: 0.692638] [G loss: 0.701726]\n",
      "[Epoch 0/2] [Batch 12/938] [D loss: 0.692531] [G loss: 0.701056]\n",
      "[Epoch 0/2] [Batch 13/938] [D loss: 0.692413] [G loss: 0.700538]\n",
      "[Epoch 0/2] [Batch 14/938] [D loss: 0.692166] [G loss: 0.699813]\n",
      "[Epoch 0/2] [Batch 15/938] [D loss: 0.692038] [G loss: 0.699116]\n",
      "[Epoch 0/2] [Batch 16/938] [D loss: 0.692068] [G loss: 0.698573]\n",
      "[Epoch 0/2] [Batch 17/938] [D loss: 0.691900] [G loss: 0.697524]\n",
      "[Epoch 0/2] [Batch 18/938] [D loss: 0.691684] [G loss: 0.696342]\n",
      "[Epoch 0/2] [Batch 19/938] [D loss: 0.691664] [G loss: 0.694830]\n",
      "[Epoch 0/2] [Batch 20/938] [D loss: 0.691738] [G loss: 0.693022]\n",
      "[Epoch 0/2] [Batch 21/938] [D loss: 0.691622] [G loss: 0.692552]\n",
      "[Epoch 0/2] [Batch 22/938] [D loss: 0.691256] [G loss: 0.692258]\n",
      "[Epoch 0/2] [Batch 23/938] [D loss: 0.691160] [G loss: 0.691402]\n",
      "[Epoch 0/2] [Batch 24/938] [D loss: 0.691259] [G loss: 0.690320]\n",
      "[Epoch 0/2] [Batch 25/938] [D loss: 0.692814] [G loss: 0.687511]\n",
      "[Epoch 0/2] [Batch 26/938] [D loss: 0.692562] [G loss: 0.688581]\n",
      "[Epoch 0/2] [Batch 27/938] [D loss: 0.691760] [G loss: 0.688329]\n",
      "[Epoch 0/2] [Batch 28/938] [D loss: 0.690666] [G loss: 0.690147]\n",
      "[Epoch 0/2] [Batch 29/938] [D loss: 0.691203] [G loss: 0.688799]\n",
      "[Epoch 0/2] [Batch 30/938] [D loss: 0.692149] [G loss: 0.690817]\n",
      "[Epoch 0/2] [Batch 31/938] [D loss: 0.691506] [G loss: 0.688290]\n",
      "[Epoch 0/2] [Batch 32/938] [D loss: 0.690595] [G loss: 0.691837]\n",
      "[Epoch 0/2] [Batch 33/938] [D loss: 0.691091] [G loss: 0.691420]\n",
      "[Epoch 0/2] [Batch 34/938] [D loss: 0.689394] [G loss: 0.693066]\n",
      "[Epoch 0/2] [Batch 35/938] [D loss: 0.688465] [G loss: 0.694780]\n",
      "[Epoch 0/2] [Batch 36/938] [D loss: 0.688240] [G loss: 0.694793]\n",
      "[Epoch 0/2] [Batch 37/938] [D loss: 0.688232] [G loss: 0.696602]\n",
      "[Epoch 0/2] [Batch 38/938] [D loss: 0.687377] [G loss: 0.698365]\n",
      "[Epoch 0/2] [Batch 39/938] [D loss: 0.687930] [G loss: 0.704132]\n",
      "[Epoch 0/2] [Batch 40/938] [D loss: 0.686878] [G loss: 0.697994]\n",
      "[Epoch 0/2] [Batch 41/938] [D loss: 0.687299] [G loss: 0.697298]\n",
      "[Epoch 0/2] [Batch 42/938] [D loss: 0.685725] [G loss: 0.694017]\n",
      "[Epoch 0/2] [Batch 43/938] [D loss: 0.687442] [G loss: 0.689269]\n",
      "[Epoch 0/2] [Batch 44/938] [D loss: 0.689267] [G loss: 0.681670]\n",
      "[Epoch 0/2] [Batch 45/938] [D loss: 0.688534] [G loss: 0.676636]\n",
      "[Epoch 0/2] [Batch 46/938] [D loss: 0.690295] [G loss: 0.674567]\n",
      "[Epoch 0/2] [Batch 47/938] [D loss: 0.691560] [G loss: 0.674082]\n",
      "[Epoch 0/2] [Batch 48/938] [D loss: 0.691716] [G loss: 0.671545]\n",
      "[Epoch 0/2] [Batch 49/938] [D loss: 0.690161] [G loss: 0.670186]\n",
      "[Epoch 0/2] [Batch 50/938] [D loss: 0.682775] [G loss: 0.668514]\n",
      "[Epoch 0/2] [Batch 51/938] [D loss: 0.694080] [G loss: 0.667819]\n",
      "[Epoch 0/2] [Batch 52/938] [D loss: 0.688380] [G loss: 0.660256]\n",
      "[Epoch 0/2] [Batch 53/938] [D loss: 0.691075] [G loss: 0.665183]\n",
      "[Epoch 0/2] [Batch 54/938] [D loss: 0.693527] [G loss: 0.667846]\n",
      "[Epoch 0/2] [Batch 55/938] [D loss: 0.694348] [G loss: 0.675644]\n",
      "[Epoch 0/2] [Batch 56/938] [D loss: 0.695099] [G loss: 0.678828]\n",
      "[Epoch 0/2] [Batch 57/938] [D loss: 0.694180] [G loss: 0.693489]\n",
      "[Epoch 0/2] [Batch 58/938] [D loss: 0.691138] [G loss: 0.698883]\n",
      "[Epoch 0/2] [Batch 59/938] [D loss: 0.690142] [G loss: 0.696616]\n",
      "[Epoch 0/2] [Batch 60/938] [D loss: 0.692009] [G loss: 0.699456]\n",
      "[Epoch 0/2] [Batch 61/938] [D loss: 0.692047] [G loss: 0.698990]\n",
      "[Epoch 0/2] [Batch 62/938] [D loss: 0.692315] [G loss: 0.702392]\n",
      "[Epoch 0/2] [Batch 63/938] [D loss: 0.695976] [G loss: 0.695528]\n",
      "[Epoch 0/2] [Batch 64/938] [D loss: 0.693811] [G loss: 0.698206]\n",
      "[Epoch 0/2] [Batch 65/938] [D loss: 0.696644] [G loss: 0.697557]\n",
      "[Epoch 0/2] [Batch 66/938] [D loss: 0.693803] [G loss: 0.697548]\n",
      "[Epoch 0/2] [Batch 67/938] [D loss: 0.694291] [G loss: 0.690445]\n",
      "[Epoch 0/2] [Batch 68/938] [D loss: 0.693100] [G loss: 0.694437]\n",
      "[Epoch 0/2] [Batch 69/938] [D loss: 0.689764] [G loss: 0.693565]\n",
      "[Epoch 0/2] [Batch 70/938] [D loss: 0.690532] [G loss: 0.683703]\n",
      "[Epoch 0/2] [Batch 71/938] [D loss: 0.688819] [G loss: 0.684486]\n",
      "[Epoch 0/2] [Batch 72/938] [D loss: 0.694213] [G loss: 0.676984]\n",
      "[Epoch 0/2] [Batch 73/938] [D loss: 0.698406] [G loss: 0.679723]\n",
      "[Epoch 0/2] [Batch 74/938] [D loss: 0.693181] [G loss: 0.687472]\n",
      "[Epoch 0/2] [Batch 75/938] [D loss: 0.696433] [G loss: 0.689983]\n",
      "[Epoch 0/2] [Batch 76/938] [D loss: 0.694090] [G loss: 0.695135]\n",
      "[Epoch 0/2] [Batch 77/938] [D loss: 0.694524] [G loss: 0.697472]\n",
      "[Epoch 0/2] [Batch 78/938] [D loss: 0.694633] [G loss: 0.701840]\n",
      "[Epoch 0/2] [Batch 79/938] [D loss: 0.692298] [G loss: 0.710895]\n",
      "[Epoch 0/2] [Batch 80/938] [D loss: 0.691542] [G loss: 0.712054]\n",
      "[Epoch 0/2] [Batch 81/938] [D loss: 0.691533] [G loss: 0.710041]\n",
      "[Epoch 0/2] [Batch 82/938] [D loss: 0.692122] [G loss: 0.718904]\n",
      "[Epoch 0/2] [Batch 83/938] [D loss: 0.690764] [G loss: 0.715552]\n",
      "[Epoch 0/2] [Batch 84/938] [D loss: 0.695040] [G loss: 0.713556]\n",
      "[Epoch 0/2] [Batch 85/938] [D loss: 0.691779] [G loss: 0.709507]\n",
      "[Epoch 0/2] [Batch 86/938] [D loss: 0.691544] [G loss: 0.700655]\n",
      "[Epoch 0/2] [Batch 87/938] [D loss: 0.697525] [G loss: 0.700877]\n",
      "[Epoch 0/2] [Batch 88/938] [D loss: 0.695943] [G loss: 0.696751]\n",
      "[Epoch 0/2] [Batch 89/938] [D loss: 0.696608] [G loss: 0.695632]\n",
      "[Epoch 0/2] [Batch 90/938] [D loss: 0.695518] [G loss: 0.693479]\n",
      "[Epoch 0/2] [Batch 91/938] [D loss: 0.691691] [G loss: 0.689207]\n",
      "[Epoch 0/2] [Batch 92/938] [D loss: 0.692284] [G loss: 0.690673]\n",
      "[Epoch 0/2] [Batch 93/938] [D loss: 0.690911] [G loss: 0.684474]\n",
      "[Epoch 0/2] [Batch 94/938] [D loss: 0.689041] [G loss: 0.689378]\n",
      "[Epoch 0/2] [Batch 95/938] [D loss: 0.689739] [G loss: 0.681235]\n",
      "[Epoch 0/2] [Batch 96/938] [D loss: 0.689202] [G loss: 0.679707]\n",
      "[Epoch 0/2] [Batch 97/938] [D loss: 0.692928] [G loss: 0.670871]\n",
      "[Epoch 0/2] [Batch 98/938] [D loss: 0.694255] [G loss: 0.673576]\n",
      "[Epoch 0/2] [Batch 99/938] [D loss: 0.696197] [G loss: 0.675959]\n",
      "[Epoch 0/2] [Batch 100/938] [D loss: 0.694131] [G loss: 0.682431]\n",
      "[Epoch 0/2] [Batch 101/938] [D loss: 0.693676] [G loss: 0.678635]\n",
      "[Epoch 0/2] [Batch 102/938] [D loss: 0.694372] [G loss: 0.688661]\n",
      "[Epoch 0/2] [Batch 103/938] [D loss: 0.693191] [G loss: 0.686178]\n",
      "[Epoch 0/2] [Batch 104/938] [D loss: 0.696907] [G loss: 0.693577]\n",
      "[Epoch 0/2] [Batch 105/938] [D loss: 0.694046] [G loss: 0.697530]\n",
      "[Epoch 0/2] [Batch 106/938] [D loss: 0.695817] [G loss: 0.704816]\n",
      "[Epoch 0/2] [Batch 107/938] [D loss: 0.692031] [G loss: 0.705366]\n",
      "[Epoch 0/2] [Batch 108/938] [D loss: 0.693931] [G loss: 0.713680]\n",
      "[Epoch 0/2] [Batch 109/938] [D loss: 0.693693] [G loss: 0.714377]\n",
      "[Epoch 0/2] [Batch 110/938] [D loss: 0.693078] [G loss: 0.720640]\n",
      "[Epoch 0/2] [Batch 111/938] [D loss: 0.690984] [G loss: 0.718459]\n",
      "[Epoch 0/2] [Batch 112/938] [D loss: 0.687740] [G loss: 0.721897]\n",
      "[Epoch 0/2] [Batch 113/938] [D loss: 0.693625] [G loss: 0.722653]\n",
      "[Epoch 0/2] [Batch 114/938] [D loss: 0.691818] [G loss: 0.715264]\n",
      "[Epoch 0/2] [Batch 115/938] [D loss: 0.692841] [G loss: 0.713223]\n",
      "[Epoch 0/2] [Batch 116/938] [D loss: 0.696355] [G loss: 0.708916]\n",
      "[Epoch 0/2] [Batch 117/938] [D loss: 0.699804] [G loss: 0.698194]\n",
      "[Epoch 0/2] [Batch 118/938] [D loss: 0.700422] [G loss: 0.693104]\n",
      "[Epoch 0/2] [Batch 119/938] [D loss: 0.697644] [G loss: 0.693988]\n",
      "[Epoch 0/2] [Batch 120/938] [D loss: 0.696777] [G loss: 0.693227]\n",
      "[Epoch 0/2] [Batch 121/938] [D loss: 0.693294] [G loss: 0.697832]\n",
      "[Epoch 0/2] [Batch 122/938] [D loss: 0.692448] [G loss: 0.697242]\n",
      "[Epoch 0/2] [Batch 123/938] [D loss: 0.689569] [G loss: 0.693962]\n",
      "[Epoch 0/2] [Batch 124/938] [D loss: 0.689122] [G loss: 0.695033]\n",
      "[Epoch 0/2] [Batch 125/938] [D loss: 0.689948] [G loss: 0.688432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 126/938] [D loss: 0.689781] [G loss: 0.683614]\n",
      "[Epoch 0/2] [Batch 127/938] [D loss: 0.689230] [G loss: 0.678326]\n",
      "[Epoch 0/2] [Batch 128/938] [D loss: 0.691927] [G loss: 0.678007]\n",
      "[Epoch 0/2] [Batch 129/938] [D loss: 0.694402] [G loss: 0.671082]\n",
      "[Epoch 0/2] [Batch 130/938] [D loss: 0.697763] [G loss: 0.670242]\n",
      "[Epoch 0/2] [Batch 131/938] [D loss: 0.696146] [G loss: 0.672262]\n",
      "[Epoch 0/2] [Batch 132/938] [D loss: 0.699234] [G loss: 0.681113]\n",
      "[Epoch 0/2] [Batch 133/938] [D loss: 0.695328] [G loss: 0.682067]\n",
      "[Epoch 0/2] [Batch 134/938] [D loss: 0.697226] [G loss: 0.688764]\n",
      "[Epoch 0/2] [Batch 135/938] [D loss: 0.696835] [G loss: 0.690955]\n",
      "[Epoch 0/2] [Batch 136/938] [D loss: 0.696762] [G loss: 0.700489]\n",
      "[Epoch 0/2] [Batch 137/938] [D loss: 0.693243] [G loss: 0.700975]\n",
      "[Epoch 0/2] [Batch 138/938] [D loss: 0.693985] [G loss: 0.702345]\n",
      "[Epoch 0/2] [Batch 139/938] [D loss: 0.692527] [G loss: 0.708584]\n",
      "[Epoch 0/2] [Batch 140/938] [D loss: 0.693681] [G loss: 0.707838]\n",
      "[Epoch 0/2] [Batch 141/938] [D loss: 0.691449] [G loss: 0.707360]\n",
      "[Epoch 0/2] [Batch 142/938] [D loss: 0.692762] [G loss: 0.708305]\n",
      "[Epoch 0/2] [Batch 143/938] [D loss: 0.694478] [G loss: 0.710776]\n",
      "[Epoch 0/2] [Batch 144/938] [D loss: 0.693158] [G loss: 0.709581]\n",
      "[Epoch 0/2] [Batch 145/938] [D loss: 0.693181] [G loss: 0.712855]\n",
      "[Epoch 0/2] [Batch 146/938] [D loss: 0.690891] [G loss: 0.712469]\n",
      "[Epoch 0/2] [Batch 147/938] [D loss: 0.690620] [G loss: 0.710073]\n",
      "[Epoch 0/2] [Batch 148/938] [D loss: 0.691203] [G loss: 0.711497]\n",
      "[Epoch 0/2] [Batch 149/938] [D loss: 0.690075] [G loss: 0.710712]\n",
      "[Epoch 0/2] [Batch 150/938] [D loss: 0.692042] [G loss: 0.706614]\n",
      "[Epoch 0/2] [Batch 151/938] [D loss: 0.692615] [G loss: 0.705952]\n",
      "[Epoch 0/2] [Batch 152/938] [D loss: 0.691017] [G loss: 0.704678]\n",
      "[Epoch 0/2] [Batch 153/938] [D loss: 0.692082] [G loss: 0.700078]\n",
      "[Epoch 0/2] [Batch 154/938] [D loss: 0.695050] [G loss: 0.696262]\n",
      "[Epoch 0/2] [Batch 155/938] [D loss: 0.692407] [G loss: 0.694925]\n",
      "[Epoch 0/2] [Batch 156/938] [D loss: 0.696347] [G loss: 0.692338]\n",
      "[Epoch 0/2] [Batch 157/938] [D loss: 0.695088] [G loss: 0.690166]\n",
      "[Epoch 0/2] [Batch 158/938] [D loss: 0.695926] [G loss: 0.689879]\n",
      "[Epoch 0/2] [Batch 159/938] [D loss: 0.695261] [G loss: 0.690616]\n",
      "[Epoch 0/2] [Batch 160/938] [D loss: 0.693302] [G loss: 0.689561]\n",
      "[Epoch 0/2] [Batch 161/938] [D loss: 0.692879] [G loss: 0.687902]\n",
      "[Epoch 0/2] [Batch 162/938] [D loss: 0.693302] [G loss: 0.689994]\n",
      "[Epoch 0/2] [Batch 163/938] [D loss: 0.692547] [G loss: 0.686255]\n",
      "[Epoch 0/2] [Batch 164/938] [D loss: 0.694380] [G loss: 0.686967]\n",
      "[Epoch 0/2] [Batch 165/938] [D loss: 0.693277] [G loss: 0.685688]\n",
      "[Epoch 0/2] [Batch 166/938] [D loss: 0.693877] [G loss: 0.687333]\n",
      "[Epoch 0/2] [Batch 167/938] [D loss: 0.692040] [G loss: 0.684922]\n",
      "[Epoch 0/2] [Batch 168/938] [D loss: 0.692535] [G loss: 0.685054]\n",
      "[Epoch 0/2] [Batch 169/938] [D loss: 0.694606] [G loss: 0.684695]\n",
      "[Epoch 0/2] [Batch 170/938] [D loss: 0.692973] [G loss: 0.685431]\n",
      "[Epoch 0/2] [Batch 171/938] [D loss: 0.693812] [G loss: 0.689245]\n",
      "[Epoch 0/2] [Batch 172/938] [D loss: 0.695280] [G loss: 0.692266]\n",
      "[Epoch 0/2] [Batch 173/938] [D loss: 0.693467] [G loss: 0.688974]\n",
      "[Epoch 0/2] [Batch 174/938] [D loss: 0.692789] [G loss: 0.693772]\n",
      "[Epoch 0/2] [Batch 175/938] [D loss: 0.694298] [G loss: 0.696587]\n",
      "[Epoch 0/2] [Batch 176/938] [D loss: 0.694442] [G loss: 0.697425]\n",
      "[Epoch 0/2] [Batch 177/938] [D loss: 0.692629] [G loss: 0.699172]\n",
      "[Epoch 0/2] [Batch 178/938] [D loss: 0.693901] [G loss: 0.700336]\n",
      "[Epoch 0/2] [Batch 179/938] [D loss: 0.692176] [G loss: 0.700578]\n",
      "[Epoch 0/2] [Batch 180/938] [D loss: 0.693843] [G loss: 0.703892]\n",
      "[Epoch 0/2] [Batch 181/938] [D loss: 0.691341] [G loss: 0.705209]\n",
      "[Epoch 0/2] [Batch 182/938] [D loss: 0.693660] [G loss: 0.703441]\n",
      "[Epoch 0/2] [Batch 183/938] [D loss: 0.693243] [G loss: 0.703691]\n",
      "[Epoch 0/2] [Batch 184/938] [D loss: 0.693587] [G loss: 0.706942]\n",
      "[Epoch 0/2] [Batch 185/938] [D loss: 0.692826] [G loss: 0.706207]\n",
      "[Epoch 0/2] [Batch 186/938] [D loss: 0.692444] [G loss: 0.706859]\n",
      "[Epoch 0/2] [Batch 187/938] [D loss: 0.693149] [G loss: 0.702639]\n",
      "[Epoch 0/2] [Batch 188/938] [D loss: 0.691929] [G loss: 0.703949]\n",
      "[Epoch 0/2] [Batch 189/938] [D loss: 0.694474] [G loss: 0.703437]\n",
      "[Epoch 0/2] [Batch 190/938] [D loss: 0.693276] [G loss: 0.699515]\n",
      "[Epoch 0/2] [Batch 191/938] [D loss: 0.694682] [G loss: 0.700184]\n",
      "[Epoch 0/2] [Batch 192/938] [D loss: 0.693600] [G loss: 0.699363]\n",
      "[Epoch 0/2] [Batch 193/938] [D loss: 0.693515] [G loss: 0.697929]\n",
      "[Epoch 0/2] [Batch 194/938] [D loss: 0.694681] [G loss: 0.699534]\n",
      "[Epoch 0/2] [Batch 195/938] [D loss: 0.694537] [G loss: 0.696027]\n",
      "[Epoch 0/2] [Batch 196/938] [D loss: 0.693274] [G loss: 0.694498]\n",
      "[Epoch 0/2] [Batch 197/938] [D loss: 0.694114] [G loss: 0.692461]\n",
      "[Epoch 0/2] [Batch 198/938] [D loss: 0.694637] [G loss: 0.696619]\n",
      "[Epoch 0/2] [Batch 199/938] [D loss: 0.693985] [G loss: 0.695100]\n",
      "[Epoch 0/2] [Batch 200/938] [D loss: 0.694080] [G loss: 0.696584]\n",
      "[Epoch 0/2] [Batch 201/938] [D loss: 0.693418] [G loss: 0.694564]\n",
      "[Epoch 0/2] [Batch 202/938] [D loss: 0.691923] [G loss: 0.690211]\n",
      "[Epoch 0/2] [Batch 203/938] [D loss: 0.693512] [G loss: 0.692471]\n",
      "[Epoch 0/2] [Batch 204/938] [D loss: 0.691435] [G loss: 0.693583]\n",
      "[Epoch 0/2] [Batch 205/938] [D loss: 0.692438] [G loss: 0.688871]\n",
      "[Epoch 0/2] [Batch 206/938] [D loss: 0.691643] [G loss: 0.686361]\n",
      "[Epoch 0/2] [Batch 207/938] [D loss: 0.693979] [G loss: 0.688131]\n",
      "[Epoch 0/2] [Batch 208/938] [D loss: 0.692310] [G loss: 0.685746]\n",
      "[Epoch 0/2] [Batch 209/938] [D loss: 0.693433] [G loss: 0.684586]\n",
      "[Epoch 0/2] [Batch 210/938] [D loss: 0.691707] [G loss: 0.687556]\n",
      "[Epoch 0/2] [Batch 211/938] [D loss: 0.694597] [G loss: 0.687290]\n",
      "[Epoch 0/2] [Batch 212/938] [D loss: 0.694321] [G loss: 0.687856]\n",
      "[Epoch 0/2] [Batch 213/938] [D loss: 0.693307] [G loss: 0.689584]\n",
      "[Epoch 0/2] [Batch 214/938] [D loss: 0.693307] [G loss: 0.688125]\n",
      "[Epoch 0/2] [Batch 215/938] [D loss: 0.694970] [G loss: 0.690043]\n",
      "[Epoch 0/2] [Batch 216/938] [D loss: 0.693527] [G loss: 0.692332]\n",
      "[Epoch 0/2] [Batch 217/938] [D loss: 0.691644] [G loss: 0.695935]\n",
      "[Epoch 0/2] [Batch 218/938] [D loss: 0.692363] [G loss: 0.691690]\n",
      "[Epoch 0/2] [Batch 219/938] [D loss: 0.694006] [G loss: 0.691931]\n",
      "[Epoch 0/2] [Batch 220/938] [D loss: 0.693108] [G loss: 0.693425]\n",
      "[Epoch 0/2] [Batch 221/938] [D loss: 0.693157] [G loss: 0.692815]\n",
      "[Epoch 0/2] [Batch 222/938] [D loss: 0.693332] [G loss: 0.693216]\n",
      "[Epoch 0/2] [Batch 223/938] [D loss: 0.693594] [G loss: 0.695224]\n",
      "[Epoch 0/2] [Batch 224/938] [D loss: 0.694785] [G loss: 0.695671]\n",
      "[Epoch 0/2] [Batch 225/938] [D loss: 0.694974] [G loss: 0.696897]\n",
      "[Epoch 0/2] [Batch 226/938] [D loss: 0.693819] [G loss: 0.695739]\n",
      "[Epoch 0/2] [Batch 227/938] [D loss: 0.692622] [G loss: 0.694738]\n",
      "[Epoch 0/2] [Batch 228/938] [D loss: 0.691696] [G loss: 0.697772]\n",
      "[Epoch 0/2] [Batch 229/938] [D loss: 0.693479] [G loss: 0.699393]\n",
      "[Epoch 0/2] [Batch 230/938] [D loss: 0.692443] [G loss: 0.695822]\n",
      "[Epoch 0/2] [Batch 231/938] [D loss: 0.694232] [G loss: 0.698145]\n",
      "[Epoch 0/2] [Batch 232/938] [D loss: 0.692712] [G loss: 0.701531]\n",
      "[Epoch 0/2] [Batch 233/938] [D loss: 0.693936] [G loss: 0.697158]\n",
      "[Epoch 0/2] [Batch 234/938] [D loss: 0.696024] [G loss: 0.699736]\n",
      "[Epoch 0/2] [Batch 235/938] [D loss: 0.694663] [G loss: 0.699030]\n",
      "[Epoch 0/2] [Batch 236/938] [D loss: 0.693393] [G loss: 0.702354]\n",
      "[Epoch 0/2] [Batch 237/938] [D loss: 0.691833] [G loss: 0.700031]\n",
      "[Epoch 0/2] [Batch 238/938] [D loss: 0.692453] [G loss: 0.696740]\n",
      "[Epoch 0/2] [Batch 239/938] [D loss: 0.692705] [G loss: 0.695964]\n",
      "[Epoch 0/2] [Batch 240/938] [D loss: 0.692502] [G loss: 0.696578]\n",
      "[Epoch 0/2] [Batch 241/938] [D loss: 0.693594] [G loss: 0.696817]\n",
      "[Epoch 0/2] [Batch 242/938] [D loss: 0.693198] [G loss: 0.692591]\n",
      "[Epoch 0/2] [Batch 243/938] [D loss: 0.692759] [G loss: 0.694538]\n",
      "[Epoch 0/2] [Batch 244/938] [D loss: 0.692223] [G loss: 0.695532]\n",
      "[Epoch 0/2] [Batch 245/938] [D loss: 0.692452] [G loss: 0.691486]\n",
      "[Epoch 0/2] [Batch 246/938] [D loss: 0.692638] [G loss: 0.691319]\n",
      "[Epoch 0/2] [Batch 247/938] [D loss: 0.691025] [G loss: 0.692460]\n",
      "[Epoch 0/2] [Batch 248/938] [D loss: 0.691620] [G loss: 0.688828]\n",
      "[Epoch 0/2] [Batch 249/938] [D loss: 0.693301] [G loss: 0.685488]\n",
      "[Epoch 0/2] [Batch 250/938] [D loss: 0.693777] [G loss: 0.690732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 251/938] [D loss: 0.692446] [G loss: 0.687075]\n",
      "[Epoch 0/2] [Batch 252/938] [D loss: 0.693590] [G loss: 0.687934]\n",
      "[Epoch 0/2] [Batch 253/938] [D loss: 0.694786] [G loss: 0.689274]\n",
      "[Epoch 0/2] [Batch 254/938] [D loss: 0.692332] [G loss: 0.692683]\n",
      "[Epoch 0/2] [Batch 255/938] [D loss: 0.694227] [G loss: 0.690323]\n",
      "[Epoch 0/2] [Batch 256/938] [D loss: 0.694957] [G loss: 0.693381]\n",
      "[Epoch 0/2] [Batch 257/938] [D loss: 0.693283] [G loss: 0.691676]\n",
      "[Epoch 0/2] [Batch 258/938] [D loss: 0.693404] [G loss: 0.693742]\n",
      "[Epoch 0/2] [Batch 259/938] [D loss: 0.692563] [G loss: 0.695447]\n",
      "[Epoch 0/2] [Batch 260/938] [D loss: 0.693734] [G loss: 0.696627]\n",
      "[Epoch 0/2] [Batch 261/938] [D loss: 0.693077] [G loss: 0.700139]\n",
      "[Epoch 0/2] [Batch 262/938] [D loss: 0.693623] [G loss: 0.698536]\n",
      "[Epoch 0/2] [Batch 263/938] [D loss: 0.693573] [G loss: 0.700273]\n",
      "[Epoch 0/2] [Batch 264/938] [D loss: 0.692131] [G loss: 0.696553]\n",
      "[Epoch 0/2] [Batch 265/938] [D loss: 0.691593] [G loss: 0.697125]\n",
      "[Epoch 0/2] [Batch 266/938] [D loss: 0.692900] [G loss: 0.700190]\n",
      "[Epoch 0/2] [Batch 267/938] [D loss: 0.690738] [G loss: 0.698838]\n",
      "[Epoch 0/2] [Batch 268/938] [D loss: 0.692085] [G loss: 0.700990]\n",
      "[Epoch 0/2] [Batch 269/938] [D loss: 0.692491] [G loss: 0.696522]\n",
      "[Epoch 0/2] [Batch 270/938] [D loss: 0.693261] [G loss: 0.694812]\n",
      "[Epoch 0/2] [Batch 271/938] [D loss: 0.691932] [G loss: 0.695122]\n",
      "[Epoch 0/2] [Batch 272/938] [D loss: 0.693505] [G loss: 0.697726]\n",
      "[Epoch 0/2] [Batch 273/938] [D loss: 0.692000] [G loss: 0.695896]\n",
      "[Epoch 0/2] [Batch 274/938] [D loss: 0.692655] [G loss: 0.692991]\n",
      "[Epoch 0/2] [Batch 275/938] [D loss: 0.692163] [G loss: 0.694615]\n",
      "[Epoch 0/2] [Batch 276/938] [D loss: 0.693671] [G loss: 0.694884]\n",
      "[Epoch 0/2] [Batch 277/938] [D loss: 0.693185] [G loss: 0.695615]\n",
      "[Epoch 0/2] [Batch 278/938] [D loss: 0.695143] [G loss: 0.694000]\n",
      "[Epoch 0/2] [Batch 279/938] [D loss: 0.693565] [G loss: 0.693814]\n",
      "[Epoch 0/2] [Batch 280/938] [D loss: 0.693558] [G loss: 0.693704]\n",
      "[Epoch 0/2] [Batch 281/938] [D loss: 0.695513] [G loss: 0.693577]\n",
      "[Epoch 0/2] [Batch 282/938] [D loss: 0.692837] [G loss: 0.692814]\n",
      "[Epoch 0/2] [Batch 283/938] [D loss: 0.692299] [G loss: 0.690363]\n",
      "[Epoch 0/2] [Batch 284/938] [D loss: 0.694045] [G loss: 0.691049]\n",
      "[Epoch 0/2] [Batch 285/938] [D loss: 0.694903] [G loss: 0.692447]\n",
      "[Epoch 0/2] [Batch 286/938] [D loss: 0.692829] [G loss: 0.691030]\n",
      "[Epoch 0/2] [Batch 287/938] [D loss: 0.694380] [G loss: 0.693188]\n",
      "[Epoch 0/2] [Batch 288/938] [D loss: 0.692543] [G loss: 0.690541]\n",
      "[Epoch 0/2] [Batch 289/938] [D loss: 0.693060] [G loss: 0.690624]\n",
      "[Epoch 0/2] [Batch 290/938] [D loss: 0.692225] [G loss: 0.692131]\n",
      "[Epoch 0/2] [Batch 291/938] [D loss: 0.695263] [G loss: 0.691612]\n",
      "[Epoch 0/2] [Batch 292/938] [D loss: 0.693081] [G loss: 0.690708]\n",
      "[Epoch 0/2] [Batch 293/938] [D loss: 0.693948] [G loss: 0.692790]\n",
      "[Epoch 0/2] [Batch 294/938] [D loss: 0.694536] [G loss: 0.694737]\n",
      "[Epoch 0/2] [Batch 295/938] [D loss: 0.693109] [G loss: 0.692939]\n",
      "[Epoch 0/2] [Batch 296/938] [D loss: 0.693709] [G loss: 0.694616]\n",
      "[Epoch 0/2] [Batch 297/938] [D loss: 0.692232] [G loss: 0.694553]\n",
      "[Epoch 0/2] [Batch 298/938] [D loss: 0.692393] [G loss: 0.695032]\n",
      "[Epoch 0/2] [Batch 299/938] [D loss: 0.693451] [G loss: 0.693689]\n",
      "[Epoch 0/2] [Batch 300/938] [D loss: 0.692392] [G loss: 0.698157]\n",
      "[Epoch 0/2] [Batch 301/938] [D loss: 0.692292] [G loss: 0.697653]\n",
      "[Epoch 0/2] [Batch 302/938] [D loss: 0.691931] [G loss: 0.697355]\n",
      "[Epoch 0/2] [Batch 303/938] [D loss: 0.692205] [G loss: 0.698263]\n",
      "[Epoch 0/2] [Batch 304/938] [D loss: 0.692398] [G loss: 0.697586]\n",
      "[Epoch 0/2] [Batch 305/938] [D loss: 0.692728] [G loss: 0.698281]\n",
      "[Epoch 0/2] [Batch 306/938] [D loss: 0.691237] [G loss: 0.693751]\n",
      "[Epoch 0/2] [Batch 307/938] [D loss: 0.693761] [G loss: 0.695009]\n",
      "[Epoch 0/2] [Batch 308/938] [D loss: 0.693663] [G loss: 0.692593]\n",
      "[Epoch 0/2] [Batch 309/938] [D loss: 0.693059] [G loss: 0.692194]\n",
      "[Epoch 0/2] [Batch 310/938] [D loss: 0.692208] [G loss: 0.695300]\n",
      "[Epoch 0/2] [Batch 311/938] [D loss: 0.691816] [G loss: 0.692148]\n",
      "[Epoch 0/2] [Batch 312/938] [D loss: 0.692783] [G loss: 0.691792]\n",
      "[Epoch 0/2] [Batch 313/938] [D loss: 0.693408] [G loss: 0.688609]\n",
      "[Epoch 0/2] [Batch 314/938] [D loss: 0.693205] [G loss: 0.689161]\n",
      "[Epoch 0/2] [Batch 315/938] [D loss: 0.693342] [G loss: 0.690056]\n",
      "[Epoch 0/2] [Batch 316/938] [D loss: 0.692266] [G loss: 0.690694]\n",
      "[Epoch 0/2] [Batch 317/938] [D loss: 0.693430] [G loss: 0.688814]\n",
      "[Epoch 0/2] [Batch 318/938] [D loss: 0.691781] [G loss: 0.689062]\n",
      "[Epoch 0/2] [Batch 319/938] [D loss: 0.692426] [G loss: 0.687204]\n",
      "[Epoch 0/2] [Batch 320/938] [D loss: 0.692416] [G loss: 0.687468]\n",
      "[Epoch 0/2] [Batch 321/938] [D loss: 0.690974] [G loss: 0.692011]\n",
      "[Epoch 0/2] [Batch 322/938] [D loss: 0.693217] [G loss: 0.686659]\n",
      "[Epoch 0/2] [Batch 323/938] [D loss: 0.693573] [G loss: 0.688661]\n",
      "[Epoch 0/2] [Batch 324/938] [D loss: 0.692376] [G loss: 0.690556]\n",
      "[Epoch 0/2] [Batch 325/938] [D loss: 0.691266] [G loss: 0.691286]\n",
      "[Epoch 0/2] [Batch 326/938] [D loss: 0.693512] [G loss: 0.690761]\n",
      "[Epoch 0/2] [Batch 327/938] [D loss: 0.691140] [G loss: 0.689249]\n",
      "[Epoch 0/2] [Batch 328/938] [D loss: 0.691501] [G loss: 0.687458]\n",
      "[Epoch 0/2] [Batch 329/938] [D loss: 0.694876] [G loss: 0.690981]\n",
      "[Epoch 0/2] [Batch 330/938] [D loss: 0.694220] [G loss: 0.693648]\n",
      "[Epoch 0/2] [Batch 331/938] [D loss: 0.694674] [G loss: 0.693234]\n",
      "[Epoch 0/2] [Batch 332/938] [D loss: 0.691852] [G loss: 0.695601]\n",
      "[Epoch 0/2] [Batch 333/938] [D loss: 0.694236] [G loss: 0.695167]\n",
      "[Epoch 0/2] [Batch 334/938] [D loss: 0.693871] [G loss: 0.695472]\n",
      "[Epoch 0/2] [Batch 335/938] [D loss: 0.692267] [G loss: 0.694055]\n",
      "[Epoch 0/2] [Batch 336/938] [D loss: 0.693500] [G loss: 0.695550]\n",
      "[Epoch 0/2] [Batch 337/938] [D loss: 0.693540] [G loss: 0.694667]\n",
      "[Epoch 0/2] [Batch 338/938] [D loss: 0.693261] [G loss: 0.693729]\n",
      "[Epoch 0/2] [Batch 339/938] [D loss: 0.693930] [G loss: 0.695007]\n",
      "[Epoch 0/2] [Batch 340/938] [D loss: 0.695456] [G loss: 0.694128]\n",
      "[Epoch 0/2] [Batch 341/938] [D loss: 0.692997] [G loss: 0.694660]\n",
      "[Epoch 0/2] [Batch 342/938] [D loss: 0.692822] [G loss: 0.692694]\n",
      "[Epoch 0/2] [Batch 343/938] [D loss: 0.693517] [G loss: 0.693341]\n",
      "[Epoch 0/2] [Batch 344/938] [D loss: 0.692942] [G loss: 0.692493]\n",
      "[Epoch 0/2] [Batch 345/938] [D loss: 0.693466] [G loss: 0.694433]\n",
      "[Epoch 0/2] [Batch 346/938] [D loss: 0.693893] [G loss: 0.693606]\n",
      "[Epoch 0/2] [Batch 347/938] [D loss: 0.693259] [G loss: 0.696609]\n",
      "[Epoch 0/2] [Batch 348/938] [D loss: 0.693751] [G loss: 0.694562]\n",
      "[Epoch 0/2] [Batch 349/938] [D loss: 0.692591] [G loss: 0.695359]\n",
      "[Epoch 0/2] [Batch 350/938] [D loss: 0.694322] [G loss: 0.695725]\n",
      "[Epoch 0/2] [Batch 351/938] [D loss: 0.693896] [G loss: 0.697321]\n",
      "[Epoch 0/2] [Batch 352/938] [D loss: 0.694551] [G loss: 0.695111]\n",
      "[Epoch 0/2] [Batch 353/938] [D loss: 0.692660] [G loss: 0.698864]\n",
      "[Epoch 0/2] [Batch 354/938] [D loss: 0.691838] [G loss: 0.695692]\n",
      "[Epoch 0/2] [Batch 355/938] [D loss: 0.692800] [G loss: 0.697027]\n",
      "[Epoch 0/2] [Batch 356/938] [D loss: 0.692611] [G loss: 0.695918]\n",
      "[Epoch 0/2] [Batch 357/938] [D loss: 0.692097] [G loss: 0.690448]\n",
      "[Epoch 0/2] [Batch 358/938] [D loss: 0.694599] [G loss: 0.692047]\n",
      "[Epoch 0/2] [Batch 359/938] [D loss: 0.692810] [G loss: 0.692772]\n",
      "[Epoch 0/2] [Batch 360/938] [D loss: 0.693919] [G loss: 0.696125]\n",
      "[Epoch 0/2] [Batch 361/938] [D loss: 0.693042] [G loss: 0.694181]\n",
      "[Epoch 0/2] [Batch 362/938] [D loss: 0.693427] [G loss: 0.691608]\n",
      "[Epoch 0/2] [Batch 363/938] [D loss: 0.693990] [G loss: 0.694990]\n",
      "[Epoch 0/2] [Batch 364/938] [D loss: 0.692249] [G loss: 0.692675]\n",
      "[Epoch 0/2] [Batch 365/938] [D loss: 0.696193] [G loss: 0.692546]\n",
      "[Epoch 0/2] [Batch 366/938] [D loss: 0.694660] [G loss: 0.695947]\n",
      "[Epoch 0/2] [Batch 367/938] [D loss: 0.692384] [G loss: 0.695127]\n",
      "[Epoch 0/2] [Batch 368/938] [D loss: 0.694807] [G loss: 0.697975]\n",
      "[Epoch 0/2] [Batch 369/938] [D loss: 0.693297] [G loss: 0.696754]\n",
      "[Epoch 0/2] [Batch 370/938] [D loss: 0.690903] [G loss: 0.697869]\n",
      "[Epoch 0/2] [Batch 371/938] [D loss: 0.692085] [G loss: 0.695060]\n",
      "[Epoch 0/2] [Batch 372/938] [D loss: 0.693515] [G loss: 0.696002]\n",
      "[Epoch 0/2] [Batch 373/938] [D loss: 0.693035] [G loss: 0.695087]\n",
      "[Epoch 0/2] [Batch 374/938] [D loss: 0.691873] [G loss: 0.694615]\n",
      "[Epoch 0/2] [Batch 375/938] [D loss: 0.693657] [G loss: 0.692518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 376/938] [D loss: 0.690653] [G loss: 0.695544]\n",
      "[Epoch 0/2] [Batch 377/938] [D loss: 0.688184] [G loss: 0.691220]\n",
      "[Epoch 0/2] [Batch 378/938] [D loss: 0.689566] [G loss: 0.690136]\n",
      "[Epoch 0/2] [Batch 379/938] [D loss: 0.691901] [G loss: 0.691527]\n",
      "[Epoch 0/2] [Batch 380/938] [D loss: 0.690875] [G loss: 0.686844]\n",
      "[Epoch 0/2] [Batch 381/938] [D loss: 0.689702] [G loss: 0.687048]\n",
      "[Epoch 0/2] [Batch 382/938] [D loss: 0.693104] [G loss: 0.682397]\n",
      "[Epoch 0/2] [Batch 383/938] [D loss: 0.698146] [G loss: 0.680188]\n",
      "[Epoch 0/2] [Batch 384/938] [D loss: 0.693049] [G loss: 0.683059]\n",
      "[Epoch 0/2] [Batch 385/938] [D loss: 0.694093] [G loss: 0.685088]\n",
      "[Epoch 0/2] [Batch 386/938] [D loss: 0.692533] [G loss: 0.685312]\n",
      "[Epoch 0/2] [Batch 387/938] [D loss: 0.693547] [G loss: 0.684974]\n",
      "[Epoch 0/2] [Batch 388/938] [D loss: 0.697138] [G loss: 0.684343]\n",
      "[Epoch 0/2] [Batch 389/938] [D loss: 0.697032] [G loss: 0.686678]\n",
      "[Epoch 0/2] [Batch 390/938] [D loss: 0.694481] [G loss: 0.693864]\n",
      "[Epoch 0/2] [Batch 391/938] [D loss: 0.695238] [G loss: 0.691882]\n",
      "[Epoch 0/2] [Batch 392/938] [D loss: 0.696690] [G loss: 0.696895]\n",
      "[Epoch 0/2] [Batch 393/938] [D loss: 0.695151] [G loss: 0.702006]\n",
      "[Epoch 0/2] [Batch 394/938] [D loss: 0.692791] [G loss: 0.700140]\n",
      "[Epoch 0/2] [Batch 395/938] [D loss: 0.692825] [G loss: 0.701591]\n",
      "[Epoch 0/2] [Batch 396/938] [D loss: 0.695369] [G loss: 0.705084]\n",
      "[Epoch 0/2] [Batch 397/938] [D loss: 0.692300] [G loss: 0.707451]\n",
      "[Epoch 0/2] [Batch 398/938] [D loss: 0.692062] [G loss: 0.709670]\n",
      "[Epoch 0/2] [Batch 399/938] [D loss: 0.690569] [G loss: 0.711706]\n",
      "[Epoch 0/2] [Batch 400/938] [D loss: 0.692865] [G loss: 0.710886]\n",
      "[Epoch 0/2] [Batch 401/938] [D loss: 0.690410] [G loss: 0.709232]\n",
      "[Epoch 0/2] [Batch 402/938] [D loss: 0.690154] [G loss: 0.710434]\n",
      "[Epoch 0/2] [Batch 403/938] [D loss: 0.692883] [G loss: 0.703236]\n",
      "[Epoch 0/2] [Batch 404/938] [D loss: 0.693916] [G loss: 0.700148]\n",
      "[Epoch 0/2] [Batch 405/938] [D loss: 0.693470] [G loss: 0.698567]\n",
      "[Epoch 0/2] [Batch 406/938] [D loss: 0.691814] [G loss: 0.696781]\n",
      "[Epoch 0/2] [Batch 407/938] [D loss: 0.693739] [G loss: 0.692824]\n",
      "[Epoch 0/2] [Batch 408/938] [D loss: 0.695503] [G loss: 0.691348]\n",
      "[Epoch 0/2] [Batch 409/938] [D loss: 0.695417] [G loss: 0.689137]\n",
      "[Epoch 0/2] [Batch 410/938] [D loss: 0.693041] [G loss: 0.688227]\n",
      "[Epoch 0/2] [Batch 411/938] [D loss: 0.693180] [G loss: 0.691041]\n",
      "[Epoch 0/2] [Batch 412/938] [D loss: 0.692303] [G loss: 0.685578]\n",
      "[Epoch 0/2] [Batch 413/938] [D loss: 0.693956] [G loss: 0.685397]\n",
      "[Epoch 0/2] [Batch 414/938] [D loss: 0.692418] [G loss: 0.684218]\n",
      "[Epoch 0/2] [Batch 415/938] [D loss: 0.695149] [G loss: 0.684674]\n",
      "[Epoch 0/2] [Batch 416/938] [D loss: 0.693509] [G loss: 0.683992]\n",
      "[Epoch 0/2] [Batch 417/938] [D loss: 0.692299] [G loss: 0.687373]\n",
      "[Epoch 0/2] [Batch 418/938] [D loss: 0.695577] [G loss: 0.689684]\n",
      "[Epoch 0/2] [Batch 419/938] [D loss: 0.695169] [G loss: 0.693426]\n",
      "[Epoch 0/2] [Batch 420/938] [D loss: 0.693285] [G loss: 0.692121]\n",
      "[Epoch 0/2] [Batch 421/938] [D loss: 0.694552] [G loss: 0.697691]\n",
      "[Epoch 0/2] [Batch 422/938] [D loss: 0.692939] [G loss: 0.699512]\n",
      "[Epoch 0/2] [Batch 423/938] [D loss: 0.693884] [G loss: 0.700978]\n",
      "[Epoch 0/2] [Batch 424/938] [D loss: 0.694564] [G loss: 0.704166]\n",
      "[Epoch 0/2] [Batch 425/938] [D loss: 0.692679] [G loss: 0.703018]\n",
      "[Epoch 0/2] [Batch 426/938] [D loss: 0.692211] [G loss: 0.708189]\n",
      "[Epoch 0/2] [Batch 427/938] [D loss: 0.691580] [G loss: 0.705918]\n",
      "[Epoch 0/2] [Batch 428/938] [D loss: 0.691700] [G loss: 0.705244]\n",
      "[Epoch 0/2] [Batch 429/938] [D loss: 0.693214] [G loss: 0.704183]\n",
      "[Epoch 0/2] [Batch 430/938] [D loss: 0.690974] [G loss: 0.702046]\n",
      "[Epoch 0/2] [Batch 431/938] [D loss: 0.691628] [G loss: 0.702549]\n",
      "[Epoch 0/2] [Batch 432/938] [D loss: 0.691372] [G loss: 0.697291]\n",
      "[Epoch 0/2] [Batch 433/938] [D loss: 0.691158] [G loss: 0.693371]\n",
      "[Epoch 0/2] [Batch 434/938] [D loss: 0.692908] [G loss: 0.694635]\n",
      "[Epoch 0/2] [Batch 435/938] [D loss: 0.692001] [G loss: 0.690419]\n",
      "[Epoch 0/2] [Batch 436/938] [D loss: 0.694137] [G loss: 0.688258]\n",
      "[Epoch 0/2] [Batch 437/938] [D loss: 0.690846] [G loss: 0.684546]\n",
      "[Epoch 0/2] [Batch 438/938] [D loss: 0.691532] [G loss: 0.681590]\n",
      "[Epoch 0/2] [Batch 439/938] [D loss: 0.691950] [G loss: 0.679785]\n",
      "[Epoch 0/2] [Batch 440/938] [D loss: 0.695738] [G loss: 0.679622]\n",
      "[Epoch 0/2] [Batch 441/938] [D loss: 0.695283] [G loss: 0.680893]\n",
      "[Epoch 0/2] [Batch 442/938] [D loss: 0.692218] [G loss: 0.682813]\n",
      "[Epoch 0/2] [Batch 443/938] [D loss: 0.695196] [G loss: 0.686028]\n",
      "[Epoch 0/2] [Batch 444/938] [D loss: 0.693574] [G loss: 0.685223]\n",
      "[Epoch 0/2] [Batch 445/938] [D loss: 0.696515] [G loss: 0.687362]\n",
      "[Epoch 0/2] [Batch 446/938] [D loss: 0.694470] [G loss: 0.693010]\n",
      "[Epoch 0/2] [Batch 447/938] [D loss: 0.694754] [G loss: 0.695438]\n",
      "[Epoch 0/2] [Batch 448/938] [D loss: 0.694003] [G loss: 0.697757]\n",
      "[Epoch 0/2] [Batch 449/938] [D loss: 0.695532] [G loss: 0.699383]\n",
      "[Epoch 0/2] [Batch 450/938] [D loss: 0.692787] [G loss: 0.699540]\n",
      "[Epoch 0/2] [Batch 451/938] [D loss: 0.693988] [G loss: 0.699107]\n",
      "[Epoch 0/2] [Batch 452/938] [D loss: 0.693233] [G loss: 0.702671]\n",
      "[Epoch 0/2] [Batch 453/938] [D loss: 0.693630] [G loss: 0.701601]\n",
      "[Epoch 0/2] [Batch 454/938] [D loss: 0.693127] [G loss: 0.704482]\n",
      "[Epoch 0/2] [Batch 455/938] [D loss: 0.694688] [G loss: 0.703400]\n",
      "[Epoch 0/2] [Batch 456/938] [D loss: 0.693334] [G loss: 0.703854]\n",
      "[Epoch 0/2] [Batch 457/938] [D loss: 0.692777] [G loss: 0.702512]\n",
      "[Epoch 0/2] [Batch 458/938] [D loss: 0.693030] [G loss: 0.701609]\n",
      "[Epoch 0/2] [Batch 459/938] [D loss: 0.692731] [G loss: 0.699590]\n",
      "[Epoch 0/2] [Batch 460/938] [D loss: 0.692864] [G loss: 0.695336]\n",
      "[Epoch 0/2] [Batch 461/938] [D loss: 0.692465] [G loss: 0.695203]\n",
      "[Epoch 0/2] [Batch 462/938] [D loss: 0.694033] [G loss: 0.693489]\n",
      "[Epoch 0/2] [Batch 463/938] [D loss: 0.692232] [G loss: 0.692285]\n",
      "[Epoch 0/2] [Batch 464/938] [D loss: 0.692289] [G loss: 0.692536]\n",
      "[Epoch 0/2] [Batch 465/938] [D loss: 0.692263] [G loss: 0.691896]\n",
      "[Epoch 0/2] [Batch 466/938] [D loss: 0.691157] [G loss: 0.689748]\n",
      "[Epoch 0/2] [Batch 467/938] [D loss: 0.691826] [G loss: 0.686125]\n",
      "[Epoch 0/2] [Batch 468/938] [D loss: 0.691943] [G loss: 0.687993]\n",
      "[Epoch 0/2] [Batch 469/938] [D loss: 0.692010] [G loss: 0.686002]\n",
      "[Epoch 0/2] [Batch 470/938] [D loss: 0.690948] [G loss: 0.683803]\n",
      "[Epoch 0/2] [Batch 471/938] [D loss: 0.692161] [G loss: 0.684979]\n",
      "[Epoch 0/2] [Batch 472/938] [D loss: 0.693410] [G loss: 0.685753]\n",
      "[Epoch 0/2] [Batch 473/938] [D loss: 0.694184] [G loss: 0.687041]\n",
      "[Epoch 0/2] [Batch 474/938] [D loss: 0.690527] [G loss: 0.689047]\n",
      "[Epoch 0/2] [Batch 475/938] [D loss: 0.693127] [G loss: 0.688158]\n",
      "[Epoch 0/2] [Batch 476/938] [D loss: 0.694043] [G loss: 0.690930]\n",
      "[Epoch 0/2] [Batch 477/938] [D loss: 0.696549] [G loss: 0.690506]\n",
      "[Epoch 0/2] [Batch 478/938] [D loss: 0.692702] [G loss: 0.699308]\n",
      "[Epoch 0/2] [Batch 479/938] [D loss: 0.693614] [G loss: 0.697877]\n",
      "[Epoch 0/2] [Batch 480/938] [D loss: 0.694734] [G loss: 0.696916]\n",
      "[Epoch 0/2] [Batch 481/938] [D loss: 0.692743] [G loss: 0.697895]\n",
      "[Epoch 0/2] [Batch 482/938] [D loss: 0.693422] [G loss: 0.699319]\n",
      "[Epoch 0/2] [Batch 483/938] [D loss: 0.693838] [G loss: 0.701307]\n",
      "[Epoch 0/2] [Batch 484/938] [D loss: 0.692526] [G loss: 0.699069]\n",
      "[Epoch 0/2] [Batch 485/938] [D loss: 0.693063] [G loss: 0.702024]\n",
      "[Epoch 0/2] [Batch 486/938] [D loss: 0.695160] [G loss: 0.696792]\n",
      "[Epoch 0/2] [Batch 487/938] [D loss: 0.692455] [G loss: 0.695534]\n",
      "[Epoch 0/2] [Batch 488/938] [D loss: 0.691212] [G loss: 0.691070]\n",
      "[Epoch 0/2] [Batch 489/938] [D loss: 0.692616] [G loss: 0.692526]\n",
      "[Epoch 0/2] [Batch 490/938] [D loss: 0.692632] [G loss: 0.690072]\n",
      "[Epoch 0/2] [Batch 491/938] [D loss: 0.691326] [G loss: 0.691584]\n",
      "[Epoch 0/2] [Batch 492/938] [D loss: 0.691660] [G loss: 0.689413]\n",
      "[Epoch 0/2] [Batch 493/938] [D loss: 0.690748] [G loss: 0.686069]\n",
      "[Epoch 0/2] [Batch 494/938] [D loss: 0.693122] [G loss: 0.686374]\n",
      "[Epoch 0/2] [Batch 495/938] [D loss: 0.689510] [G loss: 0.681951]\n",
      "[Epoch 0/2] [Batch 496/938] [D loss: 0.691171] [G loss: 0.684294]\n",
      "[Epoch 0/2] [Batch 497/938] [D loss: 0.693919] [G loss: 0.680067]\n",
      "[Epoch 0/2] [Batch 498/938] [D loss: 0.692897] [G loss: 0.677245]\n",
      "[Epoch 0/2] [Batch 499/938] [D loss: 0.693521] [G loss: 0.679451]\n",
      "[Epoch 0/2] [Batch 500/938] [D loss: 0.692701] [G loss: 0.684658]\n",
      "[Epoch 0/2] [Batch 501/938] [D loss: 0.691775] [G loss: 0.683442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 502/938] [D loss: 0.698007] [G loss: 0.685271]\n",
      "[Epoch 0/2] [Batch 503/938] [D loss: 0.699083] [G loss: 0.689567]\n",
      "[Epoch 0/2] [Batch 504/938] [D loss: 0.693978] [G loss: 0.694699]\n",
      "[Epoch 0/2] [Batch 505/938] [D loss: 0.694890] [G loss: 0.698440]\n",
      "[Epoch 0/2] [Batch 506/938] [D loss: 0.694817] [G loss: 0.699158]\n",
      "[Epoch 0/2] [Batch 507/938] [D loss: 0.692992] [G loss: 0.695589]\n",
      "[Epoch 0/2] [Batch 508/938] [D loss: 0.694380] [G loss: 0.701679]\n",
      "[Epoch 0/2] [Batch 509/938] [D loss: 0.692162] [G loss: 0.702514]\n",
      "[Epoch 0/2] [Batch 510/938] [D loss: 0.692036] [G loss: 0.698655]\n",
      "[Epoch 0/2] [Batch 511/938] [D loss: 0.695146] [G loss: 0.699887]\n",
      "[Epoch 0/2] [Batch 512/938] [D loss: 0.693674] [G loss: 0.699516]\n",
      "[Epoch 0/2] [Batch 513/938] [D loss: 0.693215] [G loss: 0.702630]\n",
      "[Epoch 0/2] [Batch 514/938] [D loss: 0.695057] [G loss: 0.698485]\n",
      "[Epoch 0/2] [Batch 515/938] [D loss: 0.693624] [G loss: 0.703174]\n",
      "[Epoch 0/2] [Batch 516/938] [D loss: 0.692204] [G loss: 0.698709]\n",
      "[Epoch 0/2] [Batch 517/938] [D loss: 0.690871] [G loss: 0.700338]\n",
      "[Epoch 0/2] [Batch 518/938] [D loss: 0.692398] [G loss: 0.699246]\n",
      "[Epoch 0/2] [Batch 519/938] [D loss: 0.690596] [G loss: 0.697505]\n",
      "[Epoch 0/2] [Batch 520/938] [D loss: 0.690800] [G loss: 0.695430]\n",
      "[Epoch 0/2] [Batch 521/938] [D loss: 0.692679] [G loss: 0.695896]\n",
      "[Epoch 0/2] [Batch 522/938] [D loss: 0.689958] [G loss: 0.690863]\n",
      "[Epoch 0/2] [Batch 523/938] [D loss: 0.691002] [G loss: 0.691301]\n",
      "[Epoch 0/2] [Batch 524/938] [D loss: 0.692915] [G loss: 0.694398]\n",
      "[Epoch 0/2] [Batch 525/938] [D loss: 0.690257] [G loss: 0.689740]\n",
      "[Epoch 0/2] [Batch 526/938] [D loss: 0.692811] [G loss: 0.688011]\n",
      "[Epoch 0/2] [Batch 527/938] [D loss: 0.693016] [G loss: 0.687068]\n",
      "[Epoch 0/2] [Batch 528/938] [D loss: 0.693276] [G loss: 0.692212]\n",
      "[Epoch 0/2] [Batch 529/938] [D loss: 0.694169] [G loss: 0.693302]\n",
      "[Epoch 0/2] [Batch 530/938] [D loss: 0.694691] [G loss: 0.700498]\n",
      "[Epoch 0/2] [Batch 531/938] [D loss: 0.692862] [G loss: 0.696940]\n",
      "[Epoch 0/2] [Batch 532/938] [D loss: 0.692958] [G loss: 0.696265]\n",
      "[Epoch 0/2] [Batch 533/938] [D loss: 0.694017] [G loss: 0.697147]\n",
      "[Epoch 0/2] [Batch 534/938] [D loss: 0.692988] [G loss: 0.701662]\n",
      "[Epoch 0/2] [Batch 535/938] [D loss: 0.695755] [G loss: 0.699600]\n",
      "[Epoch 0/2] [Batch 536/938] [D loss: 0.696012] [G loss: 0.701955]\n",
      "[Epoch 0/2] [Batch 537/938] [D loss: 0.694531] [G loss: 0.705180]\n",
      "[Epoch 0/2] [Batch 538/938] [D loss: 0.693729] [G loss: 0.707033]\n",
      "[Epoch 0/2] [Batch 539/938] [D loss: 0.694115] [G loss: 0.703210]\n",
      "[Epoch 0/2] [Batch 540/938] [D loss: 0.693520] [G loss: 0.700978]\n",
      "[Epoch 0/2] [Batch 541/938] [D loss: 0.693260] [G loss: 0.704344]\n",
      "[Epoch 0/2] [Batch 542/938] [D loss: 0.693084] [G loss: 0.700968]\n",
      "[Epoch 0/2] [Batch 543/938] [D loss: 0.693188] [G loss: 0.699624]\n",
      "[Epoch 0/2] [Batch 544/938] [D loss: 0.691988] [G loss: 0.697181]\n",
      "[Epoch 0/2] [Batch 545/938] [D loss: 0.691067] [G loss: 0.696037]\n",
      "[Epoch 0/2] [Batch 546/938] [D loss: 0.690695] [G loss: 0.694925]\n",
      "[Epoch 0/2] [Batch 547/938] [D loss: 0.691593] [G loss: 0.691747]\n",
      "[Epoch 0/2] [Batch 548/938] [D loss: 0.690693] [G loss: 0.689619]\n",
      "[Epoch 0/2] [Batch 549/938] [D loss: 0.692117] [G loss: 0.686381]\n",
      "[Epoch 0/2] [Batch 550/938] [D loss: 0.690301] [G loss: 0.684703]\n",
      "[Epoch 0/2] [Batch 551/938] [D loss: 0.692062] [G loss: 0.684357]\n",
      "[Epoch 0/2] [Batch 552/938] [D loss: 0.692730] [G loss: 0.686050]\n",
      "[Epoch 0/2] [Batch 553/938] [D loss: 0.691059] [G loss: 0.688122]\n",
      "[Epoch 0/2] [Batch 554/938] [D loss: 0.692901] [G loss: 0.690079]\n",
      "[Epoch 0/2] [Batch 555/938] [D loss: 0.695736] [G loss: 0.685400]\n",
      "[Epoch 0/2] [Batch 556/938] [D loss: 0.693729] [G loss: 0.692024]\n",
      "[Epoch 0/2] [Batch 557/938] [D loss: 0.692752] [G loss: 0.699380]\n",
      "[Epoch 0/2] [Batch 558/938] [D loss: 0.694041] [G loss: 0.698685]\n",
      "[Epoch 0/2] [Batch 559/938] [D loss: 0.693545] [G loss: 0.697477]\n",
      "[Epoch 0/2] [Batch 560/938] [D loss: 0.693502] [G loss: 0.702594]\n",
      "[Epoch 0/2] [Batch 561/938] [D loss: 0.692454] [G loss: 0.701277]\n",
      "[Epoch 0/2] [Batch 562/938] [D loss: 0.694371] [G loss: 0.702457]\n",
      "[Epoch 0/2] [Batch 563/938] [D loss: 0.693027] [G loss: 0.701650]\n",
      "[Epoch 0/2] [Batch 564/938] [D loss: 0.695931] [G loss: 0.701990]\n",
      "[Epoch 0/2] [Batch 565/938] [D loss: 0.693690] [G loss: 0.698246]\n",
      "[Epoch 0/2] [Batch 566/938] [D loss: 0.695076] [G loss: 0.697594]\n",
      "[Epoch 0/2] [Batch 567/938] [D loss: 0.693965] [G loss: 0.695773]\n",
      "[Epoch 0/2] [Batch 568/938] [D loss: 0.693132] [G loss: 0.696467]\n",
      "[Epoch 0/2] [Batch 569/938] [D loss: 0.693600] [G loss: 0.696964]\n",
      "[Epoch 0/2] [Batch 570/938] [D loss: 0.691547] [G loss: 0.695648]\n",
      "[Epoch 0/2] [Batch 571/938] [D loss: 0.691034] [G loss: 0.696658]\n",
      "[Epoch 0/2] [Batch 572/938] [D loss: 0.690986] [G loss: 0.691309]\n",
      "[Epoch 0/2] [Batch 573/938] [D loss: 0.688660] [G loss: 0.691486]\n",
      "[Epoch 0/2] [Batch 574/938] [D loss: 0.691919] [G loss: 0.688540]\n",
      "[Epoch 0/2] [Batch 575/938] [D loss: 0.693049] [G loss: 0.685790]\n",
      "[Epoch 0/2] [Batch 576/938] [D loss: 0.690393] [G loss: 0.686892]\n",
      "[Epoch 0/2] [Batch 577/938] [D loss: 0.689827] [G loss: 0.694224]\n",
      "[Epoch 0/2] [Batch 578/938] [D loss: 0.692333] [G loss: 0.688740]\n",
      "[Epoch 0/2] [Batch 579/938] [D loss: 0.690932] [G loss: 0.692155]\n",
      "[Epoch 0/2] [Batch 580/938] [D loss: 0.691994] [G loss: 0.694749]\n",
      "[Epoch 0/2] [Batch 581/938] [D loss: 0.691877] [G loss: 0.699115]\n",
      "[Epoch 0/2] [Batch 582/938] [D loss: 0.693899] [G loss: 0.698011]\n",
      "[Epoch 0/2] [Batch 583/938] [D loss: 0.692693] [G loss: 0.703144]\n",
      "[Epoch 0/2] [Batch 584/938] [D loss: 0.693405] [G loss: 0.703391]\n",
      "[Epoch 0/2] [Batch 585/938] [D loss: 0.694468] [G loss: 0.698905]\n",
      "[Epoch 0/2] [Batch 586/938] [D loss: 0.693233] [G loss: 0.695897]\n",
      "[Epoch 0/2] [Batch 587/938] [D loss: 0.696325] [G loss: 0.694365]\n",
      "[Epoch 0/2] [Batch 588/938] [D loss: 0.692958] [G loss: 0.691293]\n",
      "[Epoch 0/2] [Batch 589/938] [D loss: 0.693786] [G loss: 0.687290]\n",
      "[Epoch 0/2] [Batch 590/938] [D loss: 0.694974] [G loss: 0.685648]\n",
      "[Epoch 0/2] [Batch 591/938] [D loss: 0.691357] [G loss: 0.682728]\n",
      "[Epoch 0/2] [Batch 592/938] [D loss: 0.691301] [G loss: 0.682096]\n",
      "[Epoch 0/2] [Batch 593/938] [D loss: 0.689783] [G loss: 0.683211]\n",
      "[Epoch 0/2] [Batch 594/938] [D loss: 0.690557] [G loss: 0.675069]\n",
      "[Epoch 0/2] [Batch 595/938] [D loss: 0.692019] [G loss: 0.673091]\n",
      "[Epoch 0/2] [Batch 596/938] [D loss: 0.691826] [G loss: 0.672704]\n",
      "[Epoch 0/2] [Batch 597/938] [D loss: 0.689323] [G loss: 0.671606]\n",
      "[Epoch 0/2] [Batch 598/938] [D loss: 0.690912] [G loss: 0.677905]\n",
      "[Epoch 0/2] [Batch 599/938] [D loss: 0.693131] [G loss: 0.671069]\n",
      "[Epoch 0/2] [Batch 600/938] [D loss: 0.692968] [G loss: 0.681016]\n",
      "[Epoch 0/2] [Batch 601/938] [D loss: 0.696666] [G loss: 0.681662]\n",
      "[Epoch 0/2] [Batch 602/938] [D loss: 0.694083] [G loss: 0.679854]\n",
      "[Epoch 0/2] [Batch 603/938] [D loss: 0.689417] [G loss: 0.686583]\n",
      "[Epoch 0/2] [Batch 604/938] [D loss: 0.697782] [G loss: 0.690238]\n",
      "[Epoch 0/2] [Batch 605/938] [D loss: 0.696117] [G loss: 0.697264]\n",
      "[Epoch 0/2] [Batch 606/938] [D loss: 0.692858] [G loss: 0.702286]\n",
      "[Epoch 0/2] [Batch 607/938] [D loss: 0.693501] [G loss: 0.702751]\n",
      "[Epoch 0/2] [Batch 608/938] [D loss: 0.694552] [G loss: 0.704807]\n",
      "[Epoch 0/2] [Batch 609/938] [D loss: 0.694324] [G loss: 0.708999]\n",
      "[Epoch 0/2] [Batch 610/938] [D loss: 0.692536] [G loss: 0.705164]\n",
      "[Epoch 0/2] [Batch 611/938] [D loss: 0.693321] [G loss: 0.702983]\n",
      "[Epoch 0/2] [Batch 612/938] [D loss: 0.694470] [G loss: 0.700319]\n",
      "[Epoch 0/2] [Batch 613/938] [D loss: 0.692053] [G loss: 0.700365]\n",
      "[Epoch 0/2] [Batch 614/938] [D loss: 0.690037] [G loss: 0.699896]\n",
      "[Epoch 0/2] [Batch 615/938] [D loss: 0.692227] [G loss: 0.697575]\n",
      "[Epoch 0/2] [Batch 616/938] [D loss: 0.690632] [G loss: 0.694499]\n",
      "[Epoch 0/2] [Batch 617/938] [D loss: 0.689242] [G loss: 0.688503]\n",
      "[Epoch 0/2] [Batch 618/938] [D loss: 0.694298] [G loss: 0.692464]\n",
      "[Epoch 0/2] [Batch 619/938] [D loss: 0.696184] [G loss: 0.687341]\n",
      "[Epoch 0/2] [Batch 620/938] [D loss: 0.694047] [G loss: 0.688846]\n",
      "[Epoch 0/2] [Batch 621/938] [D loss: 0.698839] [G loss: 0.693322]\n",
      "[Epoch 0/2] [Batch 622/938] [D loss: 0.695306] [G loss: 0.700104]\n",
      "[Epoch 0/2] [Batch 623/938] [D loss: 0.695096] [G loss: 0.707102]\n",
      "[Epoch 0/2] [Batch 624/938] [D loss: 0.693706] [G loss: 0.707717]\n",
      "[Epoch 0/2] [Batch 625/938] [D loss: 0.693095] [G loss: 0.711844]\n",
      "[Epoch 0/2] [Batch 626/938] [D loss: 0.691589] [G loss: 0.712815]\n",
      "[Epoch 0/2] [Batch 627/938] [D loss: 0.691315] [G loss: 0.709967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 628/938] [D loss: 0.693233] [G loss: 0.719420]\n",
      "[Epoch 0/2] [Batch 629/938] [D loss: 0.690741] [G loss: 0.712023]\n",
      "[Epoch 0/2] [Batch 630/938] [D loss: 0.694547] [G loss: 0.711143]\n",
      "[Epoch 0/2] [Batch 631/938] [D loss: 0.693631] [G loss: 0.710328]\n",
      "[Epoch 0/2] [Batch 632/938] [D loss: 0.691746] [G loss: 0.708108]\n",
      "[Epoch 0/2] [Batch 633/938] [D loss: 0.692590] [G loss: 0.700595]\n",
      "[Epoch 0/2] [Batch 634/938] [D loss: 0.693246] [G loss: 0.701110]\n",
      "[Epoch 0/2] [Batch 635/938] [D loss: 0.689983] [G loss: 0.695859]\n",
      "[Epoch 0/2] [Batch 636/938] [D loss: 0.691275] [G loss: 0.695521]\n",
      "[Epoch 0/2] [Batch 637/938] [D loss: 0.689748] [G loss: 0.692162]\n",
      "[Epoch 0/2] [Batch 638/938] [D loss: 0.692174] [G loss: 0.691856]\n",
      "[Epoch 0/2] [Batch 639/938] [D loss: 0.686653] [G loss: 0.685993]\n",
      "[Epoch 0/2] [Batch 640/938] [D loss: 0.689393] [G loss: 0.679632]\n",
      "[Epoch 0/2] [Batch 641/938] [D loss: 0.691758] [G loss: 0.675328]\n",
      "[Epoch 0/2] [Batch 642/938] [D loss: 0.694442] [G loss: 0.674480]\n",
      "[Epoch 0/2] [Batch 643/938] [D loss: 0.692821] [G loss: 0.680324]\n",
      "[Epoch 0/2] [Batch 644/938] [D loss: 0.694530] [G loss: 0.684610]\n",
      "[Epoch 0/2] [Batch 645/938] [D loss: 0.695075] [G loss: 0.689624]\n",
      "[Epoch 0/2] [Batch 646/938] [D loss: 0.696143] [G loss: 0.701833]\n",
      "[Epoch 0/2] [Batch 647/938] [D loss: 0.694191] [G loss: 0.701616]\n",
      "[Epoch 0/2] [Batch 648/938] [D loss: 0.694890] [G loss: 0.698374]\n",
      "[Epoch 0/2] [Batch 649/938] [D loss: 0.692458] [G loss: 0.710205]\n",
      "[Epoch 0/2] [Batch 650/938] [D loss: 0.694571] [G loss: 0.714157]\n",
      "[Epoch 0/2] [Batch 651/938] [D loss: 0.691163] [G loss: 0.715453]\n",
      "[Epoch 0/2] [Batch 652/938] [D loss: 0.691953] [G loss: 0.711158]\n",
      "[Epoch 0/2] [Batch 653/938] [D loss: 0.692733] [G loss: 0.712429]\n",
      "[Epoch 0/2] [Batch 654/938] [D loss: 0.691178] [G loss: 0.709711]\n",
      "[Epoch 0/2] [Batch 655/938] [D loss: 0.693345] [G loss: 0.707002]\n",
      "[Epoch 0/2] [Batch 656/938] [D loss: 0.692518] [G loss: 0.703067]\n",
      "[Epoch 0/2] [Batch 657/938] [D loss: 0.689695] [G loss: 0.698465]\n",
      "[Epoch 0/2] [Batch 658/938] [D loss: 0.688168] [G loss: 0.701159]\n",
      "[Epoch 0/2] [Batch 659/938] [D loss: 0.685301] [G loss: 0.694441]\n",
      "[Epoch 0/2] [Batch 660/938] [D loss: 0.686339] [G loss: 0.689979]\n",
      "[Epoch 0/2] [Batch 661/938] [D loss: 0.685517] [G loss: 0.683631]\n",
      "[Epoch 0/2] [Batch 662/938] [D loss: 0.691186] [G loss: 0.679416]\n",
      "[Epoch 0/2] [Batch 663/938] [D loss: 0.689532] [G loss: 0.680072]\n",
      "[Epoch 0/2] [Batch 664/938] [D loss: 0.693379] [G loss: 0.687497]\n",
      "[Epoch 0/2] [Batch 665/938] [D loss: 0.692966] [G loss: 0.688225]\n",
      "[Epoch 0/2] [Batch 666/938] [D loss: 0.695307] [G loss: 0.677359]\n",
      "[Epoch 0/2] [Batch 667/938] [D loss: 0.703382] [G loss: 0.678070]\n",
      "[Epoch 0/2] [Batch 668/938] [D loss: 0.703077] [G loss: 0.689620]\n",
      "[Epoch 0/2] [Batch 669/938] [D loss: 0.698765] [G loss: 0.690869]\n",
      "[Epoch 0/2] [Batch 670/938] [D loss: 0.697075] [G loss: 0.698726]\n",
      "[Epoch 0/2] [Batch 671/938] [D loss: 0.692215] [G loss: 0.706003]\n",
      "[Epoch 0/2] [Batch 672/938] [D loss: 0.691385] [G loss: 0.706719]\n",
      "[Epoch 0/2] [Batch 673/938] [D loss: 0.692235] [G loss: 0.715148]\n",
      "[Epoch 0/2] [Batch 674/938] [D loss: 0.692971] [G loss: 0.709902]\n",
      "[Epoch 0/2] [Batch 675/938] [D loss: 0.687895] [G loss: 0.710051]\n",
      "[Epoch 0/2] [Batch 676/938] [D loss: 0.688740] [G loss: 0.706783]\n",
      "[Epoch 0/2] [Batch 677/938] [D loss: 0.689048] [G loss: 0.699717]\n",
      "[Epoch 0/2] [Batch 678/938] [D loss: 0.688249] [G loss: 0.687701]\n",
      "[Epoch 0/2] [Batch 679/938] [D loss: 0.687242] [G loss: 0.683614]\n",
      "[Epoch 0/2] [Batch 680/938] [D loss: 0.685867] [G loss: 0.682195]\n",
      "[Epoch 0/2] [Batch 681/938] [D loss: 0.690333] [G loss: 0.671550]\n",
      "[Epoch 0/2] [Batch 682/938] [D loss: 0.692211] [G loss: 0.670885]\n",
      "[Epoch 0/2] [Batch 683/938] [D loss: 0.690349] [G loss: 0.666723]\n",
      "[Epoch 0/2] [Batch 684/938] [D loss: 0.691234] [G loss: 0.664313]\n",
      "[Epoch 0/2] [Batch 685/938] [D loss: 0.693537] [G loss: 0.666147]\n",
      "[Epoch 0/2] [Batch 686/938] [D loss: 0.700308] [G loss: 0.666228]\n",
      "[Epoch 0/2] [Batch 687/938] [D loss: 0.697137] [G loss: 0.680831]\n",
      "[Epoch 0/2] [Batch 688/938] [D loss: 0.697956] [G loss: 0.688313]\n",
      "[Epoch 0/2] [Batch 689/938] [D loss: 0.698911] [G loss: 0.701705]\n",
      "[Epoch 0/2] [Batch 690/938] [D loss: 0.696598] [G loss: 0.705352]\n",
      "[Epoch 0/2] [Batch 691/938] [D loss: 0.695628] [G loss: 0.717497]\n",
      "[Epoch 0/2] [Batch 692/938] [D loss: 0.693368] [G loss: 0.723519]\n",
      "[Epoch 0/2] [Batch 693/938] [D loss: 0.689734] [G loss: 0.722789]\n",
      "[Epoch 0/2] [Batch 694/938] [D loss: 0.691692] [G loss: 0.728128]\n",
      "[Epoch 0/2] [Batch 695/938] [D loss: 0.688902] [G loss: 0.725523]\n",
      "[Epoch 0/2] [Batch 696/938] [D loss: 0.692671] [G loss: 0.721711]\n",
      "[Epoch 0/2] [Batch 697/938] [D loss: 0.690938] [G loss: 0.725091]\n",
      "[Epoch 0/2] [Batch 698/938] [D loss: 0.688861] [G loss: 0.719676]\n",
      "[Epoch 0/2] [Batch 699/938] [D loss: 0.688546] [G loss: 0.722143]\n",
      "[Epoch 0/2] [Batch 700/938] [D loss: 0.691551] [G loss: 0.712895]\n",
      "[Epoch 0/2] [Batch 701/938] [D loss: 0.690836] [G loss: 0.711445]\n",
      "[Epoch 0/2] [Batch 702/938] [D loss: 0.688334] [G loss: 0.707373]\n",
      "[Epoch 0/2] [Batch 703/938] [D loss: 0.690191] [G loss: 0.705024]\n",
      "[Epoch 0/2] [Batch 704/938] [D loss: 0.689212] [G loss: 0.690653]\n",
      "[Epoch 0/2] [Batch 705/938] [D loss: 0.689627] [G loss: 0.692936]\n",
      "[Epoch 0/2] [Batch 706/938] [D loss: 0.691336] [G loss: 0.684108]\n",
      "[Epoch 0/2] [Batch 707/938] [D loss: 0.692552] [G loss: 0.675638]\n",
      "[Epoch 0/2] [Batch 708/938] [D loss: 0.695004] [G loss: 0.675375]\n",
      "[Epoch 0/2] [Batch 709/938] [D loss: 0.696465] [G loss: 0.674570]\n",
      "[Epoch 0/2] [Batch 710/938] [D loss: 0.691384] [G loss: 0.667414]\n",
      "[Epoch 0/2] [Batch 711/938] [D loss: 0.696370] [G loss: 0.677831]\n",
      "[Epoch 0/2] [Batch 712/938] [D loss: 0.696819] [G loss: 0.687954]\n",
      "[Epoch 0/2] [Batch 713/938] [D loss: 0.691568] [G loss: 0.691567]\n",
      "[Epoch 0/2] [Batch 714/938] [D loss: 0.693849] [G loss: 0.696894]\n",
      "[Epoch 0/2] [Batch 715/938] [D loss: 0.694233] [G loss: 0.707207]\n",
      "[Epoch 0/2] [Batch 716/938] [D loss: 0.691104] [G loss: 0.709461]\n",
      "[Epoch 0/2] [Batch 717/938] [D loss: 0.689602] [G loss: 0.712868]\n",
      "[Epoch 0/2] [Batch 718/938] [D loss: 0.691444] [G loss: 0.714480]\n",
      "[Epoch 0/2] [Batch 719/938] [D loss: 0.690549] [G loss: 0.707304]\n",
      "[Epoch 0/2] [Batch 720/938] [D loss: 0.693299] [G loss: 0.704253]\n",
      "[Epoch 0/2] [Batch 721/938] [D loss: 0.690973] [G loss: 0.702008]\n",
      "[Epoch 0/2] [Batch 722/938] [D loss: 0.694719] [G loss: 0.693867]\n",
      "[Epoch 0/2] [Batch 723/938] [D loss: 0.692677] [G loss: 0.694455]\n",
      "[Epoch 0/2] [Batch 724/938] [D loss: 0.693180] [G loss: 0.691432]\n",
      "[Epoch 0/2] [Batch 725/938] [D loss: 0.692701] [G loss: 0.692614]\n",
      "[Epoch 0/2] [Batch 726/938] [D loss: 0.692636] [G loss: 0.691777]\n",
      "[Epoch 0/2] [Batch 727/938] [D loss: 0.690029] [G loss: 0.688569]\n",
      "[Epoch 0/2] [Batch 728/938] [D loss: 0.689454] [G loss: 0.687579]\n",
      "[Epoch 0/2] [Batch 729/938] [D loss: 0.688159] [G loss: 0.687731]\n",
      "[Epoch 0/2] [Batch 730/938] [D loss: 0.690729] [G loss: 0.682405]\n",
      "[Epoch 0/2] [Batch 731/938] [D loss: 0.690416] [G loss: 0.686893]\n",
      "[Epoch 0/2] [Batch 732/938] [D loss: 0.690642] [G loss: 0.692700]\n",
      "[Epoch 0/2] [Batch 733/938] [D loss: 0.691109] [G loss: 0.691070]\n",
      "[Epoch 0/2] [Batch 734/938] [D loss: 0.695569] [G loss: 0.692129]\n",
      "[Epoch 0/2] [Batch 735/938] [D loss: 0.692994] [G loss: 0.708934]\n",
      "[Epoch 0/2] [Batch 736/938] [D loss: 0.691031] [G loss: 0.724216]\n",
      "[Epoch 0/2] [Batch 737/938] [D loss: 0.691409] [G loss: 0.720026]\n",
      "[Epoch 0/2] [Batch 738/938] [D loss: 0.694158] [G loss: 0.720731]\n",
      "[Epoch 0/2] [Batch 739/938] [D loss: 0.691824] [G loss: 0.720289]\n",
      "[Epoch 0/2] [Batch 740/938] [D loss: 0.692016] [G loss: 0.708813]\n",
      "[Epoch 0/2] [Batch 741/938] [D loss: 0.690769] [G loss: 0.709572]\n",
      "[Epoch 0/2] [Batch 742/938] [D loss: 0.691720] [G loss: 0.704264]\n",
      "[Epoch 0/2] [Batch 743/938] [D loss: 0.692130] [G loss: 0.697911]\n",
      "[Epoch 0/2] [Batch 744/938] [D loss: 0.690914] [G loss: 0.685074]\n",
      "[Epoch 0/2] [Batch 745/938] [D loss: 0.690514] [G loss: 0.689633]\n",
      "[Epoch 0/2] [Batch 746/938] [D loss: 0.689286] [G loss: 0.679602]\n",
      "[Epoch 0/2] [Batch 747/938] [D loss: 0.691387] [G loss: 0.681259]\n",
      "[Epoch 0/2] [Batch 748/938] [D loss: 0.692750] [G loss: 0.683947]\n",
      "[Epoch 0/2] [Batch 749/938] [D loss: 0.693498] [G loss: 0.676839]\n",
      "[Epoch 0/2] [Batch 750/938] [D loss: 0.692139] [G loss: 0.680694]\n",
      "[Epoch 0/2] [Batch 751/938] [D loss: 0.692607] [G loss: 0.688255]\n",
      "[Epoch 0/2] [Batch 752/938] [D loss: 0.693108] [G loss: 0.689316]\n",
      "[Epoch 0/2] [Batch 753/938] [D loss: 0.693884] [G loss: 0.700834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 754/938] [D loss: 0.692811] [G loss: 0.705539]\n",
      "[Epoch 0/2] [Batch 755/938] [D loss: 0.691009] [G loss: 0.707563]\n",
      "[Epoch 0/2] [Batch 756/938] [D loss: 0.687585] [G loss: 0.711134]\n",
      "[Epoch 0/2] [Batch 757/938] [D loss: 0.691977] [G loss: 0.711064]\n",
      "[Epoch 0/2] [Batch 758/938] [D loss: 0.691649] [G loss: 0.712881]\n",
      "[Epoch 0/2] [Batch 759/938] [D loss: 0.691981] [G loss: 0.707366]\n",
      "[Epoch 0/2] [Batch 760/938] [D loss: 0.695382] [G loss: 0.711961]\n",
      "[Epoch 0/2] [Batch 761/938] [D loss: 0.690951] [G loss: 0.707172]\n",
      "[Epoch 0/2] [Batch 762/938] [D loss: 0.688673] [G loss: 0.706280]\n",
      "[Epoch 0/2] [Batch 763/938] [D loss: 0.694103] [G loss: 0.703980]\n",
      "[Epoch 0/2] [Batch 764/938] [D loss: 0.686460] [G loss: 0.694805]\n",
      "[Epoch 0/2] [Batch 765/938] [D loss: 0.684785] [G loss: 0.696292]\n",
      "[Epoch 0/2] [Batch 766/938] [D loss: 0.692623] [G loss: 0.688782]\n",
      "[Epoch 0/2] [Batch 767/938] [D loss: 0.684621] [G loss: 0.684708]\n",
      "[Epoch 0/2] [Batch 768/938] [D loss: 0.695506] [G loss: 0.680030]\n",
      "[Epoch 0/2] [Batch 769/938] [D loss: 0.687871] [G loss: 0.696842]\n",
      "[Epoch 0/2] [Batch 770/938] [D loss: 0.698347] [G loss: 0.689869]\n",
      "[Epoch 0/2] [Batch 771/938] [D loss: 0.697942] [G loss: 0.705039]\n",
      "[Epoch 0/2] [Batch 772/938] [D loss: 0.700190] [G loss: 0.711519]\n",
      "[Epoch 0/2] [Batch 773/938] [D loss: 0.699801] [G loss: 0.710760]\n",
      "[Epoch 0/2] [Batch 774/938] [D loss: 0.694782] [G loss: 0.711122]\n",
      "[Epoch 0/2] [Batch 775/938] [D loss: 0.690197] [G loss: 0.711832]\n",
      "[Epoch 0/2] [Batch 776/938] [D loss: 0.691408] [G loss: 0.710252]\n",
      "[Epoch 0/2] [Batch 777/938] [D loss: 0.692720] [G loss: 0.709569]\n",
      "[Epoch 0/2] [Batch 778/938] [D loss: 0.689565] [G loss: 0.705281]\n",
      "[Epoch 0/2] [Batch 779/938] [D loss: 0.692154] [G loss: 0.698013]\n",
      "[Epoch 0/2] [Batch 780/938] [D loss: 0.686752] [G loss: 0.699024]\n",
      "[Epoch 0/2] [Batch 781/938] [D loss: 0.688366] [G loss: 0.686476]\n",
      "[Epoch 0/2] [Batch 782/938] [D loss: 0.685722] [G loss: 0.684233]\n",
      "[Epoch 0/2] [Batch 783/938] [D loss: 0.690735] [G loss: 0.682659]\n",
      "[Epoch 0/2] [Batch 784/938] [D loss: 0.690895] [G loss: 0.687208]\n",
      "[Epoch 0/2] [Batch 785/938] [D loss: 0.694999] [G loss: 0.700195]\n",
      "[Epoch 0/2] [Batch 786/938] [D loss: 0.687965] [G loss: 0.713915]\n",
      "[Epoch 0/2] [Batch 787/938] [D loss: 0.684918] [G loss: 0.710384]\n",
      "[Epoch 0/2] [Batch 788/938] [D loss: 0.692341] [G loss: 0.705968]\n",
      "[Epoch 0/2] [Batch 789/938] [D loss: 0.697805] [G loss: 0.697437]\n",
      "[Epoch 0/2] [Batch 790/938] [D loss: 0.697465] [G loss: 0.694822]\n",
      "[Epoch 0/2] [Batch 791/938] [D loss: 0.697424] [G loss: 0.683722]\n",
      "[Epoch 0/2] [Batch 792/938] [D loss: 0.690731] [G loss: 0.676818]\n",
      "[Epoch 0/2] [Batch 793/938] [D loss: 0.693503] [G loss: 0.673908]\n",
      "[Epoch 0/2] [Batch 794/938] [D loss: 0.696072] [G loss: 0.670546]\n",
      "[Epoch 0/2] [Batch 795/938] [D loss: 0.694177] [G loss: 0.677740]\n",
      "[Epoch 0/2] [Batch 796/938] [D loss: 0.695241] [G loss: 0.676118]\n",
      "[Epoch 0/2] [Batch 797/938] [D loss: 0.692180] [G loss: 0.683566]\n",
      "[Epoch 0/2] [Batch 798/938] [D loss: 0.687907] [G loss: 0.684100]\n",
      "[Epoch 0/2] [Batch 799/938] [D loss: 0.689881] [G loss: 0.679855]\n",
      "[Epoch 0/2] [Batch 800/938] [D loss: 0.690366] [G loss: 0.696464]\n",
      "[Epoch 0/2] [Batch 801/938] [D loss: 0.685983] [G loss: 0.707831]\n",
      "[Epoch 0/2] [Batch 802/938] [D loss: 0.683369] [G loss: 0.710154]\n",
      "[Epoch 0/2] [Batch 803/938] [D loss: 0.683068] [G loss: 0.699246]\n",
      "[Epoch 0/2] [Batch 804/938] [D loss: 0.691649] [G loss: 0.695421]\n",
      "[Epoch 0/2] [Batch 805/938] [D loss: 0.696045] [G loss: 0.681969]\n",
      "[Epoch 0/2] [Batch 806/938] [D loss: 0.697611] [G loss: 0.683250]\n",
      "[Epoch 0/2] [Batch 807/938] [D loss: 0.693833] [G loss: 0.678827]\n",
      "[Epoch 0/2] [Batch 808/938] [D loss: 0.695286] [G loss: 0.682477]\n",
      "[Epoch 0/2] [Batch 809/938] [D loss: 0.694810] [G loss: 0.687733]\n",
      "[Epoch 0/2] [Batch 810/938] [D loss: 0.690921] [G loss: 0.684735]\n",
      "[Epoch 0/2] [Batch 811/938] [D loss: 0.689646] [G loss: 0.676718]\n",
      "[Epoch 0/2] [Batch 812/938] [D loss: 0.689448] [G loss: 0.684871]\n",
      "[Epoch 0/2] [Batch 813/938] [D loss: 0.689471] [G loss: 0.689063]\n",
      "[Epoch 0/2] [Batch 814/938] [D loss: 0.696878] [G loss: 0.704074]\n",
      "[Epoch 0/2] [Batch 815/938] [D loss: 0.690028] [G loss: 0.717756]\n",
      "[Epoch 0/2] [Batch 816/938] [D loss: 0.692282] [G loss: 0.730083]\n",
      "[Epoch 0/2] [Batch 817/938] [D loss: 0.685702] [G loss: 0.748819]\n",
      "[Epoch 0/2] [Batch 818/938] [D loss: 0.685860] [G loss: 0.753474]\n",
      "[Epoch 0/2] [Batch 819/938] [D loss: 0.692351] [G loss: 0.752115]\n",
      "[Epoch 0/2] [Batch 820/938] [D loss: 0.690932] [G loss: 0.734410]\n",
      "[Epoch 0/2] [Batch 821/938] [D loss: 0.692332] [G loss: 0.718655]\n",
      "[Epoch 0/2] [Batch 822/938] [D loss: 0.699126] [G loss: 0.707056]\n",
      "[Epoch 0/2] [Batch 823/938] [D loss: 0.701527] [G loss: 0.699225]\n",
      "[Epoch 0/2] [Batch 824/938] [D loss: 0.693219] [G loss: 0.689055]\n",
      "[Epoch 0/2] [Batch 825/938] [D loss: 0.696953] [G loss: 0.682706]\n",
      "[Epoch 0/2] [Batch 826/938] [D loss: 0.691615] [G loss: 0.674485]\n",
      "[Epoch 0/2] [Batch 827/938] [D loss: 0.691221] [G loss: 0.677536]\n",
      "[Epoch 0/2] [Batch 828/938] [D loss: 0.691543] [G loss: 0.685665]\n",
      "[Epoch 0/2] [Batch 829/938] [D loss: 0.695905] [G loss: 0.691821]\n",
      "[Epoch 0/2] [Batch 830/938] [D loss: 0.693931] [G loss: 0.701271]\n",
      "[Epoch 0/2] [Batch 831/938] [D loss: 0.692979] [G loss: 0.706275]\n",
      "[Epoch 0/2] [Batch 832/938] [D loss: 0.693768] [G loss: 0.704936]\n",
      "[Epoch 0/2] [Batch 833/938] [D loss: 0.690777] [G loss: 0.704563]\n",
      "[Epoch 0/2] [Batch 834/938] [D loss: 0.693849] [G loss: 0.712077]\n",
      "[Epoch 0/2] [Batch 835/938] [D loss: 0.689464] [G loss: 0.711303]\n",
      "[Epoch 0/2] [Batch 836/938] [D loss: 0.690439] [G loss: 0.713941]\n",
      "[Epoch 0/2] [Batch 837/938] [D loss: 0.688764] [G loss: 0.702198]\n",
      "[Epoch 0/2] [Batch 838/938] [D loss: 0.685482] [G loss: 0.701409]\n",
      "[Epoch 0/2] [Batch 839/938] [D loss: 0.688823] [G loss: 0.697831]\n",
      "[Epoch 0/2] [Batch 840/938] [D loss: 0.686596] [G loss: 0.688998]\n",
      "[Epoch 0/2] [Batch 841/938] [D loss: 0.689063] [G loss: 0.683494]\n",
      "[Epoch 0/2] [Batch 842/938] [D loss: 0.696134] [G loss: 0.683254]\n",
      "[Epoch 0/2] [Batch 843/938] [D loss: 0.688470] [G loss: 0.686173]\n",
      "[Epoch 0/2] [Batch 844/938] [D loss: 0.693298] [G loss: 0.686096]\n",
      "[Epoch 0/2] [Batch 845/938] [D loss: 0.692620] [G loss: 0.689367]\n",
      "[Epoch 0/2] [Batch 846/938] [D loss: 0.700497] [G loss: 0.692372]\n",
      "[Epoch 0/2] [Batch 847/938] [D loss: 0.692170] [G loss: 0.696953]\n",
      "[Epoch 0/2] [Batch 848/938] [D loss: 0.697331] [G loss: 0.690931]\n",
      "[Epoch 0/2] [Batch 849/938] [D loss: 0.692566] [G loss: 0.692483]\n",
      "[Epoch 0/2] [Batch 850/938] [D loss: 0.689628] [G loss: 0.704872]\n",
      "[Epoch 0/2] [Batch 851/938] [D loss: 0.692353] [G loss: 0.697138]\n",
      "[Epoch 0/2] [Batch 852/938] [D loss: 0.690901] [G loss: 0.697967]\n",
      "[Epoch 0/2] [Batch 853/938] [D loss: 0.688385] [G loss: 0.701502]\n",
      "[Epoch 0/2] [Batch 854/938] [D loss: 0.689092] [G loss: 0.700495]\n",
      "[Epoch 0/2] [Batch 855/938] [D loss: 0.685212] [G loss: 0.707642]\n",
      "[Epoch 0/2] [Batch 856/938] [D loss: 0.686749] [G loss: 0.697149]\n",
      "[Epoch 0/2] [Batch 857/938] [D loss: 0.688528] [G loss: 0.692560]\n",
      "[Epoch 0/2] [Batch 858/938] [D loss: 0.686730] [G loss: 0.679893]\n",
      "[Epoch 0/2] [Batch 859/938] [D loss: 0.688524] [G loss: 0.687382]\n",
      "[Epoch 0/2] [Batch 860/938] [D loss: 0.683845] [G loss: 0.696158]\n",
      "[Epoch 0/2] [Batch 861/938] [D loss: 0.685379] [G loss: 0.710248]\n",
      "[Epoch 0/2] [Batch 862/938] [D loss: 0.689893] [G loss: 0.702497]\n",
      "[Epoch 0/2] [Batch 863/938] [D loss: 0.688253] [G loss: 0.696416]\n",
      "[Epoch 0/2] [Batch 864/938] [D loss: 0.690608] [G loss: 0.690174]\n",
      "[Epoch 0/2] [Batch 865/938] [D loss: 0.688105] [G loss: 0.684758]\n",
      "[Epoch 0/2] [Batch 866/938] [D loss: 0.690607] [G loss: 0.685419]\n",
      "[Epoch 0/2] [Batch 867/938] [D loss: 0.694508] [G loss: 0.689127]\n",
      "[Epoch 0/2] [Batch 868/938] [D loss: 0.687961] [G loss: 0.686716]\n",
      "[Epoch 0/2] [Batch 869/938] [D loss: 0.694056] [G loss: 0.693983]\n",
      "[Epoch 0/2] [Batch 870/938] [D loss: 0.697224] [G loss: 0.701281]\n",
      "[Epoch 0/2] [Batch 871/938] [D loss: 0.694090] [G loss: 0.702461]\n",
      "[Epoch 0/2] [Batch 872/938] [D loss: 0.695008] [G loss: 0.720963]\n",
      "[Epoch 0/2] [Batch 873/938] [D loss: 0.688493] [G loss: 0.709959]\n",
      "[Epoch 0/2] [Batch 874/938] [D loss: 0.687663] [G loss: 0.711894]\n",
      "[Epoch 0/2] [Batch 875/938] [D loss: 0.685290] [G loss: 0.693046]\n",
      "[Epoch 0/2] [Batch 876/938] [D loss: 0.690173] [G loss: 0.679405]\n",
      "[Epoch 0/2] [Batch 877/938] [D loss: 0.690954] [G loss: 0.684003]\n",
      "[Epoch 0/2] [Batch 878/938] [D loss: 0.698741] [G loss: 0.672244]\n",
      "[Epoch 0/2] [Batch 879/938] [D loss: 0.693515] [G loss: 0.680904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 880/938] [D loss: 0.689834] [G loss: 0.690530]\n",
      "[Epoch 0/2] [Batch 881/938] [D loss: 0.691459] [G loss: 0.688550]\n",
      "[Epoch 0/2] [Batch 882/938] [D loss: 0.684491] [G loss: 0.705864]\n",
      "[Epoch 0/2] [Batch 883/938] [D loss: 0.689260] [G loss: 0.682401]\n",
      "[Epoch 0/2] [Batch 884/938] [D loss: 0.695075] [G loss: 0.691271]\n",
      "[Epoch 0/2] [Batch 885/938] [D loss: 0.697188] [G loss: 0.700683]\n",
      "[Epoch 0/2] [Batch 886/938] [D loss: 0.693294] [G loss: 0.722101]\n",
      "[Epoch 0/2] [Batch 887/938] [D loss: 0.688094] [G loss: 0.720080]\n",
      "[Epoch 0/2] [Batch 888/938] [D loss: 0.693996] [G loss: 0.725306]\n",
      "[Epoch 0/2] [Batch 889/938] [D loss: 0.696645] [G loss: 0.714883]\n",
      "[Epoch 0/2] [Batch 890/938] [D loss: 0.687518] [G loss: 0.714030]\n",
      "[Epoch 0/2] [Batch 891/938] [D loss: 0.695568] [G loss: 0.711142]\n",
      "[Epoch 0/2] [Batch 892/938] [D loss: 0.685470] [G loss: 0.706918]\n",
      "[Epoch 0/2] [Batch 893/938] [D loss: 0.687463] [G loss: 0.707679]\n",
      "[Epoch 0/2] [Batch 894/938] [D loss: 0.686889] [G loss: 0.704934]\n",
      "[Epoch 0/2] [Batch 895/938] [D loss: 0.689522] [G loss: 0.693880]\n",
      "[Epoch 0/2] [Batch 896/938] [D loss: 0.686479] [G loss: 0.682124]\n",
      "[Epoch 0/2] [Batch 897/938] [D loss: 0.692615] [G loss: 0.689749]\n",
      "[Epoch 0/2] [Batch 898/938] [D loss: 0.684195] [G loss: 0.694731]\n",
      "[Epoch 0/2] [Batch 899/938] [D loss: 0.693059] [G loss: 0.679955]\n",
      "[Epoch 0/2] [Batch 900/938] [D loss: 0.691647] [G loss: 0.701633]\n",
      "[Epoch 0/2] [Batch 901/938] [D loss: 0.679447] [G loss: 0.705767]\n",
      "[Epoch 0/2] [Batch 902/938] [D loss: 0.686927] [G loss: 0.713438]\n",
      "[Epoch 0/2] [Batch 903/938] [D loss: 0.686895] [G loss: 0.707316]\n",
      "[Epoch 0/2] [Batch 904/938] [D loss: 0.686536] [G loss: 0.713709]\n",
      "[Epoch 0/2] [Batch 905/938] [D loss: 0.692045] [G loss: 0.704224]\n",
      "[Epoch 0/2] [Batch 906/938] [D loss: 0.695287] [G loss: 0.705869]\n",
      "[Epoch 0/2] [Batch 907/938] [D loss: 0.688059] [G loss: 0.703370]\n",
      "[Epoch 0/2] [Batch 908/938] [D loss: 0.690562] [G loss: 0.699345]\n",
      "[Epoch 0/2] [Batch 909/938] [D loss: 0.684222] [G loss: 0.695239]\n",
      "[Epoch 0/2] [Batch 910/938] [D loss: 0.693604] [G loss: 0.684381]\n",
      "[Epoch 0/2] [Batch 911/938] [D loss: 0.695445] [G loss: 0.687550]\n",
      "[Epoch 0/2] [Batch 912/938] [D loss: 0.695566] [G loss: 0.693932]\n",
      "[Epoch 0/2] [Batch 913/938] [D loss: 0.691803] [G loss: 0.705247]\n",
      "[Epoch 0/2] [Batch 914/938] [D loss: 0.692394] [G loss: 0.725175]\n",
      "[Epoch 0/2] [Batch 915/938] [D loss: 0.688393] [G loss: 0.721326]\n",
      "[Epoch 0/2] [Batch 916/938] [D loss: 0.684386] [G loss: 0.705536]\n",
      "[Epoch 0/2] [Batch 917/938] [D loss: 0.690009] [G loss: 0.710420]\n",
      "[Epoch 0/2] [Batch 918/938] [D loss: 0.690402] [G loss: 0.712007]\n",
      "[Epoch 0/2] [Batch 919/938] [D loss: 0.700120] [G loss: 0.689673]\n",
      "[Epoch 0/2] [Batch 920/938] [D loss: 0.698327] [G loss: 0.708745]\n",
      "[Epoch 0/2] [Batch 921/938] [D loss: 0.706097] [G loss: 0.708728]\n",
      "[Epoch 0/2] [Batch 922/938] [D loss: 0.684826] [G loss: 0.711025]\n",
      "[Epoch 0/2] [Batch 923/938] [D loss: 0.690021] [G loss: 0.700499]\n",
      "[Epoch 0/2] [Batch 924/938] [D loss: 0.691374] [G loss: 0.701623]\n",
      "[Epoch 0/2] [Batch 925/938] [D loss: 0.688580] [G loss: 0.706466]\n",
      "[Epoch 0/2] [Batch 926/938] [D loss: 0.691258] [G loss: 0.706084]\n",
      "[Epoch 0/2] [Batch 927/938] [D loss: 0.689949] [G loss: 0.708384]\n",
      "[Epoch 0/2] [Batch 928/938] [D loss: 0.692118] [G loss: 0.719194]\n",
      "[Epoch 0/2] [Batch 929/938] [D loss: 0.691094] [G loss: 0.722383]\n",
      "[Epoch 0/2] [Batch 930/938] [D loss: 0.686648] [G loss: 0.709046]\n",
      "[Epoch 0/2] [Batch 931/938] [D loss: 0.693346] [G loss: 0.703503]\n",
      "[Epoch 0/2] [Batch 932/938] [D loss: 0.684644] [G loss: 0.713198]\n",
      "[Epoch 0/2] [Batch 933/938] [D loss: 0.686154] [G loss: 0.689550]\n",
      "[Epoch 0/2] [Batch 934/938] [D loss: 0.682770] [G loss: 0.699627]\n",
      "[Epoch 0/2] [Batch 935/938] [D loss: 0.687729] [G loss: 0.701228]\n",
      "[Epoch 0/2] [Batch 936/938] [D loss: 0.690804] [G loss: 0.695497]\n",
      "[Epoch 0/2] [Batch 937/938] [D loss: 0.677596] [G loss: 0.706431]\n",
      "[Epoch 1/2] [Batch 0/938] [D loss: 0.683492] [G loss: 0.692812]\n",
      "[Epoch 1/2] [Batch 1/938] [D loss: 0.681750] [G loss: 0.687911]\n",
      "[Epoch 1/2] [Batch 2/938] [D loss: 0.687695] [G loss: 0.688294]\n",
      "[Epoch 1/2] [Batch 3/938] [D loss: 0.692915] [G loss: 0.692462]\n",
      "[Epoch 1/2] [Batch 4/938] [D loss: 0.690235] [G loss: 0.711937]\n",
      "[Epoch 1/2] [Batch 5/938] [D loss: 0.691543] [G loss: 0.711165]\n",
      "[Epoch 1/2] [Batch 6/938] [D loss: 0.686003] [G loss: 0.703688]\n",
      "[Epoch 1/2] [Batch 7/938] [D loss: 0.702021] [G loss: 0.700934]\n",
      "[Epoch 1/2] [Batch 8/938] [D loss: 0.691478] [G loss: 0.706900]\n",
      "[Epoch 1/2] [Batch 9/938] [D loss: 0.688965] [G loss: 0.698222]\n",
      "[Epoch 1/2] [Batch 10/938] [D loss: 0.686469] [G loss: 0.683534]\n",
      "[Epoch 1/2] [Batch 11/938] [D loss: 0.690610] [G loss: 0.689092]\n",
      "[Epoch 1/2] [Batch 12/938] [D loss: 0.689017] [G loss: 0.692586]\n",
      "[Epoch 1/2] [Batch 13/938] [D loss: 0.685878] [G loss: 0.697580]\n",
      "[Epoch 1/2] [Batch 14/938] [D loss: 0.690423] [G loss: 0.693943]\n",
      "[Epoch 1/2] [Batch 15/938] [D loss: 0.692713] [G loss: 0.688471]\n",
      "[Epoch 1/2] [Batch 16/938] [D loss: 0.689405] [G loss: 0.706174]\n",
      "[Epoch 1/2] [Batch 17/938] [D loss: 0.686899] [G loss: 0.705519]\n",
      "[Epoch 1/2] [Batch 18/938] [D loss: 0.686533] [G loss: 0.715008]\n",
      "[Epoch 1/2] [Batch 19/938] [D loss: 0.696299] [G loss: 0.705891]\n",
      "[Epoch 1/2] [Batch 20/938] [D loss: 0.684040] [G loss: 0.697525]\n",
      "[Epoch 1/2] [Batch 21/938] [D loss: 0.687452] [G loss: 0.697362]\n",
      "[Epoch 1/2] [Batch 22/938] [D loss: 0.683813] [G loss: 0.695791]\n",
      "[Epoch 1/2] [Batch 23/938] [D loss: 0.684141] [G loss: 0.684077]\n",
      "[Epoch 1/2] [Batch 24/938] [D loss: 0.690297] [G loss: 0.687472]\n",
      "[Epoch 1/2] [Batch 25/938] [D loss: 0.690176] [G loss: 0.681761]\n",
      "[Epoch 1/2] [Batch 26/938] [D loss: 0.691058] [G loss: 0.683522]\n",
      "[Epoch 1/2] [Batch 27/938] [D loss: 0.679860] [G loss: 0.692966]\n",
      "[Epoch 1/2] [Batch 28/938] [D loss: 0.687483] [G loss: 0.710657]\n",
      "[Epoch 1/2] [Batch 29/938] [D loss: 0.687298] [G loss: 0.707448]\n",
      "[Epoch 1/2] [Batch 30/938] [D loss: 0.689114] [G loss: 0.707138]\n",
      "[Epoch 1/2] [Batch 31/938] [D loss: 0.691111] [G loss: 0.690033]\n",
      "[Epoch 1/2] [Batch 32/938] [D loss: 0.684972] [G loss: 0.688638]\n",
      "[Epoch 1/2] [Batch 33/938] [D loss: 0.690619] [G loss: 0.683313]\n",
      "[Epoch 1/2] [Batch 34/938] [D loss: 0.683556] [G loss: 0.688292]\n",
      "[Epoch 1/2] [Batch 35/938] [D loss: 0.691153] [G loss: 0.713286]\n",
      "[Epoch 1/2] [Batch 36/938] [D loss: 0.700435] [G loss: 0.720327]\n",
      "[Epoch 1/2] [Batch 37/938] [D loss: 0.688955] [G loss: 0.733192]\n",
      "[Epoch 1/2] [Batch 38/938] [D loss: 0.686988] [G loss: 0.736697]\n",
      "[Epoch 1/2] [Batch 39/938] [D loss: 0.692351] [G loss: 0.736318]\n",
      "[Epoch 1/2] [Batch 40/938] [D loss: 0.688301] [G loss: 0.713691]\n",
      "[Epoch 1/2] [Batch 41/938] [D loss: 0.691073] [G loss: 0.707642]\n",
      "[Epoch 1/2] [Batch 42/938] [D loss: 0.687290] [G loss: 0.702687]\n",
      "[Epoch 1/2] [Batch 43/938] [D loss: 0.696621] [G loss: 0.691098]\n",
      "[Epoch 1/2] [Batch 44/938] [D loss: 0.688495] [G loss: 0.701251]\n",
      "[Epoch 1/2] [Batch 45/938] [D loss: 0.689913] [G loss: 0.716712]\n",
      "[Epoch 1/2] [Batch 46/938] [D loss: 0.689918] [G loss: 0.714345]\n",
      "[Epoch 1/2] [Batch 47/938] [D loss: 0.684461] [G loss: 0.741117]\n",
      "[Epoch 1/2] [Batch 48/938] [D loss: 0.686869] [G loss: 0.738509]\n",
      "[Epoch 1/2] [Batch 49/938] [D loss: 0.692133] [G loss: 0.744299]\n",
      "[Epoch 1/2] [Batch 50/938] [D loss: 0.692109] [G loss: 0.749570]\n",
      "[Epoch 1/2] [Batch 51/938] [D loss: 0.699062] [G loss: 0.723191]\n",
      "[Epoch 1/2] [Batch 52/938] [D loss: 0.680235] [G loss: 0.693930]\n",
      "[Epoch 1/2] [Batch 53/938] [D loss: 0.688613] [G loss: 0.669140]\n",
      "[Epoch 1/2] [Batch 54/938] [D loss: 0.686338] [G loss: 0.668613]\n",
      "[Epoch 1/2] [Batch 55/938] [D loss: 0.689862] [G loss: 0.684920]\n",
      "[Epoch 1/2] [Batch 56/938] [D loss: 0.678056] [G loss: 0.726743]\n",
      "[Epoch 1/2] [Batch 57/938] [D loss: 0.689472] [G loss: 0.735730]\n",
      "[Epoch 1/2] [Batch 58/938] [D loss: 0.680208] [G loss: 0.766084]\n",
      "[Epoch 1/2] [Batch 59/938] [D loss: 0.689277] [G loss: 0.745995]\n",
      "[Epoch 1/2] [Batch 60/938] [D loss: 0.695030] [G loss: 0.705070]\n",
      "[Epoch 1/2] [Batch 61/938] [D loss: 0.693450] [G loss: 0.689757]\n",
      "[Epoch 1/2] [Batch 62/938] [D loss: 0.687254] [G loss: 0.671322]\n",
      "[Epoch 1/2] [Batch 63/938] [D loss: 0.695862] [G loss: 0.669688]\n",
      "[Epoch 1/2] [Batch 64/938] [D loss: 0.683411] [G loss: 0.649420]\n",
      "[Epoch 1/2] [Batch 65/938] [D loss: 0.696329] [G loss: 0.678871]\n",
      "[Epoch 1/2] [Batch 66/938] [D loss: 0.692992] [G loss: 0.698194]\n",
      "[Epoch 1/2] [Batch 67/938] [D loss: 0.698144] [G loss: 0.719969]\n",
      "[Epoch 1/2] [Batch 68/938] [D loss: 0.680624] [G loss: 0.755206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 69/938] [D loss: 0.688631] [G loss: 0.766298]\n",
      "[Epoch 1/2] [Batch 70/938] [D loss: 0.685882] [G loss: 0.760917]\n",
      "[Epoch 1/2] [Batch 71/938] [D loss: 0.683797] [G loss: 0.733277]\n",
      "[Epoch 1/2] [Batch 72/938] [D loss: 0.683167] [G loss: 0.690044]\n",
      "[Epoch 1/2] [Batch 73/938] [D loss: 0.684157] [G loss: 0.699670]\n",
      "[Epoch 1/2] [Batch 74/938] [D loss: 0.689336] [G loss: 0.692005]\n",
      "[Epoch 1/2] [Batch 75/938] [D loss: 0.679542] [G loss: 0.670355]\n",
      "[Epoch 1/2] [Batch 76/938] [D loss: 0.679186] [G loss: 0.670285]\n",
      "[Epoch 1/2] [Batch 77/938] [D loss: 0.684321] [G loss: 0.674666]\n",
      "[Epoch 1/2] [Batch 78/938] [D loss: 0.680101] [G loss: 0.700547]\n",
      "[Epoch 1/2] [Batch 79/938] [D loss: 0.674767] [G loss: 0.682305]\n",
      "[Epoch 1/2] [Batch 80/938] [D loss: 0.691028] [G loss: 0.709214]\n",
      "[Epoch 1/2] [Batch 81/938] [D loss: 0.680607] [G loss: 0.716516]\n",
      "[Epoch 1/2] [Batch 82/938] [D loss: 0.669906] [G loss: 0.702670]\n",
      "[Epoch 1/2] [Batch 83/938] [D loss: 0.680099] [G loss: 0.702405]\n",
      "[Epoch 1/2] [Batch 84/938] [D loss: 0.686776] [G loss: 0.686632]\n",
      "[Epoch 1/2] [Batch 85/938] [D loss: 0.683660] [G loss: 0.693775]\n",
      "[Epoch 1/2] [Batch 86/938] [D loss: 0.693398] [G loss: 0.683793]\n",
      "[Epoch 1/2] [Batch 87/938] [D loss: 0.687865] [G loss: 0.708094]\n",
      "[Epoch 1/2] [Batch 88/938] [D loss: 0.694936] [G loss: 0.728989]\n",
      "[Epoch 1/2] [Batch 89/938] [D loss: 0.682552] [G loss: 0.709226]\n",
      "[Epoch 1/2] [Batch 90/938] [D loss: 0.704718] [G loss: 0.707428]\n",
      "[Epoch 1/2] [Batch 91/938] [D loss: 0.683589] [G loss: 0.705988]\n",
      "[Epoch 1/2] [Batch 92/938] [D loss: 0.691217] [G loss: 0.692628]\n",
      "[Epoch 1/2] [Batch 93/938] [D loss: 0.693400] [G loss: 0.684005]\n",
      "[Epoch 1/2] [Batch 94/938] [D loss: 0.691682] [G loss: 0.683042]\n",
      "[Epoch 1/2] [Batch 95/938] [D loss: 0.694065] [G loss: 0.694549]\n",
      "[Epoch 1/2] [Batch 96/938] [D loss: 0.700860] [G loss: 0.733207]\n",
      "[Epoch 1/2] [Batch 97/938] [D loss: 0.695872] [G loss: 0.722674]\n",
      "[Epoch 1/2] [Batch 98/938] [D loss: 0.700137] [G loss: 0.700019]\n",
      "[Epoch 1/2] [Batch 99/938] [D loss: 0.683142] [G loss: 0.713730]\n",
      "[Epoch 1/2] [Batch 100/938] [D loss: 0.691499] [G loss: 0.694004]\n",
      "[Epoch 1/2] [Batch 101/938] [D loss: 0.691442] [G loss: 0.711384]\n",
      "[Epoch 1/2] [Batch 102/938] [D loss: 0.685716] [G loss: 0.697957]\n",
      "[Epoch 1/2] [Batch 103/938] [D loss: 0.693542] [G loss: 0.738721]\n",
      "[Epoch 1/2] [Batch 104/938] [D loss: 0.681596] [G loss: 0.726319]\n",
      "[Epoch 1/2] [Batch 105/938] [D loss: 0.685269] [G loss: 0.743030]\n",
      "[Epoch 1/2] [Batch 106/938] [D loss: 0.683250] [G loss: 0.708492]\n",
      "[Epoch 1/2] [Batch 107/938] [D loss: 0.690754] [G loss: 0.715336]\n",
      "[Epoch 1/2] [Batch 108/938] [D loss: 0.681867] [G loss: 0.712784]\n",
      "[Epoch 1/2] [Batch 109/938] [D loss: 0.677727] [G loss: 0.708104]\n",
      "[Epoch 1/2] [Batch 110/938] [D loss: 0.677126] [G loss: 0.724024]\n",
      "[Epoch 1/2] [Batch 111/938] [D loss: 0.675699] [G loss: 0.730282]\n",
      "[Epoch 1/2] [Batch 112/938] [D loss: 0.681096] [G loss: 0.719338]\n",
      "[Epoch 1/2] [Batch 113/938] [D loss: 0.680269] [G loss: 0.714808]\n",
      "[Epoch 1/2] [Batch 114/938] [D loss: 0.683331] [G loss: 0.712142]\n",
      "[Epoch 1/2] [Batch 115/938] [D loss: 0.701414] [G loss: 0.690835]\n",
      "[Epoch 1/2] [Batch 116/938] [D loss: 0.678350] [G loss: 0.716021]\n",
      "[Epoch 1/2] [Batch 117/938] [D loss: 0.679792] [G loss: 0.696584]\n",
      "[Epoch 1/2] [Batch 118/938] [D loss: 0.703110] [G loss: 0.696900]\n",
      "[Epoch 1/2] [Batch 119/938] [D loss: 0.695292] [G loss: 0.689531]\n",
      "[Epoch 1/2] [Batch 120/938] [D loss: 0.690721] [G loss: 0.703414]\n",
      "[Epoch 1/2] [Batch 121/938] [D loss: 0.698978] [G loss: 0.687512]\n",
      "[Epoch 1/2] [Batch 122/938] [D loss: 0.684509] [G loss: 0.699687]\n",
      "[Epoch 1/2] [Batch 123/938] [D loss: 0.691416] [G loss: 0.706603]\n",
      "[Epoch 1/2] [Batch 124/938] [D loss: 0.686789] [G loss: 0.705745]\n",
      "[Epoch 1/2] [Batch 125/938] [D loss: 0.678259] [G loss: 0.711640]\n",
      "[Epoch 1/2] [Batch 126/938] [D loss: 0.683974] [G loss: 0.702979]\n",
      "[Epoch 1/2] [Batch 127/938] [D loss: 0.675657] [G loss: 0.718962]\n",
      "[Epoch 1/2] [Batch 128/938] [D loss: 0.687960] [G loss: 0.725292]\n",
      "[Epoch 1/2] [Batch 129/938] [D loss: 0.686101] [G loss: 0.725796]\n",
      "[Epoch 1/2] [Batch 130/938] [D loss: 0.684735] [G loss: 0.696280]\n",
      "[Epoch 1/2] [Batch 131/938] [D loss: 0.687213] [G loss: 0.706190]\n",
      "[Epoch 1/2] [Batch 132/938] [D loss: 0.686314] [G loss: 0.699331]\n",
      "[Epoch 1/2] [Batch 133/938] [D loss: 0.676483] [G loss: 0.718726]\n",
      "[Epoch 1/2] [Batch 134/938] [D loss: 0.686732] [G loss: 0.694579]\n",
      "[Epoch 1/2] [Batch 135/938] [D loss: 0.659160] [G loss: 0.709213]\n",
      "[Epoch 1/2] [Batch 136/938] [D loss: 0.697049] [G loss: 0.691770]\n",
      "[Epoch 1/2] [Batch 137/938] [D loss: 0.675158] [G loss: 0.702381]\n",
      "[Epoch 1/2] [Batch 138/938] [D loss: 0.679008] [G loss: 0.709384]\n",
      "[Epoch 1/2] [Batch 139/938] [D loss: 0.672497] [G loss: 0.692826]\n",
      "[Epoch 1/2] [Batch 140/938] [D loss: 0.686385] [G loss: 0.731084]\n",
      "[Epoch 1/2] [Batch 141/938] [D loss: 0.693536] [G loss: 0.701755]\n",
      "[Epoch 1/2] [Batch 142/938] [D loss: 0.679750] [G loss: 0.672911]\n",
      "[Epoch 1/2] [Batch 143/938] [D loss: 0.680129] [G loss: 0.690956]\n",
      "[Epoch 1/2] [Batch 144/938] [D loss: 0.689683] [G loss: 0.690527]\n",
      "[Epoch 1/2] [Batch 145/938] [D loss: 0.688704] [G loss: 0.684307]\n",
      "[Epoch 1/2] [Batch 146/938] [D loss: 0.690684] [G loss: 0.705458]\n",
      "[Epoch 1/2] [Batch 147/938] [D loss: 0.699792] [G loss: 0.726410]\n",
      "[Epoch 1/2] [Batch 148/938] [D loss: 0.685524] [G loss: 0.766121]\n",
      "[Epoch 1/2] [Batch 149/938] [D loss: 0.696021] [G loss: 0.748850]\n",
      "[Epoch 1/2] [Batch 150/938] [D loss: 0.692868] [G loss: 0.719935]\n",
      "[Epoch 1/2] [Batch 151/938] [D loss: 0.691909] [G loss: 0.710707]\n",
      "[Epoch 1/2] [Batch 152/938] [D loss: 0.694806] [G loss: 0.712759]\n",
      "[Epoch 1/2] [Batch 153/938] [D loss: 0.689296] [G loss: 0.710729]\n",
      "[Epoch 1/2] [Batch 154/938] [D loss: 0.682698] [G loss: 0.702001]\n",
      "[Epoch 1/2] [Batch 155/938] [D loss: 0.688065] [G loss: 0.686685]\n",
      "[Epoch 1/2] [Batch 156/938] [D loss: 0.687876] [G loss: 0.702381]\n",
      "[Epoch 1/2] [Batch 157/938] [D loss: 0.705231] [G loss: 0.723799]\n",
      "[Epoch 1/2] [Batch 158/938] [D loss: 0.693865] [G loss: 0.751530]\n",
      "[Epoch 1/2] [Batch 159/938] [D loss: 0.681493] [G loss: 0.753208]\n",
      "[Epoch 1/2] [Batch 160/938] [D loss: 0.678847] [G loss: 0.725368]\n",
      "[Epoch 1/2] [Batch 161/938] [D loss: 0.674897] [G loss: 0.740529]\n",
      "[Epoch 1/2] [Batch 162/938] [D loss: 0.688579] [G loss: 0.735987]\n",
      "[Epoch 1/2] [Batch 163/938] [D loss: 0.688839] [G loss: 0.724099]\n",
      "[Epoch 1/2] [Batch 164/938] [D loss: 0.685768] [G loss: 0.732524]\n",
      "[Epoch 1/2] [Batch 165/938] [D loss: 0.682160] [G loss: 0.692519]\n",
      "[Epoch 1/2] [Batch 166/938] [D loss: 0.680209] [G loss: 0.690046]\n",
      "[Epoch 1/2] [Batch 167/938] [D loss: 0.700005] [G loss: 0.712824]\n",
      "[Epoch 1/2] [Batch 168/938] [D loss: 0.692727] [G loss: 0.704314]\n",
      "[Epoch 1/2] [Batch 169/938] [D loss: 0.689885] [G loss: 0.717083]\n",
      "[Epoch 1/2] [Batch 170/938] [D loss: 0.693344] [G loss: 0.700514]\n",
      "[Epoch 1/2] [Batch 171/938] [D loss: 0.679049] [G loss: 0.700907]\n",
      "[Epoch 1/2] [Batch 172/938] [D loss: 0.696739] [G loss: 0.697024]\n",
      "[Epoch 1/2] [Batch 173/938] [D loss: 0.680083] [G loss: 0.685341]\n",
      "[Epoch 1/2] [Batch 174/938] [D loss: 0.677483] [G loss: 0.685062]\n",
      "[Epoch 1/2] [Batch 175/938] [D loss: 0.687809] [G loss: 0.671557]\n",
      "[Epoch 1/2] [Batch 176/938] [D loss: 0.692214] [G loss: 0.706670]\n",
      "[Epoch 1/2] [Batch 177/938] [D loss: 0.681764] [G loss: 0.684414]\n",
      "[Epoch 1/2] [Batch 178/938] [D loss: 0.680300] [G loss: 0.690106]\n",
      "[Epoch 1/2] [Batch 179/938] [D loss: 0.693856] [G loss: 0.706437]\n",
      "[Epoch 1/2] [Batch 180/938] [D loss: 0.681005] [G loss: 0.716435]\n",
      "[Epoch 1/2] [Batch 181/938] [D loss: 0.681918] [G loss: 0.696340]\n",
      "[Epoch 1/2] [Batch 182/938] [D loss: 0.680005] [G loss: 0.678227]\n",
      "[Epoch 1/2] [Batch 183/938] [D loss: 0.669977] [G loss: 0.684455]\n",
      "[Epoch 1/2] [Batch 184/938] [D loss: 0.680443] [G loss: 0.686300]\n",
      "[Epoch 1/2] [Batch 185/938] [D loss: 0.685986] [G loss: 0.709793]\n",
      "[Epoch 1/2] [Batch 186/938] [D loss: 0.685469] [G loss: 0.712069]\n",
      "[Epoch 1/2] [Batch 187/938] [D loss: 0.674696] [G loss: 0.721084]\n",
      "[Epoch 1/2] [Batch 188/938] [D loss: 0.673298] [G loss: 0.707844]\n",
      "[Epoch 1/2] [Batch 189/938] [D loss: 0.679914] [G loss: 0.711485]\n",
      "[Epoch 1/2] [Batch 190/938] [D loss: 0.677150] [G loss: 0.687098]\n",
      "[Epoch 1/2] [Batch 191/938] [D loss: 0.679132] [G loss: 0.684513]\n",
      "[Epoch 1/2] [Batch 192/938] [D loss: 0.686927] [G loss: 0.696658]\n",
      "[Epoch 1/2] [Batch 193/938] [D loss: 0.676262] [G loss: 0.704996]\n",
      "[Epoch 1/2] [Batch 194/938] [D loss: 0.678625] [G loss: 0.709310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 195/938] [D loss: 0.678310] [G loss: 0.762215]\n",
      "[Epoch 1/2] [Batch 196/938] [D loss: 0.693340] [G loss: 0.779644]\n",
      "[Epoch 1/2] [Batch 197/938] [D loss: 0.677229] [G loss: 0.734683]\n",
      "[Epoch 1/2] [Batch 198/938] [D loss: 0.694666] [G loss: 0.699364]\n",
      "[Epoch 1/2] [Batch 199/938] [D loss: 0.682164] [G loss: 0.690937]\n",
      "[Epoch 1/2] [Batch 200/938] [D loss: 0.688665] [G loss: 0.679728]\n",
      "[Epoch 1/2] [Batch 201/938] [D loss: 0.687494] [G loss: 0.670419]\n",
      "[Epoch 1/2] [Batch 202/938] [D loss: 0.680021] [G loss: 0.703126]\n",
      "[Epoch 1/2] [Batch 203/938] [D loss: 0.699775] [G loss: 0.715038]\n",
      "[Epoch 1/2] [Batch 204/938] [D loss: 0.690823] [G loss: 0.753320]\n",
      "[Epoch 1/2] [Batch 205/938] [D loss: 0.683634] [G loss: 0.782744]\n",
      "[Epoch 1/2] [Batch 206/938] [D loss: 0.671962] [G loss: 0.753371]\n",
      "[Epoch 1/2] [Batch 207/938] [D loss: 0.692705] [G loss: 0.743770]\n",
      "[Epoch 1/2] [Batch 208/938] [D loss: 0.690801] [G loss: 0.710403]\n",
      "[Epoch 1/2] [Batch 209/938] [D loss: 0.677230] [G loss: 0.676007]\n",
      "[Epoch 1/2] [Batch 210/938] [D loss: 0.705998] [G loss: 0.697675]\n",
      "[Epoch 1/2] [Batch 211/938] [D loss: 0.676381] [G loss: 0.718736]\n",
      "[Epoch 1/2] [Batch 212/938] [D loss: 0.679673] [G loss: 0.710578]\n",
      "[Epoch 1/2] [Batch 213/938] [D loss: 0.677502] [G loss: 0.729945]\n",
      "[Epoch 1/2] [Batch 214/938] [D loss: 0.688959] [G loss: 0.734829]\n",
      "[Epoch 1/2] [Batch 215/938] [D loss: 0.681262] [G loss: 0.764651]\n",
      "[Epoch 1/2] [Batch 216/938] [D loss: 0.682409] [G loss: 0.730396]\n",
      "[Epoch 1/2] [Batch 217/938] [D loss: 0.680862] [G loss: 0.700937]\n",
      "[Epoch 1/2] [Batch 218/938] [D loss: 0.697090] [G loss: 0.695452]\n",
      "[Epoch 1/2] [Batch 219/938] [D loss: 0.696635] [G loss: 0.690222]\n",
      "[Epoch 1/2] [Batch 220/938] [D loss: 0.666887] [G loss: 0.701586]\n",
      "[Epoch 1/2] [Batch 221/938] [D loss: 0.686835] [G loss: 0.698847]\n",
      "[Epoch 1/2] [Batch 222/938] [D loss: 0.690787] [G loss: 0.685614]\n",
      "[Epoch 1/2] [Batch 223/938] [D loss: 0.656293] [G loss: 0.674362]\n",
      "[Epoch 1/2] [Batch 224/938] [D loss: 0.687501] [G loss: 0.678227]\n",
      "[Epoch 1/2] [Batch 225/938] [D loss: 0.691305] [G loss: 0.724837]\n",
      "[Epoch 1/2] [Batch 226/938] [D loss: 0.690595] [G loss: 0.738342]\n",
      "[Epoch 1/2] [Batch 227/938] [D loss: 0.674971] [G loss: 0.723853]\n",
      "[Epoch 1/2] [Batch 228/938] [D loss: 0.676014] [G loss: 0.735352]\n",
      "[Epoch 1/2] [Batch 229/938] [D loss: 0.662986] [G loss: 0.708737]\n",
      "[Epoch 1/2] [Batch 230/938] [D loss: 0.674083] [G loss: 0.714186]\n",
      "[Epoch 1/2] [Batch 231/938] [D loss: 0.693347] [G loss: 0.706808]\n",
      "[Epoch 1/2] [Batch 232/938] [D loss: 0.683862] [G loss: 0.728601]\n",
      "[Epoch 1/2] [Batch 233/938] [D loss: 0.663260] [G loss: 0.697389]\n",
      "[Epoch 1/2] [Batch 234/938] [D loss: 0.676806] [G loss: 0.697569]\n",
      "[Epoch 1/2] [Batch 235/938] [D loss: 0.670498] [G loss: 0.675491]\n",
      "[Epoch 1/2] [Batch 236/938] [D loss: 0.693123] [G loss: 0.654759]\n",
      "[Epoch 1/2] [Batch 237/938] [D loss: 0.678388] [G loss: 0.686484]\n",
      "[Epoch 1/2] [Batch 238/938] [D loss: 0.702823] [G loss: 0.678724]\n",
      "[Epoch 1/2] [Batch 239/938] [D loss: 0.684745] [G loss: 0.702917]\n",
      "[Epoch 1/2] [Batch 240/938] [D loss: 0.703373] [G loss: 0.724086]\n",
      "[Epoch 1/2] [Batch 241/938] [D loss: 0.678988] [G loss: 0.766895]\n",
      "[Epoch 1/2] [Batch 242/938] [D loss: 0.668971] [G loss: 0.757946]\n",
      "[Epoch 1/2] [Batch 243/938] [D loss: 0.676602] [G loss: 0.734216]\n",
      "[Epoch 1/2] [Batch 244/938] [D loss: 0.677651] [G loss: 0.697521]\n",
      "[Epoch 1/2] [Batch 245/938] [D loss: 0.675144] [G loss: 0.685744]\n",
      "[Epoch 1/2] [Batch 246/938] [D loss: 0.694596] [G loss: 0.667954]\n",
      "[Epoch 1/2] [Batch 247/938] [D loss: 0.672444] [G loss: 0.657350]\n",
      "[Epoch 1/2] [Batch 248/938] [D loss: 0.681587] [G loss: 0.719074]\n",
      "[Epoch 1/2] [Batch 249/938] [D loss: 0.694393] [G loss: 0.785312]\n",
      "[Epoch 1/2] [Batch 250/938] [D loss: 0.683948] [G loss: 0.805282]\n",
      "[Epoch 1/2] [Batch 251/938] [D loss: 0.683699] [G loss: 0.791290]\n",
      "[Epoch 1/2] [Batch 252/938] [D loss: 0.691402] [G loss: 0.745273]\n",
      "[Epoch 1/2] [Batch 253/938] [D loss: 0.694962] [G loss: 0.737316]\n",
      "[Epoch 1/2] [Batch 254/938] [D loss: 0.677419] [G loss: 0.714073]\n",
      "[Epoch 1/2] [Batch 255/938] [D loss: 0.686700] [G loss: 0.699022]\n",
      "[Epoch 1/2] [Batch 256/938] [D loss: 0.673436] [G loss: 0.717308]\n",
      "[Epoch 1/2] [Batch 257/938] [D loss: 0.687256] [G loss: 0.700425]\n",
      "[Epoch 1/2] [Batch 258/938] [D loss: 0.686775] [G loss: 0.690748]\n",
      "[Epoch 1/2] [Batch 259/938] [D loss: 0.683866] [G loss: 0.718860]\n",
      "[Epoch 1/2] [Batch 260/938] [D loss: 0.665166] [G loss: 0.744375]\n",
      "[Epoch 1/2] [Batch 261/938] [D loss: 0.691181] [G loss: 0.720145]\n",
      "[Epoch 1/2] [Batch 262/938] [D loss: 0.680183] [G loss: 0.743786]\n",
      "[Epoch 1/2] [Batch 263/938] [D loss: 0.684408] [G loss: 0.745551]\n",
      "[Epoch 1/2] [Batch 264/938] [D loss: 0.685799] [G loss: 0.733568]\n",
      "[Epoch 1/2] [Batch 265/938] [D loss: 0.678923] [G loss: 0.717407]\n",
      "[Epoch 1/2] [Batch 266/938] [D loss: 0.676814] [G loss: 0.668831]\n",
      "[Epoch 1/2] [Batch 267/938] [D loss: 0.687914] [G loss: 0.712396]\n",
      "[Epoch 1/2] [Batch 268/938] [D loss: 0.684928] [G loss: 0.734599]\n",
      "[Epoch 1/2] [Batch 269/938] [D loss: 0.677298] [G loss: 0.745733]\n",
      "[Epoch 1/2] [Batch 270/938] [D loss: 0.672442] [G loss: 0.757661]\n",
      "[Epoch 1/2] [Batch 271/938] [D loss: 0.671839] [G loss: 0.721359]\n",
      "[Epoch 1/2] [Batch 272/938] [D loss: 0.675963] [G loss: 0.707237]\n",
      "[Epoch 1/2] [Batch 273/938] [D loss: 0.682960] [G loss: 0.710802]\n",
      "[Epoch 1/2] [Batch 274/938] [D loss: 0.687176] [G loss: 0.761506]\n",
      "[Epoch 1/2] [Batch 275/938] [D loss: 0.661107] [G loss: 0.713906]\n",
      "[Epoch 1/2] [Batch 276/938] [D loss: 0.674301] [G loss: 0.712434]\n",
      "[Epoch 1/2] [Batch 277/938] [D loss: 0.684109] [G loss: 0.709002]\n",
      "[Epoch 1/2] [Batch 278/938] [D loss: 0.668675] [G loss: 0.724263]\n",
      "[Epoch 1/2] [Batch 279/938] [D loss: 0.690950] [G loss: 0.736409]\n",
      "[Epoch 1/2] [Batch 280/938] [D loss: 0.675102] [G loss: 0.714035]\n",
      "[Epoch 1/2] [Batch 281/938] [D loss: 0.681773] [G loss: 0.747244]\n",
      "[Epoch 1/2] [Batch 282/938] [D loss: 0.675166] [G loss: 0.743691]\n",
      "[Epoch 1/2] [Batch 283/938] [D loss: 0.664435] [G loss: 0.717691]\n",
      "[Epoch 1/2] [Batch 284/938] [D loss: 0.701011] [G loss: 0.717559]\n",
      "[Epoch 1/2] [Batch 285/938] [D loss: 0.671605] [G loss: 0.737813]\n",
      "[Epoch 1/2] [Batch 286/938] [D loss: 0.678871] [G loss: 0.766896]\n",
      "[Epoch 1/2] [Batch 287/938] [D loss: 0.670992] [G loss: 0.746526]\n",
      "[Epoch 1/2] [Batch 288/938] [D loss: 0.659599] [G loss: 0.708297]\n",
      "[Epoch 1/2] [Batch 289/938] [D loss: 0.663431] [G loss: 0.702085]\n",
      "[Epoch 1/2] [Batch 290/938] [D loss: 0.684905] [G loss: 0.706767]\n",
      "[Epoch 1/2] [Batch 291/938] [D loss: 0.684147] [G loss: 0.693136]\n",
      "[Epoch 1/2] [Batch 292/938] [D loss: 0.689645] [G loss: 0.703950]\n",
      "[Epoch 1/2] [Batch 293/938] [D loss: 0.683769] [G loss: 0.694462]\n",
      "[Epoch 1/2] [Batch 294/938] [D loss: 0.697101] [G loss: 0.701947]\n",
      "[Epoch 1/2] [Batch 295/938] [D loss: 0.691186] [G loss: 0.725734]\n",
      "[Epoch 1/2] [Batch 296/938] [D loss: 0.693168] [G loss: 0.721771]\n",
      "[Epoch 1/2] [Batch 297/938] [D loss: 0.662574] [G loss: 0.724318]\n",
      "[Epoch 1/2] [Batch 298/938] [D loss: 0.700859] [G loss: 0.729945]\n",
      "[Epoch 1/2] [Batch 299/938] [D loss: 0.678774] [G loss: 0.732050]\n",
      "[Epoch 1/2] [Batch 300/938] [D loss: 0.666695] [G loss: 0.735079]\n",
      "[Epoch 1/2] [Batch 301/938] [D loss: 0.688442] [G loss: 0.701629]\n",
      "[Epoch 1/2] [Batch 302/938] [D loss: 0.686823] [G loss: 0.689638]\n",
      "[Epoch 1/2] [Batch 303/938] [D loss: 0.685666] [G loss: 0.707372]\n",
      "[Epoch 1/2] [Batch 304/938] [D loss: 0.661193] [G loss: 0.714933]\n",
      "[Epoch 1/2] [Batch 305/938] [D loss: 0.676506] [G loss: 0.729825]\n",
      "[Epoch 1/2] [Batch 306/938] [D loss: 0.667670] [G loss: 0.755708]\n",
      "[Epoch 1/2] [Batch 307/938] [D loss: 0.654537] [G loss: 0.726753]\n",
      "[Epoch 1/2] [Batch 308/938] [D loss: 0.682878] [G loss: 0.709356]\n",
      "[Epoch 1/2] [Batch 309/938] [D loss: 0.682433] [G loss: 0.692970]\n",
      "[Epoch 1/2] [Batch 310/938] [D loss: 0.680552] [G loss: 0.682762]\n",
      "[Epoch 1/2] [Batch 311/938] [D loss: 0.662583] [G loss: 0.670157]\n",
      "[Epoch 1/2] [Batch 312/938] [D loss: 0.666117] [G loss: 0.706009]\n",
      "[Epoch 1/2] [Batch 313/938] [D loss: 0.680601] [G loss: 0.725500]\n",
      "[Epoch 1/2] [Batch 314/938] [D loss: 0.665614] [G loss: 0.748621]\n",
      "[Epoch 1/2] [Batch 315/938] [D loss: 0.679561] [G loss: 0.750044]\n",
      "[Epoch 1/2] [Batch 316/938] [D loss: 0.688058] [G loss: 0.747900]\n",
      "[Epoch 1/2] [Batch 317/938] [D loss: 0.682527] [G loss: 0.706420]\n",
      "[Epoch 1/2] [Batch 318/938] [D loss: 0.670424] [G loss: 0.699203]\n",
      "[Epoch 1/2] [Batch 319/938] [D loss: 0.662790] [G loss: 0.650529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 320/938] [D loss: 0.662433] [G loss: 0.694481]\n",
      "[Epoch 1/2] [Batch 321/938] [D loss: 0.695829] [G loss: 0.732513]\n",
      "[Epoch 1/2] [Batch 322/938] [D loss: 0.675635] [G loss: 0.804897]\n",
      "[Epoch 1/2] [Batch 323/938] [D loss: 0.697875] [G loss: 0.815303]\n",
      "[Epoch 1/2] [Batch 324/938] [D loss: 0.686176] [G loss: 0.788557]\n",
      "[Epoch 1/2] [Batch 325/938] [D loss: 0.699160] [G loss: 0.766095]\n",
      "[Epoch 1/2] [Batch 326/938] [D loss: 0.686403] [G loss: 0.741139]\n",
      "[Epoch 1/2] [Batch 327/938] [D loss: 0.667078] [G loss: 0.735924]\n",
      "[Epoch 1/2] [Batch 328/938] [D loss: 0.672711] [G loss: 0.714969]\n",
      "[Epoch 1/2] [Batch 329/938] [D loss: 0.673281] [G loss: 0.694528]\n",
      "[Epoch 1/2] [Batch 330/938] [D loss: 0.691254] [G loss: 0.733865]\n",
      "[Epoch 1/2] [Batch 331/938] [D loss: 0.681039] [G loss: 0.774907]\n",
      "[Epoch 1/2] [Batch 332/938] [D loss: 0.657610] [G loss: 0.779995]\n",
      "[Epoch 1/2] [Batch 333/938] [D loss: 0.693910] [G loss: 0.743898]\n",
      "[Epoch 1/2] [Batch 334/938] [D loss: 0.669584] [G loss: 0.687661]\n",
      "[Epoch 1/2] [Batch 335/938] [D loss: 0.689202] [G loss: 0.697745]\n",
      "[Epoch 1/2] [Batch 336/938] [D loss: 0.684255] [G loss: 0.662034]\n",
      "[Epoch 1/2] [Batch 337/938] [D loss: 0.688709] [G loss: 0.760419]\n",
      "[Epoch 1/2] [Batch 338/938] [D loss: 0.674325] [G loss: 0.751220]\n",
      "[Epoch 1/2] [Batch 339/938] [D loss: 0.668209] [G loss: 0.746647]\n",
      "[Epoch 1/2] [Batch 340/938] [D loss: 0.660690] [G loss: 0.735031]\n",
      "[Epoch 1/2] [Batch 341/938] [D loss: 0.660064] [G loss: 0.720707]\n",
      "[Epoch 1/2] [Batch 342/938] [D loss: 0.673479] [G loss: 0.717893]\n",
      "[Epoch 1/2] [Batch 343/938] [D loss: 0.687771] [G loss: 0.745248]\n",
      "[Epoch 1/2] [Batch 344/938] [D loss: 0.655467] [G loss: 0.753677]\n",
      "[Epoch 1/2] [Batch 345/938] [D loss: 0.673586] [G loss: 0.733991]\n",
      "[Epoch 1/2] [Batch 346/938] [D loss: 0.667253] [G loss: 0.708052]\n",
      "[Epoch 1/2] [Batch 347/938] [D loss: 0.671277] [G loss: 0.694037]\n",
      "[Epoch 1/2] [Batch 348/938] [D loss: 0.700452] [G loss: 0.731434]\n",
      "[Epoch 1/2] [Batch 349/938] [D loss: 0.663091] [G loss: 0.743567]\n",
      "[Epoch 1/2] [Batch 350/938] [D loss: 0.697029] [G loss: 0.762680]\n",
      "[Epoch 1/2] [Batch 351/938] [D loss: 0.656803] [G loss: 0.727042]\n",
      "[Epoch 1/2] [Batch 352/938] [D loss: 0.667950] [G loss: 0.701389]\n",
      "[Epoch 1/2] [Batch 353/938] [D loss: 0.686125] [G loss: 0.659047]\n",
      "[Epoch 1/2] [Batch 354/938] [D loss: 0.685843] [G loss: 0.748103]\n",
      "[Epoch 1/2] [Batch 355/938] [D loss: 0.649657] [G loss: 0.748142]\n",
      "[Epoch 1/2] [Batch 356/938] [D loss: 0.677077] [G loss: 0.728786]\n",
      "[Epoch 1/2] [Batch 357/938] [D loss: 0.697741] [G loss: 0.731233]\n",
      "[Epoch 1/2] [Batch 358/938] [D loss: 0.693126] [G loss: 0.750112]\n",
      "[Epoch 1/2] [Batch 359/938] [D loss: 0.675544] [G loss: 0.725930]\n",
      "[Epoch 1/2] [Batch 360/938] [D loss: 0.682094] [G loss: 0.722135]\n",
      "[Epoch 1/2] [Batch 361/938] [D loss: 0.668961] [G loss: 0.711537]\n",
      "[Epoch 1/2] [Batch 362/938] [D loss: 0.692266] [G loss: 0.764172]\n",
      "[Epoch 1/2] [Batch 363/938] [D loss: 0.680877] [G loss: 0.763858]\n",
      "[Epoch 1/2] [Batch 364/938] [D loss: 0.688005] [G loss: 0.737343]\n",
      "[Epoch 1/2] [Batch 365/938] [D loss: 0.693431] [G loss: 0.725964]\n",
      "[Epoch 1/2] [Batch 366/938] [D loss: 0.675152] [G loss: 0.725646]\n",
      "[Epoch 1/2] [Batch 367/938] [D loss: 0.672732] [G loss: 0.725825]\n",
      "[Epoch 1/2] [Batch 368/938] [D loss: 0.664572] [G loss: 0.730275]\n",
      "[Epoch 1/2] [Batch 369/938] [D loss: 0.679103] [G loss: 0.715370]\n",
      "[Epoch 1/2] [Batch 370/938] [D loss: 0.686260] [G loss: 0.713324]\n",
      "[Epoch 1/2] [Batch 371/938] [D loss: 0.678116] [G loss: 0.721933]\n",
      "[Epoch 1/2] [Batch 372/938] [D loss: 0.663992] [G loss: 0.729116]\n",
      "[Epoch 1/2] [Batch 373/938] [D loss: 0.667900] [G loss: 0.689423]\n",
      "[Epoch 1/2] [Batch 374/938] [D loss: 0.667907] [G loss: 0.759161]\n",
      "[Epoch 1/2] [Batch 375/938] [D loss: 0.675025] [G loss: 0.774456]\n",
      "[Epoch 1/2] [Batch 376/938] [D loss: 0.675929] [G loss: 0.694863]\n",
      "[Epoch 1/2] [Batch 377/938] [D loss: 0.655267] [G loss: 0.713801]\n",
      "[Epoch 1/2] [Batch 378/938] [D loss: 0.682200] [G loss: 0.734880]\n",
      "[Epoch 1/2] [Batch 379/938] [D loss: 0.700521] [G loss: 0.711089]\n",
      "[Epoch 1/2] [Batch 380/938] [D loss: 0.690460] [G loss: 0.728283]\n",
      "[Epoch 1/2] [Batch 381/938] [D loss: 0.675245] [G loss: 0.779032]\n",
      "[Epoch 1/2] [Batch 382/938] [D loss: 0.670649] [G loss: 0.734080]\n",
      "[Epoch 1/2] [Batch 383/938] [D loss: 0.693498] [G loss: 0.738001]\n",
      "[Epoch 1/2] [Batch 384/938] [D loss: 0.674263] [G loss: 0.754293]\n",
      "[Epoch 1/2] [Batch 385/938] [D loss: 0.675459] [G loss: 0.729377]\n",
      "[Epoch 1/2] [Batch 386/938] [D loss: 0.680937] [G loss: 0.729721]\n",
      "[Epoch 1/2] [Batch 387/938] [D loss: 0.679267] [G loss: 0.759586]\n",
      "[Epoch 1/2] [Batch 388/938] [D loss: 0.701509] [G loss: 0.715964]\n",
      "[Epoch 1/2] [Batch 389/938] [D loss: 0.712601] [G loss: 0.739201]\n",
      "[Epoch 1/2] [Batch 390/938] [D loss: 0.674303] [G loss: 0.731509]\n",
      "[Epoch 1/2] [Batch 391/938] [D loss: 0.670895] [G loss: 0.707925]\n",
      "[Epoch 1/2] [Batch 392/938] [D loss: 0.654498] [G loss: 0.701005]\n",
      "[Epoch 1/2] [Batch 393/938] [D loss: 0.667288] [G loss: 0.698410]\n",
      "[Epoch 1/2] [Batch 394/938] [D loss: 0.667901] [G loss: 0.725120]\n",
      "[Epoch 1/2] [Batch 395/938] [D loss: 0.670357] [G loss: 0.774348]\n",
      "[Epoch 1/2] [Batch 396/938] [D loss: 0.672277] [G loss: 0.734154]\n",
      "[Epoch 1/2] [Batch 397/938] [D loss: 0.693335] [G loss: 0.712420]\n",
      "[Epoch 1/2] [Batch 398/938] [D loss: 0.692905] [G loss: 0.665013]\n",
      "[Epoch 1/2] [Batch 399/938] [D loss: 0.699118] [G loss: 0.672823]\n",
      "[Epoch 1/2] [Batch 400/938] [D loss: 0.691222] [G loss: 0.713340]\n",
      "[Epoch 1/2] [Batch 401/938] [D loss: 0.679332] [G loss: 0.745535]\n",
      "[Epoch 1/2] [Batch 402/938] [D loss: 0.666281] [G loss: 0.766143]\n",
      "[Epoch 1/2] [Batch 403/938] [D loss: 0.689480] [G loss: 0.741572]\n",
      "[Epoch 1/2] [Batch 404/938] [D loss: 0.698599] [G loss: 0.713469]\n",
      "[Epoch 1/2] [Batch 405/938] [D loss: 0.683970] [G loss: 0.686763]\n",
      "[Epoch 1/2] [Batch 406/938] [D loss: 0.662213] [G loss: 0.679937]\n",
      "[Epoch 1/2] [Batch 407/938] [D loss: 0.677725] [G loss: 0.730005]\n",
      "[Epoch 1/2] [Batch 408/938] [D loss: 0.676196] [G loss: 0.762076]\n",
      "[Epoch 1/2] [Batch 409/938] [D loss: 0.677473] [G loss: 0.745830]\n",
      "[Epoch 1/2] [Batch 410/938] [D loss: 0.679336] [G loss: 0.763255]\n",
      "[Epoch 1/2] [Batch 411/938] [D loss: 0.656663] [G loss: 0.735735]\n",
      "[Epoch 1/2] [Batch 412/938] [D loss: 0.660713] [G loss: 0.697931]\n",
      "[Epoch 1/2] [Batch 413/938] [D loss: 0.656271] [G loss: 0.705903]\n",
      "[Epoch 1/2] [Batch 414/938] [D loss: 0.662685] [G loss: 0.764342]\n",
      "[Epoch 1/2] [Batch 415/938] [D loss: 0.664759] [G loss: 0.736963]\n",
      "[Epoch 1/2] [Batch 416/938] [D loss: 0.653977] [G loss: 0.757821]\n",
      "[Epoch 1/2] [Batch 417/938] [D loss: 0.681483] [G loss: 0.738643]\n",
      "[Epoch 1/2] [Batch 418/938] [D loss: 0.690145] [G loss: 0.720627]\n",
      "[Epoch 1/2] [Batch 419/938] [D loss: 0.691470] [G loss: 0.721910]\n",
      "[Epoch 1/2] [Batch 420/938] [D loss: 0.669845] [G loss: 0.718902]\n",
      "[Epoch 1/2] [Batch 421/938] [D loss: 0.671230] [G loss: 0.726811]\n",
      "[Epoch 1/2] [Batch 422/938] [D loss: 0.684394] [G loss: 0.708832]\n",
      "[Epoch 1/2] [Batch 423/938] [D loss: 0.694355] [G loss: 0.752282]\n",
      "[Epoch 1/2] [Batch 424/938] [D loss: 0.670959] [G loss: 0.727661]\n",
      "[Epoch 1/2] [Batch 425/938] [D loss: 0.677335] [G loss: 0.731339]\n",
      "[Epoch 1/2] [Batch 426/938] [D loss: 0.679267] [G loss: 0.732262]\n",
      "[Epoch 1/2] [Batch 427/938] [D loss: 0.684116] [G loss: 0.737462]\n",
      "[Epoch 1/2] [Batch 428/938] [D loss: 0.651209] [G loss: 0.711166]\n",
      "[Epoch 1/2] [Batch 429/938] [D loss: 0.654070] [G loss: 0.738561]\n",
      "[Epoch 1/2] [Batch 430/938] [D loss: 0.662291] [G loss: 0.731005]\n",
      "[Epoch 1/2] [Batch 431/938] [D loss: 0.647337] [G loss: 0.707757]\n",
      "[Epoch 1/2] [Batch 432/938] [D loss: 0.662915] [G loss: 0.736449]\n",
      "[Epoch 1/2] [Batch 433/938] [D loss: 0.683053] [G loss: 0.756414]\n",
      "[Epoch 1/2] [Batch 434/938] [D loss: 0.668871] [G loss: 0.799371]\n",
      "[Epoch 1/2] [Batch 435/938] [D loss: 0.694003] [G loss: 0.768404]\n",
      "[Epoch 1/2] [Batch 436/938] [D loss: 0.670927] [G loss: 0.750551]\n",
      "[Epoch 1/2] [Batch 437/938] [D loss: 0.703638] [G loss: 0.679244]\n",
      "[Epoch 1/2] [Batch 438/938] [D loss: 0.682662] [G loss: 0.736312]\n",
      "[Epoch 1/2] [Batch 439/938] [D loss: 0.672445] [G loss: 0.798446]\n",
      "[Epoch 1/2] [Batch 440/938] [D loss: 0.666711] [G loss: 0.755059]\n",
      "[Epoch 1/2] [Batch 441/938] [D loss: 0.681746] [G loss: 0.783120]\n",
      "[Epoch 1/2] [Batch 442/938] [D loss: 0.675274] [G loss: 0.766651]\n",
      "[Epoch 1/2] [Batch 443/938] [D loss: 0.668288] [G loss: 0.708950]\n",
      "[Epoch 1/2] [Batch 444/938] [D loss: 0.664248] [G loss: 0.741030]\n",
      "[Epoch 1/2] [Batch 445/938] [D loss: 0.657383] [G loss: 0.720332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 446/938] [D loss: 0.685490] [G loss: 0.696137]\n",
      "[Epoch 1/2] [Batch 447/938] [D loss: 0.685740] [G loss: 0.738987]\n",
      "[Epoch 1/2] [Batch 448/938] [D loss: 0.664044] [G loss: 0.729250]\n",
      "[Epoch 1/2] [Batch 449/938] [D loss: 0.650421] [G loss: 0.688653]\n",
      "[Epoch 1/2] [Batch 450/938] [D loss: 0.686913] [G loss: 0.705622]\n",
      "[Epoch 1/2] [Batch 451/938] [D loss: 0.670815] [G loss: 0.722786]\n",
      "[Epoch 1/2] [Batch 452/938] [D loss: 0.662627] [G loss: 0.687852]\n",
      "[Epoch 1/2] [Batch 453/938] [D loss: 0.664294] [G loss: 0.735281]\n",
      "[Epoch 1/2] [Batch 454/938] [D loss: 0.652617] [G loss: 0.700377]\n",
      "[Epoch 1/2] [Batch 455/938] [D loss: 0.693633] [G loss: 0.699205]\n",
      "[Epoch 1/2] [Batch 456/938] [D loss: 0.701081] [G loss: 0.775598]\n",
      "[Epoch 1/2] [Batch 457/938] [D loss: 0.674072] [G loss: 0.732875]\n",
      "[Epoch 1/2] [Batch 458/938] [D loss: 0.686486] [G loss: 0.744827]\n",
      "[Epoch 1/2] [Batch 459/938] [D loss: 0.694326] [G loss: 0.753452]\n",
      "[Epoch 1/2] [Batch 460/938] [D loss: 0.684064] [G loss: 0.715555]\n",
      "[Epoch 1/2] [Batch 461/938] [D loss: 0.662917] [G loss: 0.756948]\n",
      "[Epoch 1/2] [Batch 462/938] [D loss: 0.679114] [G loss: 0.772178]\n",
      "[Epoch 1/2] [Batch 463/938] [D loss: 0.661544] [G loss: 0.750614]\n",
      "[Epoch 1/2] [Batch 464/938] [D loss: 0.673113] [G loss: 0.699802]\n",
      "[Epoch 1/2] [Batch 465/938] [D loss: 0.641083] [G loss: 0.665849]\n",
      "[Epoch 1/2] [Batch 466/938] [D loss: 0.696320] [G loss: 0.770389]\n",
      "[Epoch 1/2] [Batch 467/938] [D loss: 0.651338] [G loss: 0.758922]\n",
      "[Epoch 1/2] [Batch 468/938] [D loss: 0.676194] [G loss: 0.746862]\n",
      "[Epoch 1/2] [Batch 469/938] [D loss: 0.684096] [G loss: 0.697182]\n",
      "[Epoch 1/2] [Batch 470/938] [D loss: 0.681263] [G loss: 0.704205]\n",
      "[Epoch 1/2] [Batch 471/938] [D loss: 0.653921] [G loss: 0.716130]\n",
      "[Epoch 1/2] [Batch 472/938] [D loss: 0.668928] [G loss: 0.703558]\n",
      "[Epoch 1/2] [Batch 473/938] [D loss: 0.665193] [G loss: 0.790351]\n",
      "[Epoch 1/2] [Batch 474/938] [D loss: 0.643929] [G loss: 0.816087]\n",
      "[Epoch 1/2] [Batch 475/938] [D loss: 0.689697] [G loss: 0.750405]\n",
      "[Epoch 1/2] [Batch 476/938] [D loss: 0.681051] [G loss: 0.706883]\n",
      "[Epoch 1/2] [Batch 477/938] [D loss: 0.652089] [G loss: 0.693450]\n",
      "[Epoch 1/2] [Batch 478/938] [D loss: 0.675580] [G loss: 0.771179]\n",
      "[Epoch 1/2] [Batch 479/938] [D loss: 0.681433] [G loss: 0.698525]\n",
      "[Epoch 1/2] [Batch 480/938] [D loss: 0.679667] [G loss: 0.700006]\n",
      "[Epoch 1/2] [Batch 481/938] [D loss: 0.681224] [G loss: 0.802357]\n",
      "[Epoch 1/2] [Batch 482/938] [D loss: 0.665635] [G loss: 0.759213]\n",
      "[Epoch 1/2] [Batch 483/938] [D loss: 0.693827] [G loss: 0.714293]\n",
      "[Epoch 1/2] [Batch 484/938] [D loss: 0.662758] [G loss: 0.734466]\n",
      "[Epoch 1/2] [Batch 485/938] [D loss: 0.641814] [G loss: 0.729321]\n",
      "[Epoch 1/2] [Batch 486/938] [D loss: 0.665482] [G loss: 0.705307]\n",
      "[Epoch 1/2] [Batch 487/938] [D loss: 0.657014] [G loss: 0.761960]\n",
      "[Epoch 1/2] [Batch 488/938] [D loss: 0.683548] [G loss: 0.726492]\n",
      "[Epoch 1/2] [Batch 489/938] [D loss: 0.658409] [G loss: 0.740049]\n",
      "[Epoch 1/2] [Batch 490/938] [D loss: 0.677155] [G loss: 0.761651]\n",
      "[Epoch 1/2] [Batch 491/938] [D loss: 0.661909] [G loss: 0.769753]\n",
      "[Epoch 1/2] [Batch 492/938] [D loss: 0.643999] [G loss: 0.778017]\n",
      "[Epoch 1/2] [Batch 493/938] [D loss: 0.672210] [G loss: 0.743843]\n",
      "[Epoch 1/2] [Batch 494/938] [D loss: 0.698187] [G loss: 0.683363]\n",
      "[Epoch 1/2] [Batch 495/938] [D loss: 0.724617] [G loss: 0.675592]\n",
      "[Epoch 1/2] [Batch 496/938] [D loss: 0.692777] [G loss: 0.767654]\n",
      "[Epoch 1/2] [Batch 497/938] [D loss: 0.683649] [G loss: 0.786281]\n",
      "[Epoch 1/2] [Batch 498/938] [D loss: 0.655679] [G loss: 0.794114]\n",
      "[Epoch 1/2] [Batch 499/938] [D loss: 0.669435] [G loss: 0.765796]\n",
      "[Epoch 1/2] [Batch 500/938] [D loss: 0.665590] [G loss: 0.739924]\n",
      "[Epoch 1/2] [Batch 501/938] [D loss: 0.658342] [G loss: 0.765770]\n",
      "[Epoch 1/2] [Batch 502/938] [D loss: 0.658614] [G loss: 0.808923]\n",
      "[Epoch 1/2] [Batch 503/938] [D loss: 0.657092] [G loss: 0.913608]\n",
      "[Epoch 1/2] [Batch 504/938] [D loss: 0.690323] [G loss: 0.815429]\n",
      "[Epoch 1/2] [Batch 505/938] [D loss: 0.680112] [G loss: 0.731810]\n",
      "[Epoch 1/2] [Batch 506/938] [D loss: 0.685916] [G loss: 0.691575]\n",
      "[Epoch 1/2] [Batch 507/938] [D loss: 0.665372] [G loss: 0.656898]\n",
      "[Epoch 1/2] [Batch 508/938] [D loss: 0.675952] [G loss: 0.665117]\n",
      "[Epoch 1/2] [Batch 509/938] [D loss: 0.697223] [G loss: 0.655137]\n",
      "[Epoch 1/2] [Batch 510/938] [D loss: 0.690529] [G loss: 0.718941]\n",
      "[Epoch 1/2] [Batch 511/938] [D loss: 0.680847] [G loss: 0.798063]\n",
      "[Epoch 1/2] [Batch 512/938] [D loss: 0.697330] [G loss: 0.844169]\n",
      "[Epoch 1/2] [Batch 513/938] [D loss: 0.696558] [G loss: 0.745241]\n",
      "[Epoch 1/2] [Batch 514/938] [D loss: 0.637319] [G loss: 0.728839]\n",
      "[Epoch 1/2] [Batch 515/938] [D loss: 0.684359] [G loss: 0.724922]\n",
      "[Epoch 1/2] [Batch 516/938] [D loss: 0.668058] [G loss: 0.684080]\n",
      "[Epoch 1/2] [Batch 517/938] [D loss: 0.671114] [G loss: 0.724336]\n",
      "[Epoch 1/2] [Batch 518/938] [D loss: 0.680765] [G loss: 0.711806]\n",
      "[Epoch 1/2] [Batch 519/938] [D loss: 0.647115] [G loss: 0.743741]\n",
      "[Epoch 1/2] [Batch 520/938] [D loss: 0.680048] [G loss: 0.788732]\n",
      "[Epoch 1/2] [Batch 521/938] [D loss: 0.660024] [G loss: 0.829574]\n",
      "[Epoch 1/2] [Batch 522/938] [D loss: 0.660368] [G loss: 0.770769]\n",
      "[Epoch 1/2] [Batch 523/938] [D loss: 0.657143] [G loss: 0.737449]\n",
      "[Epoch 1/2] [Batch 524/938] [D loss: 0.658841] [G loss: 0.717862]\n",
      "[Epoch 1/2] [Batch 525/938] [D loss: 0.665157] [G loss: 0.710247]\n",
      "[Epoch 1/2] [Batch 526/938] [D loss: 0.662154] [G loss: 0.738032]\n",
      "[Epoch 1/2] [Batch 527/938] [D loss: 0.673218] [G loss: 0.773133]\n",
      "[Epoch 1/2] [Batch 528/938] [D loss: 0.687261] [G loss: 0.761949]\n",
      "[Epoch 1/2] [Batch 529/938] [D loss: 0.660667] [G loss: 0.764139]\n",
      "[Epoch 1/2] [Batch 530/938] [D loss: 0.668568] [G loss: 0.739802]\n",
      "[Epoch 1/2] [Batch 531/938] [D loss: 0.704032] [G loss: 0.690693]\n",
      "[Epoch 1/2] [Batch 532/938] [D loss: 0.645191] [G loss: 0.729817]\n",
      "[Epoch 1/2] [Batch 533/938] [D loss: 0.703651] [G loss: 0.730054]\n",
      "[Epoch 1/2] [Batch 534/938] [D loss: 0.704643] [G loss: 0.701919]\n",
      "[Epoch 1/2] [Batch 535/938] [D loss: 0.673461] [G loss: 0.749298]\n",
      "[Epoch 1/2] [Batch 536/938] [D loss: 0.665861] [G loss: 0.656906]\n",
      "[Epoch 1/2] [Batch 537/938] [D loss: 0.698161] [G loss: 0.711968]\n",
      "[Epoch 1/2] [Batch 538/938] [D loss: 0.661314] [G loss: 0.772402]\n",
      "[Epoch 1/2] [Batch 539/938] [D loss: 0.693186] [G loss: 0.835977]\n",
      "[Epoch 1/2] [Batch 540/938] [D loss: 0.671320] [G loss: 0.733026]\n",
      "[Epoch 1/2] [Batch 541/938] [D loss: 0.655953] [G loss: 0.729216]\n",
      "[Epoch 1/2] [Batch 542/938] [D loss: 0.673391] [G loss: 0.710007]\n",
      "[Epoch 1/2] [Batch 543/938] [D loss: 0.674902] [G loss: 0.754949]\n",
      "[Epoch 1/2] [Batch 544/938] [D loss: 0.670732] [G loss: 0.770118]\n",
      "[Epoch 1/2] [Batch 545/938] [D loss: 0.652899] [G loss: 0.705574]\n",
      "[Epoch 1/2] [Batch 546/938] [D loss: 0.676118] [G loss: 0.758129]\n",
      "[Epoch 1/2] [Batch 547/938] [D loss: 0.664823] [G loss: 0.742721]\n",
      "[Epoch 1/2] [Batch 548/938] [D loss: 0.650733] [G loss: 0.774588]\n",
      "[Epoch 1/2] [Batch 549/938] [D loss: 0.678790] [G loss: 0.714270]\n",
      "[Epoch 1/2] [Batch 550/938] [D loss: 0.674964] [G loss: 0.735331]\n",
      "[Epoch 1/2] [Batch 551/938] [D loss: 0.658797] [G loss: 0.725516]\n",
      "[Epoch 1/2] [Batch 552/938] [D loss: 0.648142] [G loss: 0.688642]\n",
      "[Epoch 1/2] [Batch 553/938] [D loss: 0.660549] [G loss: 0.741953]\n",
      "[Epoch 1/2] [Batch 554/938] [D loss: 0.644815] [G loss: 0.753110]\n",
      "[Epoch 1/2] [Batch 555/938] [D loss: 0.685647] [G loss: 0.765882]\n",
      "[Epoch 1/2] [Batch 556/938] [D loss: 0.662490] [G loss: 0.798340]\n",
      "[Epoch 1/2] [Batch 557/938] [D loss: 0.670666] [G loss: 0.805082]\n",
      "[Epoch 1/2] [Batch 558/938] [D loss: 0.641221] [G loss: 0.741471]\n",
      "[Epoch 1/2] [Batch 559/938] [D loss: 0.662842] [G loss: 0.726429]\n",
      "[Epoch 1/2] [Batch 560/938] [D loss: 0.688430] [G loss: 0.704112]\n",
      "[Epoch 1/2] [Batch 561/938] [D loss: 0.653017] [G loss: 0.756410]\n",
      "[Epoch 1/2] [Batch 562/938] [D loss: 0.681398] [G loss: 0.773258]\n",
      "[Epoch 1/2] [Batch 563/938] [D loss: 0.667730] [G loss: 0.805539]\n",
      "[Epoch 1/2] [Batch 564/938] [D loss: 0.700386] [G loss: 0.754293]\n",
      "[Epoch 1/2] [Batch 565/938] [D loss: 0.682240] [G loss: 0.740516]\n",
      "[Epoch 1/2] [Batch 566/938] [D loss: 0.650547] [G loss: 0.709139]\n",
      "[Epoch 1/2] [Batch 567/938] [D loss: 0.674513] [G loss: 0.753958]\n",
      "[Epoch 1/2] [Batch 568/938] [D loss: 0.687439] [G loss: 0.738211]\n",
      "[Epoch 1/2] [Batch 569/938] [D loss: 0.672945] [G loss: 0.762262]\n",
      "[Epoch 1/2] [Batch 570/938] [D loss: 0.620017] [G loss: 0.720683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 571/938] [D loss: 0.683706] [G loss: 0.734731]\n",
      "[Epoch 1/2] [Batch 572/938] [D loss: 0.678017] [G loss: 0.719574]\n",
      "[Epoch 1/2] [Batch 573/938] [D loss: 0.650988] [G loss: 0.752552]\n",
      "[Epoch 1/2] [Batch 574/938] [D loss: 0.656187] [G loss: 0.693042]\n",
      "[Epoch 1/2] [Batch 575/938] [D loss: 0.685629] [G loss: 0.717495]\n",
      "[Epoch 1/2] [Batch 576/938] [D loss: 0.666466] [G loss: 0.844780]\n",
      "[Epoch 1/2] [Batch 577/938] [D loss: 0.696071] [G loss: 0.889040]\n",
      "[Epoch 1/2] [Batch 578/938] [D loss: 0.645061] [G loss: 0.747153]\n",
      "[Epoch 1/2] [Batch 579/938] [D loss: 0.632939] [G loss: 0.685845]\n",
      "[Epoch 1/2] [Batch 580/938] [D loss: 0.643815] [G loss: 0.724227]\n",
      "[Epoch 1/2] [Batch 581/938] [D loss: 0.709464] [G loss: 0.763284]\n",
      "[Epoch 1/2] [Batch 582/938] [D loss: 0.669768] [G loss: 0.814489]\n",
      "[Epoch 1/2] [Batch 583/938] [D loss: 0.656184] [G loss: 0.794233]\n",
      "[Epoch 1/2] [Batch 584/938] [D loss: 0.664672] [G loss: 0.742741]\n",
      "[Epoch 1/2] [Batch 585/938] [D loss: 0.654225] [G loss: 0.702714]\n",
      "[Epoch 1/2] [Batch 586/938] [D loss: 0.637754] [G loss: 0.679888]\n",
      "[Epoch 1/2] [Batch 587/938] [D loss: 0.658356] [G loss: 0.753987]\n",
      "[Epoch 1/2] [Batch 588/938] [D loss: 0.653853] [G loss: 0.831726]\n",
      "[Epoch 1/2] [Batch 589/938] [D loss: 0.646737] [G loss: 0.800700]\n",
      "[Epoch 1/2] [Batch 590/938] [D loss: 0.650121] [G loss: 0.776429]\n",
      "[Epoch 1/2] [Batch 591/938] [D loss: 0.654756] [G loss: 0.707988]\n",
      "[Epoch 1/2] [Batch 592/938] [D loss: 0.692951] [G loss: 0.692181]\n",
      "[Epoch 1/2] [Batch 593/938] [D loss: 0.649021] [G loss: 0.709608]\n",
      "[Epoch 1/2] [Batch 594/938] [D loss: 0.675415] [G loss: 0.744717]\n",
      "[Epoch 1/2] [Batch 595/938] [D loss: 0.650112] [G loss: 0.792909]\n",
      "[Epoch 1/2] [Batch 596/938] [D loss: 0.676968] [G loss: 0.845378]\n",
      "[Epoch 1/2] [Batch 597/938] [D loss: 0.651320] [G loss: 0.771008]\n",
      "[Epoch 1/2] [Batch 598/938] [D loss: 0.664113] [G loss: 0.740497]\n",
      "[Epoch 1/2] [Batch 599/938] [D loss: 0.709365] [G loss: 0.705101]\n",
      "[Epoch 1/2] [Batch 600/938] [D loss: 0.670599] [G loss: 0.781488]\n",
      "[Epoch 1/2] [Batch 601/938] [D loss: 0.695777] [G loss: 0.770246]\n",
      "[Epoch 1/2] [Batch 602/938] [D loss: 0.656232] [G loss: 0.828916]\n",
      "[Epoch 1/2] [Batch 603/938] [D loss: 0.655368] [G loss: 0.777660]\n",
      "[Epoch 1/2] [Batch 604/938] [D loss: 0.670966] [G loss: 0.802249]\n",
      "[Epoch 1/2] [Batch 605/938] [D loss: 0.674807] [G loss: 0.754994]\n",
      "[Epoch 1/2] [Batch 606/938] [D loss: 0.636494] [G loss: 0.668827]\n",
      "[Epoch 1/2] [Batch 607/938] [D loss: 0.630780] [G loss: 0.727798]\n",
      "[Epoch 1/2] [Batch 608/938] [D loss: 0.662504] [G loss: 0.788320]\n",
      "[Epoch 1/2] [Batch 609/938] [D loss: 0.640130] [G loss: 0.782753]\n",
      "[Epoch 1/2] [Batch 610/938] [D loss: 0.643067] [G loss: 0.753597]\n",
      "[Epoch 1/2] [Batch 611/938] [D loss: 0.642586] [G loss: 0.781939]\n",
      "[Epoch 1/2] [Batch 612/938] [D loss: 0.629698] [G loss: 0.761645]\n",
      "[Epoch 1/2] [Batch 613/938] [D loss: 0.677321] [G loss: 0.708497]\n",
      "[Epoch 1/2] [Batch 614/938] [D loss: 0.661677] [G loss: 0.792974]\n",
      "[Epoch 1/2] [Batch 615/938] [D loss: 0.678451] [G loss: 0.747046]\n",
      "[Epoch 1/2] [Batch 616/938] [D loss: 0.660602] [G loss: 0.775308]\n",
      "[Epoch 1/2] [Batch 617/938] [D loss: 0.649108] [G loss: 0.770519]\n",
      "[Epoch 1/2] [Batch 618/938] [D loss: 0.606113] [G loss: 0.797671]\n",
      "[Epoch 1/2] [Batch 619/938] [D loss: 0.647032] [G loss: 0.705437]\n",
      "[Epoch 1/2] [Batch 620/938] [D loss: 0.683591] [G loss: 0.739456]\n",
      "[Epoch 1/2] [Batch 621/938] [D loss: 0.654486] [G loss: 0.718289]\n",
      "[Epoch 1/2] [Batch 622/938] [D loss: 0.669272] [G loss: 0.812020]\n",
      "[Epoch 1/2] [Batch 623/938] [D loss: 0.683229] [G loss: 0.789023]\n",
      "[Epoch 1/2] [Batch 624/938] [D loss: 0.631770] [G loss: 0.855799]\n",
      "[Epoch 1/2] [Batch 625/938] [D loss: 0.655849] [G loss: 0.754736]\n",
      "[Epoch 1/2] [Batch 626/938] [D loss: 0.658901] [G loss: 0.702174]\n",
      "[Epoch 1/2] [Batch 627/938] [D loss: 0.667738] [G loss: 0.728569]\n",
      "[Epoch 1/2] [Batch 628/938] [D loss: 0.654551] [G loss: 0.874319]\n",
      "[Epoch 1/2] [Batch 629/938] [D loss: 0.701996] [G loss: 0.825679]\n",
      "[Epoch 1/2] [Batch 630/938] [D loss: 0.695716] [G loss: 0.784848]\n",
      "[Epoch 1/2] [Batch 631/938] [D loss: 0.664648] [G loss: 0.667350]\n",
      "[Epoch 1/2] [Batch 632/938] [D loss: 0.687846] [G loss: 0.691001]\n",
      "[Epoch 1/2] [Batch 633/938] [D loss: 0.658706] [G loss: 0.781524]\n",
      "[Epoch 1/2] [Batch 634/938] [D loss: 0.648346] [G loss: 0.774860]\n",
      "[Epoch 1/2] [Batch 635/938] [D loss: 0.691004] [G loss: 0.750515]\n",
      "[Epoch 1/2] [Batch 636/938] [D loss: 0.710564] [G loss: 0.757356]\n",
      "[Epoch 1/2] [Batch 637/938] [D loss: 0.686090] [G loss: 0.810492]\n",
      "[Epoch 1/2] [Batch 638/938] [D loss: 0.674752] [G loss: 0.803265]\n",
      "[Epoch 1/2] [Batch 639/938] [D loss: 0.685416] [G loss: 0.817896]\n",
      "[Epoch 1/2] [Batch 640/938] [D loss: 0.679996] [G loss: 0.797148]\n",
      "[Epoch 1/2] [Batch 641/938] [D loss: 0.640242] [G loss: 0.735557]\n",
      "[Epoch 1/2] [Batch 642/938] [D loss: 0.631989] [G loss: 0.757533]\n",
      "[Epoch 1/2] [Batch 643/938] [D loss: 0.687896] [G loss: 0.725708]\n",
      "[Epoch 1/2] [Batch 644/938] [D loss: 0.651363] [G loss: 0.848979]\n",
      "[Epoch 1/2] [Batch 645/938] [D loss: 0.683774] [G loss: 0.863257]\n",
      "[Epoch 1/2] [Batch 646/938] [D loss: 0.653223] [G loss: 0.785421]\n",
      "[Epoch 1/2] [Batch 647/938] [D loss: 0.680578] [G loss: 0.852605]\n",
      "[Epoch 1/2] [Batch 648/938] [D loss: 0.661816] [G loss: 0.722839]\n",
      "[Epoch 1/2] [Batch 649/938] [D loss: 0.693756] [G loss: 0.694102]\n",
      "[Epoch 1/2] [Batch 650/938] [D loss: 0.689824] [G loss: 0.811771]\n",
      "[Epoch 1/2] [Batch 651/938] [D loss: 0.659452] [G loss: 0.829645]\n",
      "[Epoch 1/2] [Batch 652/938] [D loss: 0.671893] [G loss: 0.792782]\n",
      "[Epoch 1/2] [Batch 653/938] [D loss: 0.706566] [G loss: 0.722615]\n",
      "[Epoch 1/2] [Batch 654/938] [D loss: 0.645976] [G loss: 0.740940]\n",
      "[Epoch 1/2] [Batch 655/938] [D loss: 0.693656] [G loss: 0.687416]\n",
      "[Epoch 1/2] [Batch 656/938] [D loss: 0.677130] [G loss: 0.753677]\n",
      "[Epoch 1/2] [Batch 657/938] [D loss: 0.645151] [G loss: 0.759710]\n",
      "[Epoch 1/2] [Batch 658/938] [D loss: 0.655459] [G loss: 0.734473]\n",
      "[Epoch 1/2] [Batch 659/938] [D loss: 0.675227] [G loss: 0.725666]\n",
      "[Epoch 1/2] [Batch 660/938] [D loss: 0.699920] [G loss: 0.721126]\n",
      "[Epoch 1/2] [Batch 661/938] [D loss: 0.658551] [G loss: 0.774258]\n",
      "[Epoch 1/2] [Batch 662/938] [D loss: 0.643747] [G loss: 0.795835]\n",
      "[Epoch 1/2] [Batch 663/938] [D loss: 0.684019] [G loss: 0.810622]\n",
      "[Epoch 1/2] [Batch 664/938] [D loss: 0.656424] [G loss: 0.746828]\n",
      "[Epoch 1/2] [Batch 665/938] [D loss: 0.658733] [G loss: 0.724189]\n",
      "[Epoch 1/2] [Batch 666/938] [D loss: 0.671965] [G loss: 0.800384]\n",
      "[Epoch 1/2] [Batch 667/938] [D loss: 0.657562] [G loss: 0.791903]\n",
      "[Epoch 1/2] [Batch 668/938] [D loss: 0.692048] [G loss: 0.739152]\n",
      "[Epoch 1/2] [Batch 669/938] [D loss: 0.641405] [G loss: 0.733785]\n",
      "[Epoch 1/2] [Batch 670/938] [D loss: 0.654714] [G loss: 0.749447]\n",
      "[Epoch 1/2] [Batch 671/938] [D loss: 0.649333] [G loss: 0.706920]\n",
      "[Epoch 1/2] [Batch 672/938] [D loss: 0.646510] [G loss: 0.740134]\n",
      "[Epoch 1/2] [Batch 673/938] [D loss: 0.691692] [G loss: 0.809238]\n",
      "[Epoch 1/2] [Batch 674/938] [D loss: 0.670132] [G loss: 0.730670]\n",
      "[Epoch 1/2] [Batch 675/938] [D loss: 0.626737] [G loss: 0.762051]\n",
      "[Epoch 1/2] [Batch 676/938] [D loss: 0.641538] [G loss: 0.805549]\n",
      "[Epoch 1/2] [Batch 677/938] [D loss: 0.689533] [G loss: 0.689264]\n",
      "[Epoch 1/2] [Batch 678/938] [D loss: 0.645476] [G loss: 0.631097]\n",
      "[Epoch 1/2] [Batch 679/938] [D loss: 0.662370] [G loss: 0.645551]\n",
      "[Epoch 1/2] [Batch 680/938] [D loss: 0.705503] [G loss: 0.785063]\n",
      "[Epoch 1/2] [Batch 681/938] [D loss: 0.677243] [G loss: 0.755378]\n",
      "[Epoch 1/2] [Batch 682/938] [D loss: 0.683479] [G loss: 0.807359]\n",
      "[Epoch 1/2] [Batch 683/938] [D loss: 0.648376] [G loss: 0.834492]\n",
      "[Epoch 1/2] [Batch 684/938] [D loss: 0.643222] [G loss: 0.759296]\n",
      "[Epoch 1/2] [Batch 685/938] [D loss: 0.649212] [G loss: 0.777876]\n",
      "[Epoch 1/2] [Batch 686/938] [D loss: 0.664223] [G loss: 0.680872]\n",
      "[Epoch 1/2] [Batch 687/938] [D loss: 0.650887] [G loss: 0.714423]\n",
      "[Epoch 1/2] [Batch 688/938] [D loss: 0.700606] [G loss: 0.718053]\n",
      "[Epoch 1/2] [Batch 689/938] [D loss: 0.687140] [G loss: 0.809730]\n",
      "[Epoch 1/2] [Batch 690/938] [D loss: 0.677549] [G loss: 0.781310]\n",
      "[Epoch 1/2] [Batch 691/938] [D loss: 0.687120] [G loss: 0.776219]\n",
      "[Epoch 1/2] [Batch 692/938] [D loss: 0.652294] [G loss: 0.772806]\n",
      "[Epoch 1/2] [Batch 693/938] [D loss: 0.690641] [G loss: 0.804880]\n",
      "[Epoch 1/2] [Batch 694/938] [D loss: 0.676998] [G loss: 0.772595]\n",
      "[Epoch 1/2] [Batch 695/938] [D loss: 0.657544] [G loss: 0.770294]\n",
      "[Epoch 1/2] [Batch 696/938] [D loss: 0.664484] [G loss: 0.725177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 697/938] [D loss: 0.680287] [G loss: 0.749564]\n",
      "[Epoch 1/2] [Batch 698/938] [D loss: 0.655953] [G loss: 0.740725]\n",
      "[Epoch 1/2] [Batch 699/938] [D loss: 0.691797] [G loss: 0.823180]\n",
      "[Epoch 1/2] [Batch 700/938] [D loss: 0.632593] [G loss: 0.821316]\n",
      "[Epoch 1/2] [Batch 701/938] [D loss: 0.637007] [G loss: 0.807748]\n",
      "[Epoch 1/2] [Batch 702/938] [D loss: 0.676359] [G loss: 0.852268]\n",
      "[Epoch 1/2] [Batch 703/938] [D loss: 0.689167] [G loss: 0.778329]\n",
      "[Epoch 1/2] [Batch 704/938] [D loss: 0.660801] [G loss: 0.667401]\n",
      "[Epoch 1/2] [Batch 705/938] [D loss: 0.675981] [G loss: 0.725937]\n",
      "[Epoch 1/2] [Batch 706/938] [D loss: 0.703388] [G loss: 0.765276]\n",
      "[Epoch 1/2] [Batch 707/938] [D loss: 0.677912] [G loss: 0.830258]\n",
      "[Epoch 1/2] [Batch 708/938] [D loss: 0.640332] [G loss: 0.791510]\n",
      "[Epoch 1/2] [Batch 709/938] [D loss: 0.634379] [G loss: 0.679893]\n",
      "[Epoch 1/2] [Batch 710/938] [D loss: 0.684543] [G loss: 0.703891]\n",
      "[Epoch 1/2] [Batch 711/938] [D loss: 0.656535] [G loss: 0.734000]\n",
      "[Epoch 1/2] [Batch 712/938] [D loss: 0.668570] [G loss: 0.765275]\n",
      "[Epoch 1/2] [Batch 713/938] [D loss: 0.657331] [G loss: 0.804239]\n",
      "[Epoch 1/2] [Batch 714/938] [D loss: 0.642126] [G loss: 0.806417]\n",
      "[Epoch 1/2] [Batch 715/938] [D loss: 0.639014] [G loss: 0.745531]\n",
      "[Epoch 1/2] [Batch 716/938] [D loss: 0.656595] [G loss: 0.724292]\n",
      "[Epoch 1/2] [Batch 717/938] [D loss: 0.684964] [G loss: 0.657183]\n",
      "[Epoch 1/2] [Batch 718/938] [D loss: 0.684850] [G loss: 0.780578]\n",
      "[Epoch 1/2] [Batch 719/938] [D loss: 0.678879] [G loss: 0.814652]\n",
      "[Epoch 1/2] [Batch 720/938] [D loss: 0.662133] [G loss: 0.767046]\n",
      "[Epoch 1/2] [Batch 721/938] [D loss: 0.675092] [G loss: 0.705400]\n",
      "[Epoch 1/2] [Batch 722/938] [D loss: 0.681919] [G loss: 0.765593]\n",
      "[Epoch 1/2] [Batch 723/938] [D loss: 0.677194] [G loss: 0.787723]\n",
      "[Epoch 1/2] [Batch 724/938] [D loss: 0.676567] [G loss: 0.810589]\n",
      "[Epoch 1/2] [Batch 725/938] [D loss: 0.673876] [G loss: 0.698075]\n",
      "[Epoch 1/2] [Batch 726/938] [D loss: 0.654070] [G loss: 0.748564]\n",
      "[Epoch 1/2] [Batch 727/938] [D loss: 0.649397] [G loss: 0.781587]\n",
      "[Epoch 1/2] [Batch 728/938] [D loss: 0.639850] [G loss: 0.813094]\n",
      "[Epoch 1/2] [Batch 729/938] [D loss: 0.657153] [G loss: 0.766177]\n",
      "[Epoch 1/2] [Batch 730/938] [D loss: 0.638783] [G loss: 0.812328]\n",
      "[Epoch 1/2] [Batch 731/938] [D loss: 0.678653] [G loss: 0.761605]\n",
      "[Epoch 1/2] [Batch 732/938] [D loss: 0.682763] [G loss: 0.740774]\n",
      "[Epoch 1/2] [Batch 733/938] [D loss: 0.663918] [G loss: 0.749150]\n",
      "[Epoch 1/2] [Batch 734/938] [D loss: 0.649128] [G loss: 0.719574]\n",
      "[Epoch 1/2] [Batch 735/938] [D loss: 0.697307] [G loss: 0.744828]\n",
      "[Epoch 1/2] [Batch 736/938] [D loss: 0.634487] [G loss: 0.679168]\n",
      "[Epoch 1/2] [Batch 737/938] [D loss: 0.691949] [G loss: 0.814428]\n",
      "[Epoch 1/2] [Batch 738/938] [D loss: 0.671218] [G loss: 0.756948]\n",
      "[Epoch 1/2] [Batch 739/938] [D loss: 0.695883] [G loss: 0.775781]\n",
      "[Epoch 1/2] [Batch 740/938] [D loss: 0.653217] [G loss: 0.799618]\n",
      "[Epoch 1/2] [Batch 741/938] [D loss: 0.682874] [G loss: 0.818468]\n",
      "[Epoch 1/2] [Batch 742/938] [D loss: 0.677625] [G loss: 0.785542]\n",
      "[Epoch 1/2] [Batch 743/938] [D loss: 0.651356] [G loss: 0.774463]\n",
      "[Epoch 1/2] [Batch 744/938] [D loss: 0.677456] [G loss: 0.745261]\n",
      "[Epoch 1/2] [Batch 745/938] [D loss: 0.653010] [G loss: 0.778579]\n",
      "[Epoch 1/2] [Batch 746/938] [D loss: 0.635210] [G loss: 0.760839]\n",
      "[Epoch 1/2] [Batch 747/938] [D loss: 0.654102] [G loss: 0.738579]\n",
      "[Epoch 1/2] [Batch 748/938] [D loss: 0.625518] [G loss: 0.772532]\n",
      "[Epoch 1/2] [Batch 749/938] [D loss: 0.662089] [G loss: 0.700780]\n",
      "[Epoch 1/2] [Batch 750/938] [D loss: 0.681603] [G loss: 0.786864]\n",
      "[Epoch 1/2] [Batch 751/938] [D loss: 0.697551] [G loss: 0.802043]\n",
      "[Epoch 1/2] [Batch 752/938] [D loss: 0.679131] [G loss: 0.734992]\n",
      "[Epoch 1/2] [Batch 753/938] [D loss: 0.671473] [G loss: 0.754388]\n",
      "[Epoch 1/2] [Batch 754/938] [D loss: 0.633450] [G loss: 0.801802]\n",
      "[Epoch 1/2] [Batch 755/938] [D loss: 0.658989] [G loss: 0.758812]\n",
      "[Epoch 1/2] [Batch 756/938] [D loss: 0.674658] [G loss: 0.776458]\n",
      "[Epoch 1/2] [Batch 757/938] [D loss: 0.658935] [G loss: 0.741786]\n",
      "[Epoch 1/2] [Batch 758/938] [D loss: 0.660138] [G loss: 0.715619]\n",
      "[Epoch 1/2] [Batch 759/938] [D loss: 0.624909] [G loss: 0.690889]\n",
      "[Epoch 1/2] [Batch 760/938] [D loss: 0.681697] [G loss: 0.698467]\n",
      "[Epoch 1/2] [Batch 761/938] [D loss: 0.655183] [G loss: 0.780420]\n",
      "[Epoch 1/2] [Batch 762/938] [D loss: 0.685089] [G loss: 0.812811]\n",
      "[Epoch 1/2] [Batch 763/938] [D loss: 0.679000] [G loss: 0.883490]\n",
      "[Epoch 1/2] [Batch 764/938] [D loss: 0.634542] [G loss: 0.702376]\n",
      "[Epoch 1/2] [Batch 765/938] [D loss: 0.713230] [G loss: 0.725242]\n",
      "[Epoch 1/2] [Batch 766/938] [D loss: 0.664239] [G loss: 0.725224]\n",
      "[Epoch 1/2] [Batch 767/938] [D loss: 0.653619] [G loss: 0.748699]\n",
      "[Epoch 1/2] [Batch 768/938] [D loss: 0.673297] [G loss: 0.761286]\n",
      "[Epoch 1/2] [Batch 769/938] [D loss: 0.686567] [G loss: 0.691990]\n",
      "[Epoch 1/2] [Batch 770/938] [D loss: 0.692860] [G loss: 0.745427]\n",
      "[Epoch 1/2] [Batch 771/938] [D loss: 0.699143] [G loss: 0.782676]\n",
      "[Epoch 1/2] [Batch 772/938] [D loss: 0.671037] [G loss: 0.795953]\n",
      "[Epoch 1/2] [Batch 773/938] [D loss: 0.693292] [G loss: 0.756318]\n",
      "[Epoch 1/2] [Batch 774/938] [D loss: 0.670826] [G loss: 0.722010]\n",
      "[Epoch 1/2] [Batch 775/938] [D loss: 0.645388] [G loss: 0.721009]\n",
      "[Epoch 1/2] [Batch 776/938] [D loss: 0.659362] [G loss: 0.712186]\n",
      "[Epoch 1/2] [Batch 777/938] [D loss: 0.620690] [G loss: 0.711391]\n",
      "[Epoch 1/2] [Batch 778/938] [D loss: 0.659726] [G loss: 0.785254]\n",
      "[Epoch 1/2] [Batch 779/938] [D loss: 0.665936] [G loss: 0.887330]\n",
      "[Epoch 1/2] [Batch 780/938] [D loss: 0.657802] [G loss: 0.828623]\n",
      "[Epoch 1/2] [Batch 781/938] [D loss: 0.636427] [G loss: 0.752754]\n",
      "[Epoch 1/2] [Batch 782/938] [D loss: 0.663927] [G loss: 0.761511]\n",
      "[Epoch 1/2] [Batch 783/938] [D loss: 0.652523] [G loss: 0.741747]\n",
      "[Epoch 1/2] [Batch 784/938] [D loss: 0.655072] [G loss: 0.829542]\n",
      "[Epoch 1/2] [Batch 785/938] [D loss: 0.672137] [G loss: 0.698089]\n",
      "[Epoch 1/2] [Batch 786/938] [D loss: 0.696750] [G loss: 0.785371]\n",
      "[Epoch 1/2] [Batch 787/938] [D loss: 0.666420] [G loss: 0.811453]\n",
      "[Epoch 1/2] [Batch 788/938] [D loss: 0.645673] [G loss: 0.808190]\n",
      "[Epoch 1/2] [Batch 789/938] [D loss: 0.669921] [G loss: 0.717066]\n",
      "[Epoch 1/2] [Batch 790/938] [D loss: 0.656689] [G loss: 0.800187]\n",
      "[Epoch 1/2] [Batch 791/938] [D loss: 0.652337] [G loss: 0.724682]\n",
      "[Epoch 1/2] [Batch 792/938] [D loss: 0.664361] [G loss: 0.834958]\n",
      "[Epoch 1/2] [Batch 793/938] [D loss: 0.640356] [G loss: 0.798944]\n",
      "[Epoch 1/2] [Batch 794/938] [D loss: 0.651904] [G loss: 0.778221]\n",
      "[Epoch 1/2] [Batch 795/938] [D loss: 0.654439] [G loss: 0.698321]\n",
      "[Epoch 1/2] [Batch 796/938] [D loss: 0.666559] [G loss: 0.746139]\n",
      "[Epoch 1/2] [Batch 797/938] [D loss: 0.670914] [G loss: 0.736456]\n",
      "[Epoch 1/2] [Batch 798/938] [D loss: 0.645319] [G loss: 0.818790]\n",
      "[Epoch 1/2] [Batch 799/938] [D loss: 0.665427] [G loss: 0.807669]\n",
      "[Epoch 1/2] [Batch 800/938] [D loss: 0.631995] [G loss: 0.737412]\n",
      "[Epoch 1/2] [Batch 801/938] [D loss: 0.661073] [G loss: 0.749737]\n",
      "[Epoch 1/2] [Batch 802/938] [D loss: 0.663328] [G loss: 0.671101]\n",
      "[Epoch 1/2] [Batch 803/938] [D loss: 0.691020] [G loss: 0.772231]\n",
      "[Epoch 1/2] [Batch 804/938] [D loss: 0.701057] [G loss: 0.760363]\n",
      "[Epoch 1/2] [Batch 805/938] [D loss: 0.680686] [G loss: 0.832601]\n",
      "[Epoch 1/2] [Batch 806/938] [D loss: 0.636675] [G loss: 0.753341]\n",
      "[Epoch 1/2] [Batch 807/938] [D loss: 0.676924] [G loss: 0.746657]\n",
      "[Epoch 1/2] [Batch 808/938] [D loss: 0.673006] [G loss: 0.747813]\n",
      "[Epoch 1/2] [Batch 809/938] [D loss: 0.644786] [G loss: 0.824092]\n",
      "[Epoch 1/2] [Batch 810/938] [D loss: 0.685369] [G loss: 0.789067]\n",
      "[Epoch 1/2] [Batch 811/938] [D loss: 0.687935] [G loss: 0.764077]\n",
      "[Epoch 1/2] [Batch 812/938] [D loss: 0.658053] [G loss: 0.762898]\n",
      "[Epoch 1/2] [Batch 813/938] [D loss: 0.633332] [G loss: 0.746819]\n",
      "[Epoch 1/2] [Batch 814/938] [D loss: 0.683033] [G loss: 0.678314]\n",
      "[Epoch 1/2] [Batch 815/938] [D loss: 0.683441] [G loss: 0.730732]\n",
      "[Epoch 1/2] [Batch 816/938] [D loss: 0.676487] [G loss: 0.783729]\n",
      "[Epoch 1/2] [Batch 817/938] [D loss: 0.649496] [G loss: 0.744889]\n",
      "[Epoch 1/2] [Batch 818/938] [D loss: 0.663826] [G loss: 0.762175]\n",
      "[Epoch 1/2] [Batch 819/938] [D loss: 0.645654] [G loss: 0.799229]\n",
      "[Epoch 1/2] [Batch 820/938] [D loss: 0.670288] [G loss: 0.765211]\n",
      "[Epoch 1/2] [Batch 821/938] [D loss: 0.651213] [G loss: 0.792874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 822/938] [D loss: 0.673556] [G loss: 0.799171]\n",
      "[Epoch 1/2] [Batch 823/938] [D loss: 0.650048] [G loss: 0.817710]\n",
      "[Epoch 1/2] [Batch 824/938] [D loss: 0.686721] [G loss: 0.848450]\n",
      "[Epoch 1/2] [Batch 825/938] [D loss: 0.713508] [G loss: 0.704641]\n",
      "[Epoch 1/2] [Batch 826/938] [D loss: 0.667968] [G loss: 0.696329]\n",
      "[Epoch 1/2] [Batch 827/938] [D loss: 0.661082] [G loss: 0.727381]\n",
      "[Epoch 1/2] [Batch 828/938] [D loss: 0.655563] [G loss: 0.779548]\n",
      "[Epoch 1/2] [Batch 829/938] [D loss: 0.655811] [G loss: 0.808161]\n",
      "[Epoch 1/2] [Batch 830/938] [D loss: 0.652994] [G loss: 0.762159]\n",
      "[Epoch 1/2] [Batch 831/938] [D loss: 0.671419] [G loss: 0.805354]\n",
      "[Epoch 1/2] [Batch 832/938] [D loss: 0.677128] [G loss: 0.777444]\n",
      "[Epoch 1/2] [Batch 833/938] [D loss: 0.661790] [G loss: 0.728080]\n",
      "[Epoch 1/2] [Batch 834/938] [D loss: 0.675518] [G loss: 0.714644]\n",
      "[Epoch 1/2] [Batch 835/938] [D loss: 0.664765] [G loss: 0.801351]\n",
      "[Epoch 1/2] [Batch 836/938] [D loss: 0.673862] [G loss: 0.754109]\n",
      "[Epoch 1/2] [Batch 837/938] [D loss: 0.667261] [G loss: 0.773085]\n",
      "[Epoch 1/2] [Batch 838/938] [D loss: 0.626594] [G loss: 0.736735]\n",
      "[Epoch 1/2] [Batch 839/938] [D loss: 0.694242] [G loss: 0.673710]\n",
      "[Epoch 1/2] [Batch 840/938] [D loss: 0.668979] [G loss: 0.786025]\n",
      "[Epoch 1/2] [Batch 841/938] [D loss: 0.682811] [G loss: 0.726192]\n",
      "[Epoch 1/2] [Batch 842/938] [D loss: 0.688836] [G loss: 0.788745]\n",
      "[Epoch 1/2] [Batch 843/938] [D loss: 0.693841] [G loss: 0.850805]\n",
      "[Epoch 1/2] [Batch 844/938] [D loss: 0.655025] [G loss: 0.771392]\n",
      "[Epoch 1/2] [Batch 845/938] [D loss: 0.698632] [G loss: 0.753098]\n",
      "[Epoch 1/2] [Batch 846/938] [D loss: 0.662983] [G loss: 0.681047]\n",
      "[Epoch 1/2] [Batch 847/938] [D loss: 0.653126] [G loss: 0.745826]\n",
      "[Epoch 1/2] [Batch 848/938] [D loss: 0.655779] [G loss: 0.714222]\n",
      "[Epoch 1/2] [Batch 849/938] [D loss: 0.628375] [G loss: 0.792673]\n",
      "[Epoch 1/2] [Batch 850/938] [D loss: 0.663131] [G loss: 0.756169]\n",
      "[Epoch 1/2] [Batch 851/938] [D loss: 0.656724] [G loss: 0.765064]\n",
      "[Epoch 1/2] [Batch 852/938] [D loss: 0.650616] [G loss: 0.696684]\n",
      "[Epoch 1/2] [Batch 853/938] [D loss: 0.633366] [G loss: 0.698717]\n",
      "[Epoch 1/2] [Batch 854/938] [D loss: 0.667714] [G loss: 0.700944]\n",
      "[Epoch 1/2] [Batch 855/938] [D loss: 0.709608] [G loss: 0.680847]\n",
      "[Epoch 1/2] [Batch 856/938] [D loss: 0.682241] [G loss: 0.751784]\n",
      "[Epoch 1/2] [Batch 857/938] [D loss: 0.646398] [G loss: 0.875419]\n",
      "[Epoch 1/2] [Batch 858/938] [D loss: 0.689077] [G loss: 0.803758]\n",
      "[Epoch 1/2] [Batch 859/938] [D loss: 0.695574] [G loss: 0.729358]\n",
      "[Epoch 1/2] [Batch 860/938] [D loss: 0.629345] [G loss: 0.767814]\n",
      "[Epoch 1/2] [Batch 861/938] [D loss: 0.631923] [G loss: 0.772591]\n",
      "[Epoch 1/2] [Batch 862/938] [D loss: 0.691183] [G loss: 0.758276]\n",
      "[Epoch 1/2] [Batch 863/938] [D loss: 0.622907] [G loss: 0.757054]\n",
      "[Epoch 1/2] [Batch 864/938] [D loss: 0.666937] [G loss: 0.904334]\n",
      "[Epoch 1/2] [Batch 865/938] [D loss: 0.669193] [G loss: 0.785643]\n",
      "[Epoch 1/2] [Batch 866/938] [D loss: 0.660235] [G loss: 0.723594]\n",
      "[Epoch 1/2] [Batch 867/938] [D loss: 0.687547] [G loss: 0.736141]\n",
      "[Epoch 1/2] [Batch 868/938] [D loss: 0.664447] [G loss: 0.735560]\n",
      "[Epoch 1/2] [Batch 869/938] [D loss: 0.650027] [G loss: 0.656005]\n",
      "[Epoch 1/2] [Batch 870/938] [D loss: 0.693547] [G loss: 0.762856]\n",
      "[Epoch 1/2] [Batch 871/938] [D loss: 0.669852] [G loss: 0.733798]\n",
      "[Epoch 1/2] [Batch 872/938] [D loss: 0.694270] [G loss: 0.774327]\n",
      "[Epoch 1/2] [Batch 873/938] [D loss: 0.662567] [G loss: 0.752440]\n",
      "[Epoch 1/2] [Batch 874/938] [D loss: 0.674872] [G loss: 0.787203]\n",
      "[Epoch 1/2] [Batch 875/938] [D loss: 0.658154] [G loss: 0.756607]\n",
      "[Epoch 1/2] [Batch 876/938] [D loss: 0.642700] [G loss: 0.793942]\n",
      "[Epoch 1/2] [Batch 877/938] [D loss: 0.633751] [G loss: 0.734512]\n",
      "[Epoch 1/2] [Batch 878/938] [D loss: 0.668252] [G loss: 0.740009]\n",
      "[Epoch 1/2] [Batch 879/938] [D loss: 0.676574] [G loss: 0.706234]\n",
      "[Epoch 1/2] [Batch 880/938] [D loss: 0.671537] [G loss: 0.724262]\n",
      "[Epoch 1/2] [Batch 881/938] [D loss: 0.674392] [G loss: 0.715189]\n",
      "[Epoch 1/2] [Batch 882/938] [D loss: 0.665564] [G loss: 0.731989]\n",
      "[Epoch 1/2] [Batch 883/938] [D loss: 0.615073] [G loss: 0.813464]\n",
      "[Epoch 1/2] [Batch 884/938] [D loss: 0.665729] [G loss: 0.739714]\n",
      "[Epoch 1/2] [Batch 885/938] [D loss: 0.661503] [G loss: 0.718320]\n",
      "[Epoch 1/2] [Batch 886/938] [D loss: 0.699932] [G loss: 0.735386]\n",
      "[Epoch 1/2] [Batch 887/938] [D loss: 0.635064] [G loss: 0.766896]\n",
      "[Epoch 1/2] [Batch 888/938] [D loss: 0.666701] [G loss: 0.710669]\n",
      "[Epoch 1/2] [Batch 889/938] [D loss: 0.667567] [G loss: 0.624949]\n",
      "[Epoch 1/2] [Batch 890/938] [D loss: 0.643798] [G loss: 0.726062]\n",
      "[Epoch 1/2] [Batch 891/938] [D loss: 0.664999] [G loss: 0.848530]\n",
      "[Epoch 1/2] [Batch 892/938] [D loss: 0.648594] [G loss: 0.779336]\n",
      "[Epoch 1/2] [Batch 893/938] [D loss: 0.663991] [G loss: 0.785727]\n",
      "[Epoch 1/2] [Batch 894/938] [D loss: 0.666008] [G loss: 0.726043]\n",
      "[Epoch 1/2] [Batch 895/938] [D loss: 0.647699] [G loss: 0.740676]\n",
      "[Epoch 1/2] [Batch 896/938] [D loss: 0.721286] [G loss: 0.764870]\n",
      "[Epoch 1/2] [Batch 897/938] [D loss: 0.699543] [G loss: 0.774821]\n",
      "[Epoch 1/2] [Batch 898/938] [D loss: 0.671188] [G loss: 0.793129]\n",
      "[Epoch 1/2] [Batch 899/938] [D loss: 0.672337] [G loss: 0.874985]\n",
      "[Epoch 1/2] [Batch 900/938] [D loss: 0.670298] [G loss: 0.828215]\n",
      "[Epoch 1/2] [Batch 901/938] [D loss: 0.657360] [G loss: 0.793221]\n",
      "[Epoch 1/2] [Batch 902/938] [D loss: 0.667270] [G loss: 0.720693]\n",
      "[Epoch 1/2] [Batch 903/938] [D loss: 0.633682] [G loss: 0.797358]\n",
      "[Epoch 1/2] [Batch 904/938] [D loss: 0.681663] [G loss: 0.713588]\n",
      "[Epoch 1/2] [Batch 905/938] [D loss: 0.692637] [G loss: 0.722978]\n",
      "[Epoch 1/2] [Batch 906/938] [D loss: 0.666959] [G loss: 0.786207]\n",
      "[Epoch 1/2] [Batch 907/938] [D loss: 0.661210] [G loss: 0.785151]\n",
      "[Epoch 1/2] [Batch 908/938] [D loss: 0.659397] [G loss: 0.747817]\n",
      "[Epoch 1/2] [Batch 909/938] [D loss: 0.670670] [G loss: 0.750668]\n",
      "[Epoch 1/2] [Batch 910/938] [D loss: 0.641329] [G loss: 0.732744]\n",
      "[Epoch 1/2] [Batch 911/938] [D loss: 0.663665] [G loss: 0.776011]\n",
      "[Epoch 1/2] [Batch 912/938] [D loss: 0.671041] [G loss: 0.786227]\n",
      "[Epoch 1/2] [Batch 913/938] [D loss: 0.642935] [G loss: 0.760566]\n",
      "[Epoch 1/2] [Batch 914/938] [D loss: 0.676242] [G loss: 0.711221]\n",
      "[Epoch 1/2] [Batch 915/938] [D loss: 0.675916] [G loss: 0.744054]\n",
      "[Epoch 1/2] [Batch 916/938] [D loss: 0.696344] [G loss: 0.741869]\n",
      "[Epoch 1/2] [Batch 917/938] [D loss: 0.643768] [G loss: 0.785695]\n",
      "[Epoch 1/2] [Batch 918/938] [D loss: 0.645602] [G loss: 0.697988]\n",
      "[Epoch 1/2] [Batch 919/938] [D loss: 0.621006] [G loss: 0.683314]\n",
      "[Epoch 1/2] [Batch 920/938] [D loss: 0.678630] [G loss: 0.790845]\n",
      "[Epoch 1/2] [Batch 921/938] [D loss: 0.661992] [G loss: 0.747136]\n",
      "[Epoch 1/2] [Batch 922/938] [D loss: 0.651734] [G loss: 0.800001]\n",
      "[Epoch 1/2] [Batch 923/938] [D loss: 0.643965] [G loss: 0.688559]\n",
      "[Epoch 1/2] [Batch 924/938] [D loss: 0.661117] [G loss: 0.678530]\n",
      "[Epoch 1/2] [Batch 925/938] [D loss: 0.685133] [G loss: 0.757833]\n",
      "[Epoch 1/2] [Batch 926/938] [D loss: 0.671844] [G loss: 0.775817]\n",
      "[Epoch 1/2] [Batch 927/938] [D loss: 0.659905] [G loss: 0.824361]\n",
      "[Epoch 1/2] [Batch 928/938] [D loss: 0.645807] [G loss: 0.825209]\n",
      "[Epoch 1/2] [Batch 929/938] [D loss: 0.635864] [G loss: 0.735232]\n",
      "[Epoch 1/2] [Batch 930/938] [D loss: 0.642024] [G loss: 0.752936]\n",
      "[Epoch 1/2] [Batch 931/938] [D loss: 0.634997] [G loss: 0.719367]\n",
      "[Epoch 1/2] [Batch 932/938] [D loss: 0.665692] [G loss: 0.827259]\n",
      "[Epoch 1/2] [Batch 933/938] [D loss: 0.649553] [G loss: 0.877762]\n",
      "[Epoch 1/2] [Batch 934/938] [D loss: 0.703525] [G loss: 0.850550]\n",
      "[Epoch 1/2] [Batch 935/938] [D loss: 0.657252] [G loss: 0.780740]\n",
      "[Epoch 1/2] [Batch 936/938] [D loss: 0.681524] [G loss: 0.727227]\n",
      "[Epoch 1/2] [Batch 937/938] [D loss: 0.645177] [G loss: 0.676911]\n",
      "saving states\n"
     ]
    }
   ],
   "source": [
    "DCGAN = gan.DCGAN(\"mnist_dcgan\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(DCGAN.identifier)\n",
    "with mlflow.start_run(experiment_id=DCGAN.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    DCGAN.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=1,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "[Epoch 0/2] [Batch 0/938] [D loss: 8.338694] [G loss: -0.034286]\n",
      "saving states\n",
      "[Epoch 0/2] [Batch 5/938] [D loss: 4.228947] [G loss: -0.042754]\n",
      "[Epoch 0/2] [Batch 10/938] [D loss: -5.872320] [G loss: -0.080434]\n",
      "[Epoch 0/2] [Batch 15/938] [D loss: -20.855030] [G loss: -0.205500]\n",
      "[Epoch 0/2] [Batch 20/938] [D loss: -33.967487] [G loss: -0.467806]\n",
      "[Epoch 0/2] [Batch 25/938] [D loss: -40.171349] [G loss: -0.804005]\n",
      "[Epoch 0/2] [Batch 30/938] [D loss: -40.587364] [G loss: -1.150115]\n",
      "[Epoch 0/2] [Batch 35/938] [D loss: -40.527969] [G loss: -1.461487]\n",
      "[Epoch 0/2] [Batch 40/938] [D loss: -40.401794] [G loss: -1.855785]\n",
      "[Epoch 0/2] [Batch 45/938] [D loss: -40.378300] [G loss: -2.148134]\n",
      "[Epoch 0/2] [Batch 50/938] [D loss: -40.284805] [G loss: -2.520683]\n",
      "[Epoch 0/2] [Batch 55/938] [D loss: -40.028637] [G loss: -3.047812]\n",
      "[Epoch 0/2] [Batch 60/938] [D loss: -38.714119] [G loss: -3.503300]\n",
      "[Epoch 0/2] [Batch 65/938] [D loss: -37.910328] [G loss: -4.069277]\n",
      "[Epoch 0/2] [Batch 70/938] [D loss: -37.648849] [G loss: -4.739200]\n",
      "[Epoch 0/2] [Batch 75/938] [D loss: -37.061741] [G loss: -5.076282]\n",
      "[Epoch 0/2] [Batch 80/938] [D loss: -36.824337] [G loss: -5.819731]\n",
      "[Epoch 0/2] [Batch 85/938] [D loss: -35.766335] [G loss: -6.519988]\n",
      "[Epoch 0/2] [Batch 90/938] [D loss: -35.752903] [G loss: -7.202643]\n",
      "[Epoch 0/2] [Batch 95/938] [D loss: -35.513973] [G loss: -7.904232]\n",
      "[Epoch 0/2] [Batch 100/938] [D loss: -33.304680] [G loss: -8.591360]\n",
      "[Epoch 0/2] [Batch 105/938] [D loss: -32.242382] [G loss: -9.875055]\n",
      "[Epoch 0/2] [Batch 110/938] [D loss: -31.910048] [G loss: -10.296494]\n",
      "[Epoch 0/2] [Batch 115/938] [D loss: -29.356503] [G loss: -12.148636]\n",
      "[Epoch 0/2] [Batch 120/938] [D loss: -28.035076] [G loss: -12.698895]\n",
      "[Epoch 0/2] [Batch 125/938] [D loss: -27.409222] [G loss: -13.712619]\n",
      "[Epoch 0/2] [Batch 130/938] [D loss: -24.848330] [G loss: -16.090828]\n",
      "[Epoch 0/2] [Batch 135/938] [D loss: -24.328352] [G loss: -15.801664]\n",
      "[Epoch 0/2] [Batch 140/938] [D loss: -22.568621] [G loss: -17.480202]\n",
      "[Epoch 0/2] [Batch 145/938] [D loss: -19.760496] [G loss: -19.025223]\n",
      "[Epoch 0/2] [Batch 150/938] [D loss: -17.417137] [G loss: -20.483814]\n",
      "[Epoch 0/2] [Batch 155/938] [D loss: -15.609505] [G loss: -21.571438]\n",
      "[Epoch 0/2] [Batch 160/938] [D loss: -14.957306] [G loss: -21.442455]\n",
      "[Epoch 0/2] [Batch 165/938] [D loss: -12.895464] [G loss: -22.278170]\n",
      "[Epoch 0/2] [Batch 170/938] [D loss: -13.316248] [G loss: -22.098095]\n",
      "[Epoch 0/2] [Batch 175/938] [D loss: -11.226737] [G loss: -22.183609]\n",
      "[Epoch 0/2] [Batch 180/938] [D loss: -10.327666] [G loss: -22.306385]\n",
      "[Epoch 0/2] [Batch 185/938] [D loss: -9.960020] [G loss: -21.625710]\n",
      "[Epoch 0/2] [Batch 190/938] [D loss: -6.689660] [G loss: -22.814354]\n",
      "[Epoch 0/2] [Batch 195/938] [D loss: -7.795908] [G loss: -21.929047]\n",
      "[Epoch 0/2] [Batch 200/938] [D loss: -7.178296] [G loss: -22.692795]\n",
      "[Epoch 0/2] [Batch 205/938] [D loss: -6.319777] [G loss: -23.164906]\n",
      "[Epoch 0/2] [Batch 210/938] [D loss: -6.001019] [G loss: -22.532600]\n",
      "[Epoch 0/2] [Batch 215/938] [D loss: -5.886445] [G loss: -22.094719]\n",
      "[Epoch 0/2] [Batch 220/938] [D loss: -5.359752] [G loss: -21.886631]\n",
      "[Epoch 0/2] [Batch 225/938] [D loss: -4.590196] [G loss: -21.895649]\n",
      "[Epoch 0/2] [Batch 230/938] [D loss: -2.605791] [G loss: -23.217205]\n",
      "[Epoch 0/2] [Batch 235/938] [D loss: -4.759184] [G loss: -21.041559]\n",
      "[Epoch 0/2] [Batch 240/938] [D loss: -3.538959] [G loss: -21.532726]\n",
      "[Epoch 0/2] [Batch 245/938] [D loss: -3.446065] [G loss: -20.849655]\n",
      "[Epoch 0/2] [Batch 250/938] [D loss: -2.892324] [G loss: -21.364138]\n",
      "[Epoch 0/2] [Batch 255/938] [D loss: -2.526625] [G loss: -20.860134]\n",
      "[Epoch 0/2] [Batch 260/938] [D loss: -2.930706] [G loss: -19.991760]\n",
      "[Epoch 0/2] [Batch 265/938] [D loss: -2.804740] [G loss: -19.961784]\n",
      "[Epoch 0/2] [Batch 270/938] [D loss: -2.389486] [G loss: -19.648443]\n",
      "[Epoch 0/2] [Batch 275/938] [D loss: -2.894202] [G loss: -19.844204]\n",
      "[Epoch 0/2] [Batch 280/938] [D loss: -2.616924] [G loss: -19.902477]\n",
      "[Epoch 0/2] [Batch 285/938] [D loss: -1.841976] [G loss: -20.406311]\n",
      "[Epoch 0/2] [Batch 290/938] [D loss: -1.730466] [G loss: -20.541855]\n",
      "[Epoch 0/2] [Batch 295/938] [D loss: -2.270609] [G loss: -19.312397]\n",
      "[Epoch 0/2] [Batch 300/938] [D loss: -2.030986] [G loss: -18.686295]\n",
      "[Epoch 0/2] [Batch 305/938] [D loss: -2.339816] [G loss: -18.290859]\n",
      "[Epoch 0/2] [Batch 310/938] [D loss: -1.703847] [G loss: -18.160919]\n",
      "[Epoch 0/2] [Batch 315/938] [D loss: -1.537574] [G loss: -17.746056]\n",
      "[Epoch 0/2] [Batch 320/938] [D loss: -1.912237] [G loss: -17.341221]\n",
      "[Epoch 0/2] [Batch 325/938] [D loss: -1.827331] [G loss: -17.739052]\n",
      "[Epoch 0/2] [Batch 330/938] [D loss: -1.964961] [G loss: -17.412518]\n",
      "[Epoch 0/2] [Batch 335/938] [D loss: -2.039624] [G loss: -17.772097]\n",
      "[Epoch 0/2] [Batch 340/938] [D loss: -1.845324] [G loss: -17.575214]\n",
      "[Epoch 0/2] [Batch 345/938] [D loss: -1.952794] [G loss: -17.738697]\n",
      "[Epoch 0/2] [Batch 350/938] [D loss: -1.996680] [G loss: -18.063885]\n",
      "[Epoch 0/2] [Batch 355/938] [D loss: -1.866315] [G loss: -17.212334]\n",
      "[Epoch 0/2] [Batch 360/938] [D loss: -2.182642] [G loss: -17.279190]\n",
      "[Epoch 0/2] [Batch 365/938] [D loss: -2.083092] [G loss: -16.953430]\n",
      "[Epoch 0/2] [Batch 370/938] [D loss: -1.660792] [G loss: -16.777285]\n",
      "[Epoch 0/2] [Batch 375/938] [D loss: -1.778948] [G loss: -16.714958]\n",
      "[Epoch 0/2] [Batch 380/938] [D loss: -2.168504] [G loss: -15.823299]\n",
      "[Epoch 0/2] [Batch 385/938] [D loss: -2.080781] [G loss: -14.716057]\n",
      "[Epoch 0/2] [Batch 390/938] [D loss: -2.440908] [G loss: -13.888050]\n",
      "[Epoch 0/2] [Batch 395/938] [D loss: -2.560229] [G loss: -13.183527]\n",
      "[Epoch 0/2] [Batch 400/938] [D loss: -2.408148] [G loss: -11.894108]\n",
      "[Epoch 0/2] [Batch 405/938] [D loss: -2.502193] [G loss: -12.226818]\n",
      "[Epoch 0/2] [Batch 410/938] [D loss: -2.740974] [G loss: -11.554929]\n",
      "[Epoch 0/2] [Batch 415/938] [D loss: -2.569653] [G loss: -11.457790]\n",
      "[Epoch 0/2] [Batch 420/938] [D loss: -2.355341] [G loss: -11.310226]\n",
      "[Epoch 0/2] [Batch 425/938] [D loss: -2.827200] [G loss: -10.731745]\n",
      "[Epoch 0/2] [Batch 430/938] [D loss: -3.081847] [G loss: -10.170351]\n",
      "[Epoch 0/2] [Batch 435/938] [D loss: -3.375508] [G loss: -9.252472]\n",
      "[Epoch 0/2] [Batch 440/938] [D loss: -3.978550] [G loss: -8.838686]\n",
      "[Epoch 0/2] [Batch 445/938] [D loss: -3.093725] [G loss: -8.079851]\n",
      "[Epoch 0/2] [Batch 450/938] [D loss: -3.221455] [G loss: -7.447429]\n",
      "[Epoch 0/2] [Batch 455/938] [D loss: -3.116718] [G loss: -7.506154]\n",
      "[Epoch 0/2] [Batch 460/938] [D loss: -2.987880] [G loss: -6.959658]\n",
      "[Epoch 0/2] [Batch 465/938] [D loss: -2.999018] [G loss: -6.119071]\n",
      "[Epoch 0/2] [Batch 470/938] [D loss: -2.837936] [G loss: -5.599665]\n",
      "[Epoch 0/2] [Batch 475/938] [D loss: -3.513690] [G loss: -4.948877]\n",
      "[Epoch 0/2] [Batch 480/938] [D loss: -3.296412] [G loss: -5.479145]\n",
      "[Epoch 0/2] [Batch 485/938] [D loss: -3.233527] [G loss: -5.881733]\n",
      "[Epoch 0/2] [Batch 490/938] [D loss: -2.960421] [G loss: -5.110722]\n",
      "[Epoch 0/2] [Batch 495/938] [D loss: -2.802124] [G loss: -5.647234]\n",
      "[Epoch 0/2] [Batch 500/938] [D loss: -3.028879] [G loss: -6.456769]\n",
      "[Epoch 0/2] [Batch 505/938] [D loss: -2.664004] [G loss: -7.227755]\n",
      "[Epoch 0/2] [Batch 510/938] [D loss: -2.957281] [G loss: -6.785128]\n",
      "[Epoch 0/2] [Batch 515/938] [D loss: -2.097003] [G loss: -7.901213]\n",
      "[Epoch 0/2] [Batch 520/938] [D loss: -2.047248] [G loss: -7.659676]\n",
      "[Epoch 0/2] [Batch 525/938] [D loss: -2.496207] [G loss: -7.347693]\n",
      "[Epoch 0/2] [Batch 530/938] [D loss: -2.734726] [G loss: -9.080148]\n",
      "[Epoch 0/2] [Batch 535/938] [D loss: -2.054167] [G loss: -10.255278]\n",
      "[Epoch 0/2] [Batch 540/938] [D loss: -1.953777] [G loss: -11.015913]\n",
      "[Epoch 0/2] [Batch 545/938] [D loss: -1.872422] [G loss: -10.875689]\n",
      "[Epoch 0/2] [Batch 550/938] [D loss: -1.795615] [G loss: -11.424109]\n",
      "[Epoch 0/2] [Batch 555/938] [D loss: -2.191548] [G loss: -11.189116]\n",
      "[Epoch 0/2] [Batch 560/938] [D loss: -2.188637] [G loss: -10.079863]\n",
      "[Epoch 0/2] [Batch 565/938] [D loss: -1.944234] [G loss: -10.707929]\n",
      "[Epoch 0/2] [Batch 570/938] [D loss: -2.544803] [G loss: -10.114130]\n",
      "[Epoch 0/2] [Batch 575/938] [D loss: -1.994725] [G loss: -10.082064]\n",
      "[Epoch 0/2] [Batch 580/938] [D loss: -2.617417] [G loss: -9.826572]\n",
      "[Epoch 0/2] [Batch 585/938] [D loss: -2.713253] [G loss: -8.856424]\n",
      "[Epoch 0/2] [Batch 590/938] [D loss: -2.237371] [G loss: -7.794139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 595/938] [D loss: -2.071856] [G loss: -8.411453]\n",
      "[Epoch 0/2] [Batch 600/938] [D loss: -2.789547] [G loss: -8.496975]\n",
      "[Epoch 0/2] [Batch 605/938] [D loss: -2.851047] [G loss: -7.051051]\n",
      "[Epoch 0/2] [Batch 610/938] [D loss: -3.361418] [G loss: -5.348888]\n",
      "[Epoch 0/2] [Batch 615/938] [D loss: -3.393899] [G loss: -4.635007]\n",
      "[Epoch 0/2] [Batch 620/938] [D loss: -4.211488] [G loss: -3.774219]\n",
      "[Epoch 0/2] [Batch 625/938] [D loss: -3.995700] [G loss: -3.650753]\n",
      "[Epoch 0/2] [Batch 630/938] [D loss: -4.427218] [G loss: -3.384097]\n",
      "[Epoch 0/2] [Batch 635/938] [D loss: -4.509789] [G loss: -3.663091]\n",
      "[Epoch 0/2] [Batch 640/938] [D loss: -4.757484] [G loss: -4.708852]\n",
      "[Epoch 0/2] [Batch 645/938] [D loss: -4.678022] [G loss: -3.275721]\n",
      "[Epoch 0/2] [Batch 650/938] [D loss: -5.438917] [G loss: -1.587640]\n",
      "[Epoch 0/2] [Batch 655/938] [D loss: -5.786448] [G loss: -0.101482]\n",
      "[Epoch 0/2] [Batch 660/938] [D loss: -5.072834] [G loss: -1.108147]\n",
      "[Epoch 0/2] [Batch 665/938] [D loss: -6.825358] [G loss: -1.888292]\n",
      "[Epoch 0/2] [Batch 670/938] [D loss: -6.444347] [G loss: -0.790479]\n",
      "[Epoch 0/2] [Batch 675/938] [D loss: -6.695073] [G loss: 0.206401]\n",
      "[Epoch 0/2] [Batch 680/938] [D loss: -6.388170] [G loss: -0.436391]\n",
      "[Epoch 0/2] [Batch 685/938] [D loss: -6.587983] [G loss: 1.875804]\n",
      "[Epoch 0/2] [Batch 690/938] [D loss: -6.344804] [G loss: 0.389893]\n",
      "[Epoch 0/2] [Batch 695/938] [D loss: -6.103579] [G loss: 0.383865]\n",
      "[Epoch 0/2] [Batch 700/938] [D loss: -5.749359] [G loss: -0.498238]\n",
      "[Epoch 0/2] [Batch 705/938] [D loss: -5.215789] [G loss: 0.535849]\n",
      "[Epoch 0/2] [Batch 710/938] [D loss: -5.203118] [G loss: -2.204902]\n",
      "[Epoch 0/2] [Batch 715/938] [D loss: -4.520353] [G loss: -1.616009]\n",
      "[Epoch 0/2] [Batch 720/938] [D loss: -5.172393] [G loss: -0.248117]\n",
      "[Epoch 0/2] [Batch 725/938] [D loss: -4.541009] [G loss: -1.767151]\n",
      "[Epoch 0/2] [Batch 730/938] [D loss: -4.701463] [G loss: -0.241944]\n",
      "[Epoch 0/2] [Batch 735/938] [D loss: -4.144712] [G loss: -0.465271]\n",
      "[Epoch 0/2] [Batch 740/938] [D loss: -3.860660] [G loss: -1.036889]\n",
      "[Epoch 0/2] [Batch 745/938] [D loss: -4.035075] [G loss: -1.241728]\n",
      "[Epoch 0/2] [Batch 750/938] [D loss: -3.751750] [G loss: -1.633067]\n",
      "[Epoch 0/2] [Batch 755/938] [D loss: -4.698187] [G loss: -1.319301]\n",
      "[Epoch 0/2] [Batch 760/938] [D loss: -3.599304] [G loss: -2.131111]\n",
      "[Epoch 0/2] [Batch 765/938] [D loss: -4.079500] [G loss: -3.564310]\n",
      "[Epoch 0/2] [Batch 770/938] [D loss: -4.416444] [G loss: -3.356620]\n",
      "[Epoch 0/2] [Batch 775/938] [D loss: -3.955032] [G loss: -1.293344]\n",
      "[Epoch 0/2] [Batch 780/938] [D loss: -4.166749] [G loss: -2.383329]\n",
      "[Epoch 0/2] [Batch 785/938] [D loss: -4.514307] [G loss: -2.846625]\n",
      "[Epoch 0/2] [Batch 790/938] [D loss: -4.182762] [G loss: -1.792458]\n",
      "[Epoch 0/2] [Batch 795/938] [D loss: -4.618309] [G loss: -1.534476]\n",
      "[Epoch 0/2] [Batch 800/938] [D loss: -4.531162] [G loss: -2.906873]\n",
      "[Epoch 0/2] [Batch 805/938] [D loss: -4.639615] [G loss: -3.711765]\n",
      "[Epoch 0/2] [Batch 810/938] [D loss: -5.198573] [G loss: -2.075146]\n",
      "[Epoch 0/2] [Batch 815/938] [D loss: -4.338860] [G loss: -2.143463]\n",
      "[Epoch 0/2] [Batch 820/938] [D loss: -5.112293] [G loss: -4.696926]\n",
      "[Epoch 0/2] [Batch 825/938] [D loss: -4.666640] [G loss: -1.719136]\n",
      "[Epoch 0/2] [Batch 830/938] [D loss: -4.941491] [G loss: -2.226312]\n",
      "[Epoch 0/2] [Batch 835/938] [D loss: -5.689618] [G loss: -2.532398]\n",
      "[Epoch 0/2] [Batch 840/938] [D loss: -5.450089] [G loss: -2.467215]\n",
      "[Epoch 0/2] [Batch 845/938] [D loss: -6.350683] [G loss: -1.413208]\n",
      "[Epoch 0/2] [Batch 850/938] [D loss: -5.612807] [G loss: -3.227636]\n",
      "[Epoch 0/2] [Batch 855/938] [D loss: -5.811343] [G loss: -2.835763]\n",
      "[Epoch 0/2] [Batch 860/938] [D loss: -5.715771] [G loss: -2.457493]\n",
      "[Epoch 0/2] [Batch 865/938] [D loss: -5.852928] [G loss: -3.048442]\n",
      "[Epoch 0/2] [Batch 870/938] [D loss: -6.110232] [G loss: -1.329326]\n",
      "[Epoch 0/2] [Batch 875/938] [D loss: -6.300032] [G loss: -2.099556]\n",
      "[Epoch 0/2] [Batch 880/938] [D loss: -6.638946] [G loss: -1.253429]\n",
      "[Epoch 0/2] [Batch 885/938] [D loss: -6.739577] [G loss: -0.486704]\n",
      "[Epoch 0/2] [Batch 890/938] [D loss: -5.614257] [G loss: -2.144598]\n",
      "[Epoch 0/2] [Batch 895/938] [D loss: -5.798145] [G loss: -0.337252]\n",
      "[Epoch 0/2] [Batch 900/938] [D loss: -6.091087] [G loss: -0.074364]\n",
      "[Epoch 0/2] [Batch 905/938] [D loss: -6.302378] [G loss: -1.134620]\n",
      "[Epoch 0/2] [Batch 910/938] [D loss: -6.344786] [G loss: -0.416448]\n",
      "[Epoch 0/2] [Batch 915/938] [D loss: -6.826219] [G loss: 0.909511]\n",
      "[Epoch 0/2] [Batch 920/938] [D loss: -6.913748] [G loss: -1.326056]\n",
      "[Epoch 0/2] [Batch 925/938] [D loss: -6.561090] [G loss: 1.320065]\n",
      "[Epoch 0/2] [Batch 930/938] [D loss: -6.879379] [G loss: -0.087481]\n",
      "[Epoch 0/2] [Batch 935/938] [D loss: -6.446486] [G loss: 0.163925]\n",
      "[Epoch 1/2] [Batch 0/938] [D loss: -6.473720] [G loss: -1.365338]\n",
      "[Epoch 1/2] [Batch 5/938] [D loss: -6.274610] [G loss: -1.791014]\n",
      "[Epoch 1/2] [Batch 10/938] [D loss: -6.078816] [G loss: -1.640179]\n",
      "[Epoch 1/2] [Batch 15/938] [D loss: -5.895504] [G loss: -1.030275]\n",
      "[Epoch 1/2] [Batch 20/938] [D loss: -6.279131] [G loss: -0.957900]\n",
      "[Epoch 1/2] [Batch 25/938] [D loss: -5.948658] [G loss: -0.426707]\n",
      "[Epoch 1/2] [Batch 30/938] [D loss: -5.840714] [G loss: -1.157318]\n",
      "[Epoch 1/2] [Batch 35/938] [D loss: -5.670975] [G loss: -1.642864]\n",
      "[Epoch 1/2] [Batch 40/938] [D loss: -5.875427] [G loss: -1.822059]\n",
      "[Epoch 1/2] [Batch 45/938] [D loss: -5.950736] [G loss: -1.290356]\n",
      "[Epoch 1/2] [Batch 50/938] [D loss: -5.260320] [G loss: -2.265312]\n",
      "[Epoch 1/2] [Batch 55/938] [D loss: -5.719100] [G loss: -0.961764]\n",
      "[Epoch 1/2] [Batch 60/938] [D loss: -5.671422] [G loss: -1.612506]\n",
      "[Epoch 1/2] [Batch 65/938] [D loss: -5.512917] [G loss: -1.495101]\n",
      "[Epoch 1/2] [Batch 70/938] [D loss: -4.905881] [G loss: -1.046158]\n",
      "[Epoch 1/2] [Batch 75/938] [D loss: -4.401551] [G loss: -1.079491]\n",
      "[Epoch 1/2] [Batch 80/938] [D loss: -4.842525] [G loss: -1.241586]\n",
      "[Epoch 1/2] [Batch 85/938] [D loss: -4.996294] [G loss: -2.228697]\n",
      "[Epoch 1/2] [Batch 90/938] [D loss: -4.856845] [G loss: -1.222997]\n",
      "[Epoch 1/2] [Batch 95/938] [D loss: -4.967445] [G loss: -2.961858]\n",
      "[Epoch 1/2] [Batch 100/938] [D loss: -5.257007] [G loss: -1.093919]\n",
      "[Epoch 1/2] [Batch 105/938] [D loss: -5.445892] [G loss: -2.617728]\n",
      "[Epoch 1/2] [Batch 110/938] [D loss: -4.768134] [G loss: -4.115655]\n",
      "[Epoch 1/2] [Batch 115/938] [D loss: -5.502114] [G loss: -2.244662]\n",
      "[Epoch 1/2] [Batch 120/938] [D loss: -4.911240] [G loss: -2.128094]\n",
      "[Epoch 1/2] [Batch 125/938] [D loss: -5.924218] [G loss: -2.603533]\n",
      "[Epoch 1/2] [Batch 130/938] [D loss: -5.848382] [G loss: -1.948466]\n",
      "[Epoch 1/2] [Batch 135/938] [D loss: -5.536429] [G loss: -3.496452]\n",
      "[Epoch 1/2] [Batch 140/938] [D loss: -5.775795] [G loss: -1.953364]\n",
      "[Epoch 1/2] [Batch 145/938] [D loss: -5.757039] [G loss: -2.189678]\n",
      "[Epoch 1/2] [Batch 150/938] [D loss: -6.051434] [G loss: -3.086678]\n",
      "[Epoch 1/2] [Batch 155/938] [D loss: -5.718350] [G loss: -2.945686]\n",
      "[Epoch 1/2] [Batch 160/938] [D loss: -6.145065] [G loss: -2.405854]\n",
      "[Epoch 1/2] [Batch 165/938] [D loss: -6.216078] [G loss: -2.378306]\n",
      "[Epoch 1/2] [Batch 170/938] [D loss: -6.428545] [G loss: -1.185234]\n",
      "[Epoch 1/2] [Batch 175/938] [D loss: -6.308614] [G loss: -1.690479]\n",
      "[Epoch 1/2] [Batch 180/938] [D loss: -6.130778] [G loss: -1.046076]\n",
      "[Epoch 1/2] [Batch 185/938] [D loss: -6.210643] [G loss: -1.633115]\n",
      "[Epoch 1/2] [Batch 190/938] [D loss: -7.008743] [G loss: -2.055834]\n",
      "[Epoch 1/2] [Batch 195/938] [D loss: -6.671205] [G loss: -2.677014]\n",
      "[Epoch 1/2] [Batch 200/938] [D loss: -5.930390] [G loss: -0.980969]\n",
      "[Epoch 1/2] [Batch 205/938] [D loss: -6.718262] [G loss: -0.878927]\n",
      "[Epoch 1/2] [Batch 210/938] [D loss: -6.048558] [G loss: -1.625337]\n",
      "[Epoch 1/2] [Batch 215/938] [D loss: -6.634489] [G loss: -1.450295]\n",
      "[Epoch 1/2] [Batch 220/938] [D loss: -6.252270] [G loss: 0.116876]\n",
      "[Epoch 1/2] [Batch 225/938] [D loss: -6.726415] [G loss: 0.795174]\n",
      "[Epoch 1/2] [Batch 230/938] [D loss: -7.512703] [G loss: -1.176307]\n",
      "[Epoch 1/2] [Batch 235/938] [D loss: -6.838535] [G loss: -0.166460]\n",
      "[Epoch 1/2] [Batch 240/938] [D loss: -7.003109] [G loss: -0.448112]\n",
      "[Epoch 1/2] [Batch 245/938] [D loss: -7.528896] [G loss: 1.421265]\n",
      "[Epoch 1/2] [Batch 250/938] [D loss: -7.265149] [G loss: 1.049847]\n",
      "[Epoch 1/2] [Batch 255/938] [D loss: -8.346029] [G loss: 1.888138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 260/938] [D loss: -7.769081] [G loss: 2.431551]\n",
      "[Epoch 1/2] [Batch 265/938] [D loss: -7.737829] [G loss: 1.941904]\n",
      "[Epoch 1/2] [Batch 270/938] [D loss: -8.286416] [G loss: 0.872480]\n",
      "[Epoch 1/2] [Batch 275/938] [D loss: -8.277871] [G loss: 2.604989]\n",
      "[Epoch 1/2] [Batch 280/938] [D loss: -7.735622] [G loss: 1.397768]\n",
      "[Epoch 1/2] [Batch 285/938] [D loss: -7.826842] [G loss: 2.137001]\n",
      "[Epoch 1/2] [Batch 290/938] [D loss: -8.062252] [G loss: 2.631724]\n",
      "[Epoch 1/2] [Batch 295/938] [D loss: -8.121384] [G loss: 3.448383]\n",
      "[Epoch 1/2] [Batch 300/938] [D loss: -7.908410] [G loss: 2.361703]\n",
      "[Epoch 1/2] [Batch 305/938] [D loss: -7.580414] [G loss: 2.177536]\n",
      "[Epoch 1/2] [Batch 310/938] [D loss: -7.574720] [G loss: 2.219851]\n",
      "[Epoch 1/2] [Batch 315/938] [D loss: -8.639702] [G loss: 2.847414]\n",
      "[Epoch 1/2] [Batch 320/938] [D loss: -7.442295] [G loss: 1.425089]\n",
      "[Epoch 1/2] [Batch 325/938] [D loss: -7.513917] [G loss: 2.230259]\n",
      "[Epoch 1/2] [Batch 330/938] [D loss: -7.097714] [G loss: 3.058722]\n",
      "[Epoch 1/2] [Batch 335/938] [D loss: -6.937126] [G loss: 1.502080]\n",
      "[Epoch 1/2] [Batch 340/938] [D loss: -7.062911] [G loss: 2.414003]\n",
      "[Epoch 1/2] [Batch 345/938] [D loss: -6.742111] [G loss: 1.361063]\n",
      "[Epoch 1/2] [Batch 350/938] [D loss: -7.070194] [G loss: 2.043804]\n",
      "[Epoch 1/2] [Batch 355/938] [D loss: -6.395718] [G loss: 0.346513]\n",
      "[Epoch 1/2] [Batch 360/938] [D loss: -6.768584] [G loss: 0.537741]\n",
      "[Epoch 1/2] [Batch 365/938] [D loss: -7.230500] [G loss: 0.629008]\n",
      "[Epoch 1/2] [Batch 370/938] [D loss: -7.266190] [G loss: 1.016253]\n",
      "[Epoch 1/2] [Batch 375/938] [D loss: -6.423029] [G loss: 0.776599]\n",
      "[Epoch 1/2] [Batch 380/938] [D loss: -5.849438] [G loss: 0.351075]\n",
      "[Epoch 1/2] [Batch 385/938] [D loss: -6.268460] [G loss: 1.098255]\n",
      "[Epoch 1/2] [Batch 390/938] [D loss: -7.388983] [G loss: 0.550546]\n",
      "[Epoch 1/2] [Batch 395/938] [D loss: -5.856889] [G loss: 0.063063]\n",
      "[Epoch 1/2] [Batch 400/938] [D loss: -6.553790] [G loss: 2.275502]\n",
      "[Epoch 1/2] [Batch 405/938] [D loss: -6.886234] [G loss: 1.946911]\n",
      "[Epoch 1/2] [Batch 410/938] [D loss: -6.469579] [G loss: 1.773823]\n",
      "[Epoch 1/2] [Batch 415/938] [D loss: -5.825880] [G loss: 0.884835]\n",
      "[Epoch 1/2] [Batch 420/938] [D loss: -6.142368] [G loss: 0.518643]\n",
      "[Epoch 1/2] [Batch 425/938] [D loss: -6.601505] [G loss: 0.625613]\n",
      "[Epoch 1/2] [Batch 430/938] [D loss: -5.951575] [G loss: 1.128479]\n",
      "[Epoch 1/2] [Batch 435/938] [D loss: -6.564803] [G loss: 1.205590]\n",
      "[Epoch 1/2] [Batch 440/938] [D loss: -5.723730] [G loss: 1.728863]\n",
      "[Epoch 1/2] [Batch 445/938] [D loss: -6.371482] [G loss: 1.410799]\n",
      "[Epoch 1/2] [Batch 450/938] [D loss: -7.016449] [G loss: 1.748267]\n",
      "[Epoch 1/2] [Batch 455/938] [D loss: -6.531258] [G loss: 1.117271]\n",
      "[Epoch 1/2] [Batch 460/938] [D loss: -7.187558] [G loss: 3.242369]\n",
      "[Epoch 1/2] [Batch 465/938] [D loss: -6.585850] [G loss: 3.132654]\n",
      "[Epoch 1/2] [Batch 470/938] [D loss: -6.890323] [G loss: 2.838510]\n",
      "[Epoch 1/2] [Batch 475/938] [D loss: -7.181892] [G loss: 2.314723]\n",
      "[Epoch 1/2] [Batch 480/938] [D loss: -6.833644] [G loss: 3.016963]\n",
      "[Epoch 1/2] [Batch 485/938] [D loss: -6.815055] [G loss: 3.147958]\n",
      "[Epoch 1/2] [Batch 490/938] [D loss: -7.151147] [G loss: 3.485329]\n",
      "[Epoch 1/2] [Batch 495/938] [D loss: -6.632734] [G loss: 2.584672]\n",
      "[Epoch 1/2] [Batch 500/938] [D loss: -6.722710] [G loss: 2.081159]\n",
      "[Epoch 1/2] [Batch 505/938] [D loss: -6.740452] [G loss: 1.451847]\n",
      "[Epoch 1/2] [Batch 510/938] [D loss: -6.719914] [G loss: 1.482701]\n",
      "[Epoch 1/2] [Batch 515/938] [D loss: -6.762058] [G loss: 1.821401]\n",
      "[Epoch 1/2] [Batch 520/938] [D loss: -7.262864] [G loss: 2.350829]\n",
      "[Epoch 1/2] [Batch 525/938] [D loss: -6.848550] [G loss: 1.069358]\n",
      "[Epoch 1/2] [Batch 530/938] [D loss: -6.599458] [G loss: 2.524543]\n",
      "[Epoch 1/2] [Batch 535/938] [D loss: -6.689142] [G loss: 1.937934]\n",
      "[Epoch 1/2] [Batch 540/938] [D loss: -6.933022] [G loss: 1.316161]\n",
      "[Epoch 1/2] [Batch 545/938] [D loss: -6.502259] [G loss: 1.953490]\n",
      "[Epoch 1/2] [Batch 550/938] [D loss: -6.624879] [G loss: 1.160598]\n",
      "[Epoch 1/2] [Batch 555/938] [D loss: -7.363887] [G loss: 2.287171]\n",
      "[Epoch 1/2] [Batch 560/938] [D loss: -7.376893] [G loss: 2.884756]\n",
      "[Epoch 1/2] [Batch 565/938] [D loss: -6.725694] [G loss: 1.604723]\n",
      "[Epoch 1/2] [Batch 570/938] [D loss: -7.149812] [G loss: 1.213482]\n",
      "[Epoch 1/2] [Batch 575/938] [D loss: -7.395140] [G loss: -0.812314]\n",
      "[Epoch 1/2] [Batch 580/938] [D loss: -7.960702] [G loss: 1.427670]\n",
      "[Epoch 1/2] [Batch 585/938] [D loss: -7.462648] [G loss: 1.611014]\n",
      "[Epoch 1/2] [Batch 590/938] [D loss: -6.721190] [G loss: 0.061991]\n",
      "[Epoch 1/2] [Batch 595/938] [D loss: -6.493615] [G loss: 0.151565]\n",
      "[Epoch 1/2] [Batch 600/938] [D loss: -7.228000] [G loss: 1.417518]\n",
      "[Epoch 1/2] [Batch 605/938] [D loss: -6.688182] [G loss: 1.897537]\n",
      "[Epoch 1/2] [Batch 610/938] [D loss: -7.456656] [G loss: 1.745146]\n",
      "[Epoch 1/2] [Batch 615/938] [D loss: -7.242574] [G loss: 0.422931]\n",
      "[Epoch 1/2] [Batch 620/938] [D loss: -6.963799] [G loss: 0.316212]\n",
      "[Epoch 1/2] [Batch 625/938] [D loss: -6.955939] [G loss: 1.466016]\n",
      "[Epoch 1/2] [Batch 630/938] [D loss: -7.656867] [G loss: 0.641035]\n",
      "[Epoch 1/2] [Batch 635/938] [D loss: -7.046708] [G loss: 0.353221]\n",
      "[Epoch 1/2] [Batch 640/938] [D loss: -6.043639] [G loss: 1.547276]\n",
      "[Epoch 1/2] [Batch 645/938] [D loss: -6.940955] [G loss: 0.023016]\n",
      "[Epoch 1/2] [Batch 650/938] [D loss: -6.710904] [G loss: -0.155578]\n",
      "[Epoch 1/2] [Batch 655/938] [D loss: -7.292138] [G loss: 0.856733]\n",
      "[Epoch 1/2] [Batch 660/938] [D loss: -7.221932] [G loss: 0.029362]\n",
      "[Epoch 1/2] [Batch 665/938] [D loss: -6.867052] [G loss: -1.154269]\n",
      "[Epoch 1/2] [Batch 670/938] [D loss: -7.283349] [G loss: -0.588057]\n",
      "[Epoch 1/2] [Batch 675/938] [D loss: -6.340334] [G loss: -0.181335]\n",
      "[Epoch 1/2] [Batch 680/938] [D loss: -6.650313] [G loss: -0.748479]\n",
      "[Epoch 1/2] [Batch 685/938] [D loss: -6.480456] [G loss: -0.044027]\n",
      "[Epoch 1/2] [Batch 690/938] [D loss: -6.405941] [G loss: 0.438510]\n",
      "[Epoch 1/2] [Batch 695/938] [D loss: -6.962685] [G loss: 0.536785]\n",
      "[Epoch 1/2] [Batch 700/938] [D loss: -6.911115] [G loss: -0.680500]\n",
      "[Epoch 1/2] [Batch 705/938] [D loss: -6.696776] [G loss: 0.606293]\n",
      "[Epoch 1/2] [Batch 710/938] [D loss: -6.682258] [G loss: 0.501012]\n",
      "[Epoch 1/2] [Batch 715/938] [D loss: -6.078262] [G loss: -0.110263]\n",
      "[Epoch 1/2] [Batch 720/938] [D loss: -7.383561] [G loss: -0.807478]\n",
      "[Epoch 1/2] [Batch 725/938] [D loss: -7.189339] [G loss: -0.190122]\n",
      "[Epoch 1/2] [Batch 730/938] [D loss: -7.298747] [G loss: 0.726319]\n",
      "[Epoch 1/2] [Batch 735/938] [D loss: -7.439102] [G loss: 0.737941]\n",
      "[Epoch 1/2] [Batch 740/938] [D loss: -7.486451] [G loss: -0.836494]\n",
      "[Epoch 1/2] [Batch 745/938] [D loss: -7.471307] [G loss: 0.019287]\n",
      "[Epoch 1/2] [Batch 750/938] [D loss: -7.042436] [G loss: 0.763198]\n",
      "[Epoch 1/2] [Batch 755/938] [D loss: -7.895307] [G loss: 0.198115]\n",
      "[Epoch 1/2] [Batch 760/938] [D loss: -8.190918] [G loss: 0.636063]\n",
      "[Epoch 1/2] [Batch 765/938] [D loss: -7.526474] [G loss: 1.094278]\n",
      "[Epoch 1/2] [Batch 770/938] [D loss: -8.059800] [G loss: 0.433945]\n",
      "[Epoch 1/2] [Batch 775/938] [D loss: -8.568893] [G loss: 1.142701]\n",
      "[Epoch 1/2] [Batch 780/938] [D loss: -8.103965] [G loss: 1.721447]\n",
      "[Epoch 1/2] [Batch 785/938] [D loss: -7.276075] [G loss: 1.464725]\n",
      "[Epoch 1/2] [Batch 790/938] [D loss: -8.080319] [G loss: 1.572016]\n",
      "[Epoch 1/2] [Batch 795/938] [D loss: -7.737835] [G loss: 0.442892]\n",
      "[Epoch 1/2] [Batch 800/938] [D loss: -7.290009] [G loss: 1.645587]\n",
      "[Epoch 1/2] [Batch 805/938] [D loss: -7.267824] [G loss: 0.604532]\n",
      "[Epoch 1/2] [Batch 810/938] [D loss: -7.038824] [G loss: 0.172247]\n",
      "[Epoch 1/2] [Batch 815/938] [D loss: -6.241683] [G loss: 1.053211]\n",
      "[Epoch 1/2] [Batch 820/938] [D loss: -7.128381] [G loss: 2.320239]\n",
      "[Epoch 1/2] [Batch 825/938] [D loss: -6.709228] [G loss: 1.814316]\n",
      "[Epoch 1/2] [Batch 830/938] [D loss: -6.779689] [G loss: 1.046649]\n",
      "[Epoch 1/2] [Batch 835/938] [D loss: -6.909092] [G loss: 0.212865]\n",
      "[Epoch 1/2] [Batch 840/938] [D loss: -7.417290] [G loss: 1.145615]\n",
      "[Epoch 1/2] [Batch 845/938] [D loss: -7.656610] [G loss: 2.991806]\n",
      "[Epoch 1/2] [Batch 850/938] [D loss: -7.584050] [G loss: 1.966804]\n",
      "[Epoch 1/2] [Batch 855/938] [D loss: -6.935921] [G loss: 2.610863]\n",
      "[Epoch 1/2] [Batch 860/938] [D loss: -7.256659] [G loss: 2.427115]\n",
      "[Epoch 1/2] [Batch 865/938] [D loss: -6.283935] [G loss: 1.506878]\n",
      "[Epoch 1/2] [Batch 870/938] [D loss: -6.545705] [G loss: 1.587834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 875/938] [D loss: -7.223490] [G loss: 1.878277]\n",
      "[Epoch 1/2] [Batch 880/938] [D loss: -6.724697] [G loss: 0.206166]\n",
      "[Epoch 1/2] [Batch 885/938] [D loss: -7.005715] [G loss: -0.040606]\n",
      "[Epoch 1/2] [Batch 890/938] [D loss: -6.943243] [G loss: 0.243583]\n",
      "[Epoch 1/2] [Batch 895/938] [D loss: -6.715596] [G loss: 0.986187]\n",
      "[Epoch 1/2] [Batch 900/938] [D loss: -6.676334] [G loss: 0.705724]\n",
      "[Epoch 1/2] [Batch 905/938] [D loss: -6.932789] [G loss: -0.405977]\n",
      "[Epoch 1/2] [Batch 910/938] [D loss: -7.614096] [G loss: 0.143837]\n",
      "[Epoch 1/2] [Batch 915/938] [D loss: -7.184932] [G loss: -0.453341]\n",
      "[Epoch 1/2] [Batch 920/938] [D loss: -6.908195] [G loss: -0.900278]\n",
      "[Epoch 1/2] [Batch 925/938] [D loss: -7.018968] [G loss: -0.819533]\n",
      "[Epoch 1/2] [Batch 930/938] [D loss: -6.879057] [G loss: -1.081206]\n",
      "[Epoch 1/2] [Batch 935/938] [D loss: -6.603237] [G loss: -0.498918]\n",
      "saving states\n"
     ]
    }
   ],
   "source": [
    "WGAN_GP = gan.WGAN_GP(\"mnist_wgan_gp\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(WGAN_GP.identifier)\n",
    "with mlflow.start_run(experiment_id=WGAN_GP.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    WGAN_GP.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=5,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999),\n",
    "        lambda_gp=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "[Epoch 0/2] [Batch 0/938] [D loss: -0.170010] [G loss: 0.005773]\n",
      "saving states\n",
      "[Epoch 0/2] [Batch 5/938] [D loss: -3.180050] [G loss: -0.102186]\n",
      "[Epoch 0/2] [Batch 10/938] [D loss: -10.901387] [G loss: -1.057055]\n",
      "[Epoch 0/2] [Batch 15/938] [D loss: -16.889118] [G loss: -3.784881]\n",
      "[Epoch 0/2] [Batch 20/938] [D loss: -19.562603] [G loss: -8.415730]\n",
      "[Epoch 0/2] [Batch 25/938] [D loss: -16.856379] [G loss: -14.702381]\n",
      "[Epoch 0/2] [Batch 30/938] [D loss: -11.755901] [G loss: -20.045073]\n",
      "[Epoch 0/2] [Batch 35/938] [D loss: -7.847595] [G loss: -23.969528]\n",
      "[Epoch 0/2] [Batch 40/938] [D loss: -5.508705] [G loss: -25.085793]\n",
      "[Epoch 0/2] [Batch 45/938] [D loss: -3.750599] [G loss: -25.782438]\n",
      "[Epoch 0/2] [Batch 50/938] [D loss: -4.067463] [G loss: -24.500439]\n",
      "[Epoch 0/2] [Batch 55/938] [D loss: -3.251064] [G loss: -24.668972]\n",
      "[Epoch 0/2] [Batch 60/938] [D loss: -2.647486] [G loss: -24.228962]\n",
      "[Epoch 0/2] [Batch 65/938] [D loss: -2.913563] [G loss: -23.743244]\n",
      "[Epoch 0/2] [Batch 70/938] [D loss: -1.821499] [G loss: -23.514141]\n",
      "[Epoch 0/2] [Batch 75/938] [D loss: -1.844513] [G loss: -23.252426]\n",
      "[Epoch 0/2] [Batch 80/938] [D loss: -2.009523] [G loss: -22.915138]\n",
      "[Epoch 0/2] [Batch 85/938] [D loss: -1.010006] [G loss: -22.767767]\n",
      "[Epoch 0/2] [Batch 90/938] [D loss: -1.067850] [G loss: -22.333590]\n",
      "[Epoch 0/2] [Batch 95/938] [D loss: -1.023239] [G loss: -22.107214]\n",
      "[Epoch 0/2] [Batch 100/938] [D loss: -1.114075] [G loss: -21.840317]\n",
      "[Epoch 0/2] [Batch 105/938] [D loss: -1.240211] [G loss: -21.496742]\n",
      "[Epoch 0/2] [Batch 110/938] [D loss: -1.392992] [G loss: -21.209221]\n",
      "[Epoch 0/2] [Batch 115/938] [D loss: -1.326214] [G loss: -20.869648]\n",
      "[Epoch 0/2] [Batch 120/938] [D loss: -1.243874] [G loss: -20.698805]\n",
      "[Epoch 0/2] [Batch 125/938] [D loss: -1.369402] [G loss: -20.358376]\n",
      "[Epoch 0/2] [Batch 130/938] [D loss: -1.497005] [G loss: -20.146624]\n",
      "[Epoch 0/2] [Batch 135/938] [D loss: -1.513767] [G loss: -20.051044]\n",
      "[Epoch 0/2] [Batch 140/938] [D loss: -1.781126] [G loss: -19.930752]\n",
      "[Epoch 0/2] [Batch 145/938] [D loss: -1.044716] [G loss: -20.010223]\n",
      "[Epoch 0/2] [Batch 150/938] [D loss: -0.973169] [G loss: -20.002483]\n",
      "[Epoch 0/2] [Batch 155/938] [D loss: -0.996059] [G loss: -20.066040]\n",
      "[Epoch 0/2] [Batch 160/938] [D loss: -0.942410] [G loss: -19.953981]\n",
      "[Epoch 0/2] [Batch 165/938] [D loss: -0.908918] [G loss: -19.879925]\n",
      "[Epoch 0/2] [Batch 170/938] [D loss: -0.684834] [G loss: -19.939526]\n",
      "[Epoch 0/2] [Batch 175/938] [D loss: -0.454250] [G loss: -19.900249]\n",
      "[Epoch 0/2] [Batch 180/938] [D loss: -0.943420] [G loss: -19.654507]\n",
      "[Epoch 0/2] [Batch 185/938] [D loss: -1.018570] [G loss: -19.429016]\n",
      "[Epoch 0/2] [Batch 190/938] [D loss: -0.729605] [G loss: -19.328558]\n",
      "[Epoch 0/2] [Batch 195/938] [D loss: -0.820202] [G loss: -19.084743]\n",
      "[Epoch 0/2] [Batch 200/938] [D loss: -0.479877] [G loss: -18.913071]\n",
      "[Epoch 0/2] [Batch 205/938] [D loss: -0.690741] [G loss: -18.667717]\n",
      "[Epoch 0/2] [Batch 210/938] [D loss: -0.662830] [G loss: -18.450108]\n",
      "[Epoch 0/2] [Batch 215/938] [D loss: -0.822594] [G loss: -18.146255]\n",
      "[Epoch 0/2] [Batch 220/938] [D loss: -0.700886] [G loss: -17.841539]\n",
      "[Epoch 0/2] [Batch 225/938] [D loss: -0.735697] [G loss: -17.555840]\n",
      "[Epoch 0/2] [Batch 230/938] [D loss: -0.634615] [G loss: -17.236752]\n",
      "[Epoch 0/2] [Batch 235/938] [D loss: -0.571445] [G loss: -17.107140]\n",
      "[Epoch 0/2] [Batch 240/938] [D loss: -0.743179] [G loss: -16.890015]\n",
      "[Epoch 0/2] [Batch 245/938] [D loss: -0.774164] [G loss: -16.659866]\n",
      "[Epoch 0/2] [Batch 250/938] [D loss: -0.832808] [G loss: -16.426512]\n",
      "[Epoch 0/2] [Batch 255/938] [D loss: -0.798531] [G loss: -16.352415]\n",
      "[Epoch 0/2] [Batch 260/938] [D loss: -0.620365] [G loss: -16.121357]\n",
      "[Epoch 0/2] [Batch 265/938] [D loss: -0.872765] [G loss: -15.926880]\n",
      "[Epoch 0/2] [Batch 270/938] [D loss: -0.785076] [G loss: -15.743598]\n",
      "[Epoch 0/2] [Batch 275/938] [D loss: -0.839190] [G loss: -15.610018]\n",
      "[Epoch 0/2] [Batch 280/938] [D loss: -0.650072] [G loss: -15.505482]\n",
      "[Epoch 0/2] [Batch 285/938] [D loss: -0.393370] [G loss: -15.478170]\n",
      "[Epoch 0/2] [Batch 290/938] [D loss: -0.411439] [G loss: -15.420728]\n",
      "[Epoch 0/2] [Batch 295/938] [D loss: -0.429825] [G loss: -15.333317]\n",
      "[Epoch 0/2] [Batch 300/938] [D loss: -0.348408] [G loss: -15.342440]\n",
      "[Epoch 0/2] [Batch 305/938] [D loss: -0.514221] [G loss: -15.234325]\n",
      "[Epoch 0/2] [Batch 310/938] [D loss: -0.542337] [G loss: -15.060013]\n",
      "[Epoch 0/2] [Batch 315/938] [D loss: -0.618570] [G loss: -15.019938]\n",
      "[Epoch 0/2] [Batch 320/938] [D loss: -0.566556] [G loss: -14.931846]\n",
      "[Epoch 0/2] [Batch 325/938] [D loss: -0.553701] [G loss: -14.879639]\n",
      "[Epoch 0/2] [Batch 330/938] [D loss: -0.530496] [G loss: -14.791739]\n",
      "[Epoch 0/2] [Batch 335/938] [D loss: -0.508713] [G loss: -14.799747]\n",
      "[Epoch 0/2] [Batch 340/938] [D loss: -0.689876] [G loss: -14.793703]\n",
      "[Epoch 0/2] [Batch 345/938] [D loss: -0.444761] [G loss: -14.818014]\n",
      "[Epoch 0/2] [Batch 350/938] [D loss: -0.482113] [G loss: -14.800472]\n",
      "[Epoch 0/2] [Batch 355/938] [D loss: -0.244202] [G loss: -14.896177]\n",
      "[Epoch 0/2] [Batch 360/938] [D loss: -0.405098] [G loss: -15.004617]\n",
      "[Epoch 0/2] [Batch 365/938] [D loss: -0.455154] [G loss: -15.007409]\n",
      "[Epoch 0/2] [Batch 370/938] [D loss: -0.384402] [G loss: -15.074516]\n",
      "[Epoch 0/2] [Batch 375/938] [D loss: -0.430464] [G loss: -14.894069]\n",
      "[Epoch 0/2] [Batch 380/938] [D loss: -0.288513] [G loss: -14.787772]\n",
      "[Epoch 0/2] [Batch 385/938] [D loss: -0.307769] [G loss: -14.656538]\n",
      "[Epoch 0/2] [Batch 390/938] [D loss: -0.493876] [G loss: -14.548380]\n",
      "[Epoch 0/2] [Batch 395/938] [D loss: -0.306612] [G loss: -14.370240]\n",
      "[Epoch 0/2] [Batch 400/938] [D loss: -0.485182] [G loss: -14.154571]\n",
      "[Epoch 0/2] [Batch 405/938] [D loss: -0.364058] [G loss: -14.056749]\n",
      "[Epoch 0/2] [Batch 410/938] [D loss: -0.489023] [G loss: -13.838879]\n",
      "[Epoch 0/2] [Batch 415/938] [D loss: -0.495313] [G loss: -13.643280]\n",
      "[Epoch 0/2] [Batch 420/938] [D loss: -0.288397] [G loss: -13.532208]\n",
      "[Epoch 0/2] [Batch 425/938] [D loss: -0.483300] [G loss: -13.485845]\n",
      "[Epoch 0/2] [Batch 430/938] [D loss: -0.338537] [G loss: -13.357757]\n",
      "[Epoch 0/2] [Batch 435/938] [D loss: -0.404265] [G loss: -13.081515]\n",
      "[Epoch 0/2] [Batch 440/938] [D loss: -0.333599] [G loss: -12.840237]\n",
      "[Epoch 0/2] [Batch 445/938] [D loss: -0.260120] [G loss: -12.657236]\n",
      "[Epoch 0/2] [Batch 450/938] [D loss: -0.340753] [G loss: -12.449802]\n",
      "[Epoch 0/2] [Batch 455/938] [D loss: -0.284222] [G loss: -12.283464]\n",
      "[Epoch 0/2] [Batch 460/938] [D loss: -0.179343] [G loss: -11.914618]\n",
      "[Epoch 0/2] [Batch 465/938] [D loss: -0.524522] [G loss: -11.613844]\n",
      "[Epoch 0/2] [Batch 470/938] [D loss: -0.364911] [G loss: -11.365540]\n",
      "[Epoch 0/2] [Batch 475/938] [D loss: -0.276852] [G loss: -11.288055]\n",
      "[Epoch 0/2] [Batch 480/938] [D loss: -0.338326] [G loss: -11.044785]\n",
      "[Epoch 0/2] [Batch 485/938] [D loss: -0.325403] [G loss: -10.976183]\n",
      "[Epoch 0/2] [Batch 490/938] [D loss: -0.322993] [G loss: -11.068193]\n",
      "[Epoch 0/2] [Batch 495/938] [D loss: -0.370436] [G loss: -11.248114]\n",
      "[Epoch 0/2] [Batch 500/938] [D loss: -0.641036] [G loss: -11.071918]\n",
      "[Epoch 0/2] [Batch 505/938] [D loss: -0.346169] [G loss: -11.205216]\n",
      "[Epoch 0/2] [Batch 510/938] [D loss: -0.607989] [G loss: -11.244801]\n",
      "[Epoch 0/2] [Batch 515/938] [D loss: -0.292018] [G loss: -11.361673]\n",
      "[Epoch 0/2] [Batch 520/938] [D loss: -0.362293] [G loss: -11.737433]\n",
      "[Epoch 0/2] [Batch 525/938] [D loss: -0.291346] [G loss: -11.939384]\n",
      "[Epoch 0/2] [Batch 530/938] [D loss: -0.240289] [G loss: -12.085969]\n",
      "[Epoch 0/2] [Batch 535/938] [D loss: -0.301919] [G loss: -12.394420]\n",
      "[Epoch 0/2] [Batch 540/938] [D loss: -0.178621] [G loss: -12.388021]\n",
      "[Epoch 0/2] [Batch 545/938] [D loss: -0.239010] [G loss: -12.582703]\n",
      "[Epoch 0/2] [Batch 550/938] [D loss: -0.281284] [G loss: -12.943493]\n",
      "[Epoch 0/2] [Batch 555/938] [D loss: -0.187769] [G loss: -13.208937]\n",
      "[Epoch 0/2] [Batch 560/938] [D loss: -0.360077] [G loss: -13.671604]\n",
      "[Epoch 0/2] [Batch 565/938] [D loss: -0.079367] [G loss: -14.008288]\n",
      "[Epoch 0/2] [Batch 570/938] [D loss: -0.197387] [G loss: -14.385975]\n",
      "[Epoch 0/2] [Batch 575/938] [D loss: -0.177851] [G loss: -14.448726]\n",
      "[Epoch 0/2] [Batch 580/938] [D loss: -0.105740] [G loss: -14.592966]\n",
      "[Epoch 0/2] [Batch 585/938] [D loss: -0.164808] [G loss: -14.522169]\n",
      "[Epoch 0/2] [Batch 590/938] [D loss: -0.299947] [G loss: -14.990110]\n",
      "[Epoch 0/2] [Batch 595/938] [D loss: -0.008717] [G loss: -15.190494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 600/938] [D loss: -0.139653] [G loss: -14.920118]\n",
      "[Epoch 0/2] [Batch 605/938] [D loss: -0.030760] [G loss: -14.545588]\n",
      "[Epoch 0/2] [Batch 610/938] [D loss: -0.117523] [G loss: -13.779972]\n",
      "[Epoch 0/2] [Batch 615/938] [D loss: -0.063792] [G loss: -13.245800]\n",
      "[Epoch 0/2] [Batch 620/938] [D loss: 0.025464] [G loss: -12.332292]\n",
      "[Epoch 0/2] [Batch 625/938] [D loss: -0.025538] [G loss: -12.055208]\n",
      "[Epoch 0/2] [Batch 630/938] [D loss: 0.031797] [G loss: -11.779657]\n",
      "[Epoch 0/2] [Batch 635/938] [D loss: -0.077046] [G loss: -11.655844]\n",
      "[Epoch 0/2] [Batch 640/938] [D loss: -0.194336] [G loss: -11.942909]\n",
      "[Epoch 0/2] [Batch 645/938] [D loss: -0.145226] [G loss: -11.549927]\n",
      "[Epoch 0/2] [Batch 650/938] [D loss: -0.126217] [G loss: -10.825991]\n",
      "[Epoch 0/2] [Batch 655/938] [D loss: -0.135314] [G loss: -11.134477]\n",
      "[Epoch 0/2] [Batch 660/938] [D loss: -0.056293] [G loss: -10.426508]\n",
      "[Epoch 0/2] [Batch 665/938] [D loss: -0.144836] [G loss: -10.337225]\n",
      "[Epoch 0/2] [Batch 670/938] [D loss: -0.237452] [G loss: -10.368586]\n",
      "[Epoch 0/2] [Batch 675/938] [D loss: -0.231857] [G loss: -10.446639]\n",
      "[Epoch 0/2] [Batch 680/938] [D loss: -0.265579] [G loss: -10.224514]\n",
      "[Epoch 0/2] [Batch 685/938] [D loss: -0.402235] [G loss: -9.580445]\n",
      "[Epoch 0/2] [Batch 690/938] [D loss: -0.486229] [G loss: -8.880322]\n",
      "[Epoch 0/2] [Batch 695/938] [D loss: -0.345812] [G loss: -8.251371]\n",
      "[Epoch 0/2] [Batch 700/938] [D loss: -0.483531] [G loss: -7.488847]\n",
      "[Epoch 0/2] [Batch 705/938] [D loss: -0.710842] [G loss: -6.713521]\n",
      "[Epoch 0/2] [Batch 710/938] [D loss: -0.470335] [G loss: -6.196989]\n",
      "[Epoch 0/2] [Batch 715/938] [D loss: -0.291015] [G loss: -5.926435]\n",
      "[Epoch 0/2] [Batch 720/938] [D loss: -0.336587] [G loss: -5.489355]\n",
      "[Epoch 0/2] [Batch 725/938] [D loss: -0.248037] [G loss: -5.225864]\n",
      "[Epoch 0/2] [Batch 730/938] [D loss: -0.207652] [G loss: -5.004755]\n",
      "[Epoch 0/2] [Batch 735/938] [D loss: -0.111289] [G loss: -4.275158]\n",
      "[Epoch 0/2] [Batch 740/938] [D loss: -0.097894] [G loss: -3.998124]\n",
      "[Epoch 0/2] [Batch 745/938] [D loss: -0.094365] [G loss: -3.602348]\n",
      "[Epoch 0/2] [Batch 750/938] [D loss: -0.051021] [G loss: -2.705831]\n",
      "[Epoch 0/2] [Batch 755/938] [D loss: -0.073340] [G loss: -1.883064]\n",
      "[Epoch 0/2] [Batch 760/938] [D loss: -0.154410] [G loss: -1.203627]\n",
      "[Epoch 0/2] [Batch 765/938] [D loss: -0.120372] [G loss: -0.336663]\n",
      "[Epoch 0/2] [Batch 770/938] [D loss: -0.319644] [G loss: -0.837152]\n",
      "[Epoch 0/2] [Batch 775/938] [D loss: -0.691814] [G loss: 0.672202]\n",
      "[Epoch 0/2] [Batch 780/938] [D loss: -0.866446] [G loss: 1.481034]\n",
      "[Epoch 0/2] [Batch 785/938] [D loss: -0.805290] [G loss: 1.757232]\n",
      "[Epoch 0/2] [Batch 790/938] [D loss: -0.782573] [G loss: 1.817888]\n",
      "[Epoch 0/2] [Batch 795/938] [D loss: -0.471228] [G loss: 3.345891]\n",
      "[Epoch 0/2] [Batch 800/938] [D loss: -0.160750] [G loss: 4.081102]\n",
      "[Epoch 0/2] [Batch 805/938] [D loss: 0.120132] [G loss: 3.277271]\n",
      "[Epoch 0/2] [Batch 810/938] [D loss: 0.204766] [G loss: 2.986166]\n",
      "[Epoch 0/2] [Batch 815/938] [D loss: 0.227021] [G loss: 2.569537]\n",
      "[Epoch 0/2] [Batch 820/938] [D loss: 0.149591] [G loss: 2.095663]\n",
      "[Epoch 0/2] [Batch 825/938] [D loss: 0.086884] [G loss: 1.584999]\n",
      "[Epoch 0/2] [Batch 830/938] [D loss: 0.057825] [G loss: 1.222013]\n",
      "[Epoch 0/2] [Batch 835/938] [D loss: 0.074478] [G loss: 0.942157]\n",
      "[Epoch 0/2] [Batch 840/938] [D loss: 0.015509] [G loss: 0.686557]\n",
      "[Epoch 0/2] [Batch 845/938] [D loss: 0.037262] [G loss: 0.505726]\n",
      "[Epoch 0/2] [Batch 850/938] [D loss: 0.019387] [G loss: 0.336007]\n",
      "[Epoch 0/2] [Batch 855/938] [D loss: 0.026745] [G loss: 0.192096]\n",
      "[Epoch 0/2] [Batch 860/938] [D loss: 0.007911] [G loss: 0.033263]\n",
      "[Epoch 0/2] [Batch 865/938] [D loss: -0.005441] [G loss: -0.116563]\n",
      "[Epoch 0/2] [Batch 870/938] [D loss: -0.002733] [G loss: -0.315415]\n",
      "[Epoch 0/2] [Batch 875/938] [D loss: -0.014012] [G loss: -0.614881]\n",
      "[Epoch 0/2] [Batch 880/938] [D loss: -0.025969] [G loss: -0.937565]\n",
      "[Epoch 0/2] [Batch 885/938] [D loss: -0.037985] [G loss: -1.415346]\n",
      "[Epoch 0/2] [Batch 890/938] [D loss: -0.148836] [G loss: -2.012969]\n",
      "[Epoch 0/2] [Batch 895/938] [D loss: -0.236233] [G loss: -2.654337]\n",
      "[Epoch 0/2] [Batch 900/938] [D loss: -0.378358] [G loss: -3.184537]\n",
      "[Epoch 0/2] [Batch 905/938] [D loss: -0.648991] [G loss: -3.368101]\n",
      "[Epoch 0/2] [Batch 910/938] [D loss: -0.509623] [G loss: -2.844533]\n",
      "[Epoch 0/2] [Batch 915/938] [D loss: -0.348988] [G loss: -2.361533]\n",
      "[Epoch 0/2] [Batch 920/938] [D loss: -0.329214] [G loss: -1.871264]\n",
      "[Epoch 0/2] [Batch 925/938] [D loss: -0.603693] [G loss: -0.367018]\n",
      "[Epoch 0/2] [Batch 930/938] [D loss: -0.464745] [G loss: -0.785059]\n",
      "[Epoch 0/2] [Batch 935/938] [D loss: -1.030291] [G loss: -0.765905]\n",
      "[Epoch 1/2] [Batch 0/938] [D loss: -0.309998] [G loss: -1.603257]\n",
      "[Epoch 1/2] [Batch 5/938] [D loss: -0.431560] [G loss: -1.488033]\n",
      "[Epoch 1/2] [Batch 10/938] [D loss: -0.172982] [G loss: -2.510315]\n",
      "[Epoch 1/2] [Batch 15/938] [D loss: -0.218274] [G loss: -2.923101]\n",
      "[Epoch 1/2] [Batch 20/938] [D loss: -0.381095] [G loss: -4.309740]\n",
      "[Epoch 1/2] [Batch 25/938] [D loss: -0.510474] [G loss: -4.843844]\n",
      "[Epoch 1/2] [Batch 30/938] [D loss: -0.416957] [G loss: -5.441643]\n",
      "[Epoch 1/2] [Batch 35/938] [D loss: -0.394632] [G loss: -4.652843]\n",
      "[Epoch 1/2] [Batch 40/938] [D loss: -0.338331] [G loss: -4.852314]\n",
      "[Epoch 1/2] [Batch 45/938] [D loss: -0.190645] [G loss: -4.755316]\n",
      "[Epoch 1/2] [Batch 50/938] [D loss: -0.247948] [G loss: -4.412917]\n",
      "[Epoch 1/2] [Batch 55/938] [D loss: -0.223213] [G loss: -2.950572]\n",
      "[Epoch 1/2] [Batch 60/938] [D loss: -0.107763] [G loss: -2.538673]\n",
      "[Epoch 1/2] [Batch 65/938] [D loss: -0.049958] [G loss: -2.246601]\n",
      "[Epoch 1/2] [Batch 70/938] [D loss: -0.074355] [G loss: -1.913603]\n",
      "[Epoch 1/2] [Batch 75/938] [D loss: 0.148480] [G loss: -1.235504]\n",
      "[Epoch 1/2] [Batch 80/938] [D loss: -0.174638] [G loss: -1.351579]\n",
      "[Epoch 1/2] [Batch 85/938] [D loss: -0.100824] [G loss: -0.807131]\n",
      "[Epoch 1/2] [Batch 90/938] [D loss: -0.124088] [G loss: -0.813022]\n",
      "[Epoch 1/2] [Batch 95/938] [D loss: 0.014406] [G loss: -1.264386]\n",
      "[Epoch 1/2] [Batch 100/938] [D loss: -0.131039] [G loss: -1.649598]\n",
      "[Epoch 1/2] [Batch 105/938] [D loss: -0.047570] [G loss: -1.292283]\n",
      "[Epoch 1/2] [Batch 110/938] [D loss: -0.103310] [G loss: -1.106636]\n",
      "[Epoch 1/2] [Batch 115/938] [D loss: -0.160084] [G loss: -0.469774]\n",
      "[Epoch 1/2] [Batch 120/938] [D loss: -0.289955] [G loss: -0.133545]\n",
      "[Epoch 1/2] [Batch 125/938] [D loss: -0.328693] [G loss: -0.439141]\n",
      "[Epoch 1/2] [Batch 130/938] [D loss: -0.467860] [G loss: -1.298451]\n",
      "[Epoch 1/2] [Batch 135/938] [D loss: -0.349481] [G loss: -0.747763]\n",
      "[Epoch 1/2] [Batch 140/938] [D loss: -0.397662] [G loss: -0.859458]\n",
      "[Epoch 1/2] [Batch 145/938] [D loss: -0.091049] [G loss: -0.396533]\n",
      "[Epoch 1/2] [Batch 150/938] [D loss: -0.567132] [G loss: -1.341168]\n",
      "[Epoch 1/2] [Batch 155/938] [D loss: -0.457566] [G loss: -0.558555]\n",
      "[Epoch 1/2] [Batch 160/938] [D loss: -0.645693] [G loss: -0.184140]\n",
      "[Epoch 1/2] [Batch 165/938] [D loss: -0.658555] [G loss: -0.847162]\n",
      "[Epoch 1/2] [Batch 170/938] [D loss: -0.744413] [G loss: -0.795291]\n",
      "[Epoch 1/2] [Batch 175/938] [D loss: -0.876315] [G loss: -0.867254]\n",
      "[Epoch 1/2] [Batch 180/938] [D loss: -1.065997] [G loss: -0.672630]\n",
      "[Epoch 1/2] [Batch 185/938] [D loss: -0.949702] [G loss: -0.373235]\n",
      "[Epoch 1/2] [Batch 190/938] [D loss: -0.868492] [G loss: -1.001630]\n",
      "[Epoch 1/2] [Batch 195/938] [D loss: -1.209971] [G loss: -0.551425]\n",
      "[Epoch 1/2] [Batch 200/938] [D loss: -0.881835] [G loss: -0.950508]\n",
      "[Epoch 1/2] [Batch 205/938] [D loss: -0.974500] [G loss: -0.702809]\n",
      "[Epoch 1/2] [Batch 210/938] [D loss: -1.035035] [G loss: -0.794507]\n",
      "[Epoch 1/2] [Batch 215/938] [D loss: -0.819990] [G loss: -1.119491]\n",
      "[Epoch 1/2] [Batch 220/938] [D loss: -0.788716] [G loss: -1.720429]\n",
      "[Epoch 1/2] [Batch 225/938] [D loss: -0.841535] [G loss: -1.483410]\n",
      "[Epoch 1/2] [Batch 230/938] [D loss: -0.700013] [G loss: -1.962030]\n",
      "[Epoch 1/2] [Batch 235/938] [D loss: -0.803164] [G loss: -2.283590]\n",
      "[Epoch 1/2] [Batch 240/938] [D loss: -0.787506] [G loss: -2.309084]\n",
      "[Epoch 1/2] [Batch 245/938] [D loss: -0.410390] [G loss: -2.920084]\n",
      "[Epoch 1/2] [Batch 250/938] [D loss: -0.594115] [G loss: -2.599642]\n",
      "[Epoch 1/2] [Batch 255/938] [D loss: -0.999672] [G loss: -2.335640]\n",
      "[Epoch 1/2] [Batch 260/938] [D loss: -0.809755] [G loss: -2.305825]\n",
      "[Epoch 1/2] [Batch 265/938] [D loss: -0.623098] [G loss: -2.442590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 270/938] [D loss: -1.015103] [G loss: -1.878932]\n",
      "[Epoch 1/2] [Batch 275/938] [D loss: -0.989455] [G loss: -2.327407]\n",
      "[Epoch 1/2] [Batch 280/938] [D loss: -0.725729] [G loss: -2.478575]\n",
      "[Epoch 1/2] [Batch 285/938] [D loss: -0.822465] [G loss: -2.667237]\n",
      "[Epoch 1/2] [Batch 290/938] [D loss: -0.891923] [G loss: -2.736108]\n",
      "[Epoch 1/2] [Batch 295/938] [D loss: -0.874644] [G loss: -2.233170]\n",
      "[Epoch 1/2] [Batch 300/938] [D loss: -0.815446] [G loss: -2.528566]\n",
      "[Epoch 1/2] [Batch 305/938] [D loss: -0.995366] [G loss: -2.252422]\n",
      "[Epoch 1/2] [Batch 310/938] [D loss: -0.692020] [G loss: -2.220856]\n",
      "[Epoch 1/2] [Batch 315/938] [D loss: -0.609085] [G loss: -2.614325]\n",
      "[Epoch 1/2] [Batch 320/938] [D loss: -0.677980] [G loss: -2.696496]\n",
      "[Epoch 1/2] [Batch 325/938] [D loss: -0.632648] [G loss: -2.793819]\n",
      "[Epoch 1/2] [Batch 330/938] [D loss: -0.376219] [G loss: -3.824297]\n",
      "[Epoch 1/2] [Batch 335/938] [D loss: -0.501630] [G loss: -3.943409]\n",
      "[Epoch 1/2] [Batch 340/938] [D loss: -0.469038] [G loss: -4.016922]\n",
      "[Epoch 1/2] [Batch 345/938] [D loss: -0.650050] [G loss: -3.784464]\n",
      "[Epoch 1/2] [Batch 350/938] [D loss: -0.623030] [G loss: -3.764071]\n",
      "[Epoch 1/2] [Batch 355/938] [D loss: -0.657095] [G loss: -3.675706]\n",
      "[Epoch 1/2] [Batch 360/938] [D loss: -0.603604] [G loss: -3.675988]\n",
      "[Epoch 1/2] [Batch 365/938] [D loss: -0.598302] [G loss: -3.307984]\n",
      "[Epoch 1/2] [Batch 370/938] [D loss: -0.729019] [G loss: -3.805426]\n",
      "[Epoch 1/2] [Batch 375/938] [D loss: -0.834246] [G loss: -2.984918]\n",
      "[Epoch 1/2] [Batch 380/938] [D loss: -0.764106] [G loss: -3.080646]\n",
      "[Epoch 1/2] [Batch 385/938] [D loss: -0.604124] [G loss: -3.677307]\n",
      "[Epoch 1/2] [Batch 390/938] [D loss: -0.662095] [G loss: -3.249569]\n",
      "[Epoch 1/2] [Batch 395/938] [D loss: -0.503854] [G loss: -3.898140]\n",
      "[Epoch 1/2] [Batch 400/938] [D loss: -0.637944] [G loss: -4.192928]\n",
      "[Epoch 1/2] [Batch 405/938] [D loss: -0.558948] [G loss: -3.660522]\n",
      "[Epoch 1/2] [Batch 410/938] [D loss: -0.871017] [G loss: -3.551531]\n",
      "[Epoch 1/2] [Batch 415/938] [D loss: -0.961449] [G loss: -3.194132]\n",
      "[Epoch 1/2] [Batch 420/938] [D loss: -0.903536] [G loss: -2.465311]\n",
      "[Epoch 1/2] [Batch 425/938] [D loss: -0.596973] [G loss: -2.622799]\n",
      "[Epoch 1/2] [Batch 430/938] [D loss: -0.803930] [G loss: -2.995070]\n",
      "[Epoch 1/2] [Batch 435/938] [D loss: -0.625742] [G loss: -3.452188]\n",
      "[Epoch 1/2] [Batch 440/938] [D loss: -0.739582] [G loss: -3.723454]\n",
      "[Epoch 1/2] [Batch 445/938] [D loss: -0.610841] [G loss: -3.364635]\n",
      "[Epoch 1/2] [Batch 450/938] [D loss: -0.598286] [G loss: -3.089396]\n",
      "[Epoch 1/2] [Batch 455/938] [D loss: -0.626968] [G loss: -2.725426]\n",
      "[Epoch 1/2] [Batch 460/938] [D loss: -0.780107] [G loss: -2.971766]\n",
      "[Epoch 1/2] [Batch 465/938] [D loss: -0.652291] [G loss: -3.434481]\n",
      "[Epoch 1/2] [Batch 470/938] [D loss: -0.771098] [G loss: -3.623287]\n",
      "[Epoch 1/2] [Batch 475/938] [D loss: -0.555800] [G loss: -3.344003]\n",
      "[Epoch 1/2] [Batch 480/938] [D loss: -0.632692] [G loss: -3.109987]\n",
      "[Epoch 1/2] [Batch 485/938] [D loss: -0.550723] [G loss: -3.269809]\n",
      "[Epoch 1/2] [Batch 490/938] [D loss: -0.668392] [G loss: -3.234477]\n",
      "[Epoch 1/2] [Batch 495/938] [D loss: -0.674280] [G loss: -2.941472]\n",
      "[Epoch 1/2] [Batch 500/938] [D loss: -0.575946] [G loss: -2.768932]\n",
      "[Epoch 1/2] [Batch 505/938] [D loss: -0.564914] [G loss: -2.348135]\n",
      "[Epoch 1/2] [Batch 510/938] [D loss: -0.569225] [G loss: -2.418084]\n",
      "[Epoch 1/2] [Batch 515/938] [D loss: -0.699004] [G loss: -1.927715]\n",
      "[Epoch 1/2] [Batch 520/938] [D loss: -0.704838] [G loss: -1.167784]\n",
      "[Epoch 1/2] [Batch 525/938] [D loss: -0.733427] [G loss: -1.000416]\n",
      "[Epoch 1/2] [Batch 530/938] [D loss: -0.878133] [G loss: -1.108300]\n",
      "[Epoch 1/2] [Batch 535/938] [D loss: -0.895518] [G loss: -0.838167]\n",
      "[Epoch 1/2] [Batch 540/938] [D loss: -0.640110] [G loss: -1.368048]\n",
      "[Epoch 1/2] [Batch 545/938] [D loss: -0.857856] [G loss: -0.919695]\n",
      "[Epoch 1/2] [Batch 550/938] [D loss: -0.907033] [G loss: -0.259871]\n",
      "[Epoch 1/2] [Batch 555/938] [D loss: -0.961394] [G loss: -0.320814]\n",
      "[Epoch 1/2] [Batch 560/938] [D loss: -0.776273] [G loss: -1.211089]\n",
      "[Epoch 1/2] [Batch 565/938] [D loss: -1.218473] [G loss: -1.061150]\n",
      "[Epoch 1/2] [Batch 570/938] [D loss: -0.936690] [G loss: -1.127700]\n",
      "[Epoch 1/2] [Batch 575/938] [D loss: -0.966898] [G loss: -0.587763]\n",
      "[Epoch 1/2] [Batch 580/938] [D loss: -1.278350] [G loss: -1.011459]\n",
      "[Epoch 1/2] [Batch 585/938] [D loss: -1.480693] [G loss: -1.238108]\n",
      "[Epoch 1/2] [Batch 590/938] [D loss: -1.530093] [G loss: -0.972025]\n",
      "[Epoch 1/2] [Batch 595/938] [D loss: -1.343010] [G loss: -0.723611]\n",
      "[Epoch 1/2] [Batch 600/938] [D loss: -1.373280] [G loss: -0.694970]\n",
      "[Epoch 1/2] [Batch 605/938] [D loss: -1.610260] [G loss: -0.320800]\n",
      "[Epoch 1/2] [Batch 610/938] [D loss: -1.291467] [G loss: -0.413286]\n",
      "[Epoch 1/2] [Batch 615/938] [D loss: -1.396656] [G loss: -0.558758]\n",
      "[Epoch 1/2] [Batch 620/938] [D loss: -1.011822] [G loss: -0.551348]\n",
      "[Epoch 1/2] [Batch 625/938] [D loss: -1.217591] [G loss: -0.524497]\n",
      "[Epoch 1/2] [Batch 630/938] [D loss: -1.205202] [G loss: -0.671789]\n",
      "[Epoch 1/2] [Batch 635/938] [D loss: -1.300670] [G loss: -0.737518]\n",
      "[Epoch 1/2] [Batch 640/938] [D loss: -1.080649] [G loss: -0.851731]\n",
      "[Epoch 1/2] [Batch 645/938] [D loss: -0.705470] [G loss: -0.887681]\n",
      "[Epoch 1/2] [Batch 650/938] [D loss: -0.883267] [G loss: -0.935930]\n",
      "[Epoch 1/2] [Batch 655/938] [D loss: -0.869724] [G loss: -0.966784]\n",
      "[Epoch 1/2] [Batch 660/938] [D loss: -0.928285] [G loss: -0.735806]\n",
      "[Epoch 1/2] [Batch 665/938] [D loss: -0.987311] [G loss: -0.827204]\n",
      "[Epoch 1/2] [Batch 670/938] [D loss: -0.997919] [G loss: -0.611503]\n",
      "[Epoch 1/2] [Batch 675/938] [D loss: -0.849187] [G loss: -1.218972]\n",
      "[Epoch 1/2] [Batch 680/938] [D loss: -1.115969] [G loss: -0.413698]\n",
      "[Epoch 1/2] [Batch 685/938] [D loss: -0.821579] [G loss: -0.454834]\n",
      "[Epoch 1/2] [Batch 690/938] [D loss: -0.915584] [G loss: -0.870266]\n",
      "[Epoch 1/2] [Batch 695/938] [D loss: -1.217651] [G loss: -0.507879]\n",
      "[Epoch 1/2] [Batch 700/938] [D loss: -0.894739] [G loss: -1.000670]\n",
      "[Epoch 1/2] [Batch 705/938] [D loss: -1.638809] [G loss: -1.083565]\n",
      "[Epoch 1/2] [Batch 710/938] [D loss: -1.097144] [G loss: -0.897623]\n",
      "[Epoch 1/2] [Batch 715/938] [D loss: -1.104577] [G loss: -0.734130]\n",
      "[Epoch 1/2] [Batch 720/938] [D loss: -1.301252] [G loss: -1.501149]\n",
      "[Epoch 1/2] [Batch 725/938] [D loss: -0.967027] [G loss: -1.110112]\n",
      "[Epoch 1/2] [Batch 730/938] [D loss: -0.966261] [G loss: -1.281912]\n",
      "[Epoch 1/2] [Batch 735/938] [D loss: -1.108426] [G loss: -1.333268]\n",
      "[Epoch 1/2] [Batch 740/938] [D loss: -0.990858] [G loss: -2.081800]\n",
      "[Epoch 1/2] [Batch 745/938] [D loss: -1.004249] [G loss: -1.761523]\n",
      "[Epoch 1/2] [Batch 750/938] [D loss: -0.865102] [G loss: -1.352200]\n",
      "[Epoch 1/2] [Batch 755/938] [D loss: -1.156644] [G loss: -1.069842]\n",
      "[Epoch 1/2] [Batch 760/938] [D loss: -1.155460] [G loss: -0.561435]\n",
      "[Epoch 1/2] [Batch 765/938] [D loss: -1.211039] [G loss: -0.745202]\n",
      "[Epoch 1/2] [Batch 770/938] [D loss: -1.180256] [G loss: -0.762277]\n",
      "[Epoch 1/2] [Batch 775/938] [D loss: -1.004754] [G loss: -1.083297]\n",
      "[Epoch 1/2] [Batch 780/938] [D loss: -1.053804] [G loss: -0.960057]\n",
      "[Epoch 1/2] [Batch 785/938] [D loss: -1.323256] [G loss: -0.942434]\n",
      "[Epoch 1/2] [Batch 790/938] [D loss: -0.935667] [G loss: -1.087530]\n",
      "[Epoch 1/2] [Batch 795/938] [D loss: -1.065609] [G loss: -1.216234]\n",
      "[Epoch 1/2] [Batch 800/938] [D loss: -0.898265] [G loss: -1.219592]\n",
      "[Epoch 1/2] [Batch 805/938] [D loss: -0.925993] [G loss: -1.070715]\n",
      "[Epoch 1/2] [Batch 810/938] [D loss: -1.092413] [G loss: -1.236530]\n",
      "[Epoch 1/2] [Batch 815/938] [D loss: -1.299145] [G loss: -0.745463]\n",
      "[Epoch 1/2] [Batch 820/938] [D loss: -1.217541] [G loss: -0.768487]\n",
      "[Epoch 1/2] [Batch 825/938] [D loss: -1.258823] [G loss: -0.889323]\n",
      "[Epoch 1/2] [Batch 830/938] [D loss: -1.473174] [G loss: -1.160492]\n",
      "[Epoch 1/2] [Batch 835/938] [D loss: -1.215247] [G loss: -1.202616]\n",
      "[Epoch 1/2] [Batch 840/938] [D loss: -1.022788] [G loss: -0.651050]\n",
      "[Epoch 1/2] [Batch 845/938] [D loss: -1.430461] [G loss: -0.780840]\n",
      "[Epoch 1/2] [Batch 850/938] [D loss: -1.547323] [G loss: -1.199626]\n",
      "[Epoch 1/2] [Batch 855/938] [D loss: -1.454268] [G loss: -0.780240]\n",
      "[Epoch 1/2] [Batch 860/938] [D loss: -1.405772] [G loss: -0.577451]\n",
      "[Epoch 1/2] [Batch 865/938] [D loss: -1.398271] [G loss: -0.678144]\n",
      "[Epoch 1/2] [Batch 870/938] [D loss: -1.670367] [G loss: -0.917582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 875/938] [D loss: -1.336512] [G loss: -0.826768]\n",
      "[Epoch 1/2] [Batch 880/938] [D loss: -0.987317] [G loss: -1.030190]\n",
      "[Epoch 1/2] [Batch 885/938] [D loss: -1.024814] [G loss: -1.044658]\n",
      "[Epoch 1/2] [Batch 890/938] [D loss: -1.062631] [G loss: -1.164799]\n",
      "[Epoch 1/2] [Batch 895/938] [D loss: -1.221211] [G loss: -1.045762]\n",
      "[Epoch 1/2] [Batch 900/938] [D loss: -1.184878] [G loss: -1.081911]\n",
      "[Epoch 1/2] [Batch 905/938] [D loss: -0.895218] [G loss: -1.340942]\n",
      "[Epoch 1/2] [Batch 910/938] [D loss: -0.725032] [G loss: -1.759452]\n",
      "[Epoch 1/2] [Batch 915/938] [D loss: -0.885188] [G loss: -1.368738]\n",
      "[Epoch 1/2] [Batch 920/938] [D loss: -0.768236] [G loss: -1.297593]\n",
      "[Epoch 1/2] [Batch 925/938] [D loss: -1.152323] [G loss: -1.094676]\n",
      "[Epoch 1/2] [Batch 930/938] [D loss: -1.039139] [G loss: -1.573450]\n",
      "[Epoch 1/2] [Batch 935/938] [D loss: -0.769973] [G loss: -1.741257]\n",
      "saving states\n"
     ]
    }
   ],
   "source": [
    "\n",
    "WGAN = gan.WGAN(\"mnist_wgan\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(WGAN.identifier)\n",
    "with mlflow.start_run(experiment_id=WGAN.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    WGAN.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=5,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        clip_tresh=0.01,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
