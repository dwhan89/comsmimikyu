{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from cosmikyu import visualization as covis\n",
    "from cosmikyu import gan, config\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config.default_data_dir\n",
    "mnist_dir = os.path.join(data_dir, 'mnist')\n",
    "cuda = False\n",
    "shape = (1,28,28)\n",
    "latent_dim = 100\n",
    "sample_interval = 1000\n",
    "save_interval = 50000\n",
    "batch_size = 64\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        mnist_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "VP = None # covis.VisdomPlotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WGAN = gan.WGAN(\"mnistv2\", shape, latent_dim, cuda=True, ngpu=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "[Epoch 0/200] [Batch 0/938] [D loss: 0.022548] [G loss: 0.009579]\n",
      "saving states\n",
      "[Epoch 0/200] [Batch 5/938] [D loss: 0.529250] [G loss: 0.016102]\n",
      "[Epoch 0/200] [Batch 10/938] [D loss: 1.272625] [G loss: 0.040125]\n",
      "[Epoch 0/200] [Batch 15/938] [D loss: 2.039369] [G loss: 0.079226]\n",
      "[Epoch 0/200] [Batch 20/938] [D loss: 2.881820] [G loss: 0.137924]\n",
      "[Epoch 0/200] [Batch 25/938] [D loss: 3.649480] [G loss: 0.216242]\n",
      "[Epoch 0/200] [Batch 30/938] [D loss: 4.377010] [G loss: 0.312017]\n",
      "[Epoch 0/200] [Batch 35/938] [D loss: 5.139267] [G loss: 0.441116]\n",
      "[Epoch 0/200] [Batch 40/938] [D loss: 5.788734] [G loss: 0.577204]\n",
      "[Epoch 0/200] [Batch 45/938] [D loss: 6.637061] [G loss: 0.714371]\n",
      "[Epoch 0/200] [Batch 50/938] [D loss: 7.104387] [G loss: 0.910814]\n",
      "[Epoch 0/200] [Batch 55/938] [D loss: 7.791006] [G loss: 1.134170]\n",
      "[Epoch 0/200] [Batch 60/938] [D loss: 8.318607] [G loss: 1.303359]\n",
      "[Epoch 0/200] [Batch 65/938] [D loss: 8.741735] [G loss: 1.618415]\n",
      "[Epoch 0/200] [Batch 70/938] [D loss: 9.223342] [G loss: 1.866428]\n",
      "[Epoch 0/200] [Batch 75/938] [D loss: 9.631028] [G loss: 2.182670]\n",
      "[Epoch 0/200] [Batch 80/938] [D loss: 10.148879] [G loss: 2.436999]\n",
      "[Epoch 0/200] [Batch 85/938] [D loss: 10.574038] [G loss: 2.831254]\n",
      "[Epoch 0/200] [Batch 90/938] [D loss: 10.802105] [G loss: 3.303038]\n",
      "[Epoch 0/200] [Batch 95/938] [D loss: 11.269035] [G loss: 3.667186]\n",
      "[Epoch 0/200] [Batch 100/938] [D loss: 11.331743] [G loss: 4.074805]\n",
      "[Epoch 0/200] [Batch 105/938] [D loss: 11.281406] [G loss: 4.446933]\n",
      "[Epoch 0/200] [Batch 110/938] [D loss: 11.714478] [G loss: 4.924109]\n",
      "[Epoch 0/200] [Batch 115/938] [D loss: 11.335603] [G loss: 5.439252]\n",
      "[Epoch 0/200] [Batch 120/938] [D loss: 11.843119] [G loss: 6.121567]\n",
      "[Epoch 0/200] [Batch 125/938] [D loss: 11.839069] [G loss: 6.458366]\n",
      "[Epoch 0/200] [Batch 130/938] [D loss: 12.198133] [G loss: 6.892550]\n",
      "[Epoch 0/200] [Batch 135/938] [D loss: 11.757697] [G loss: 7.606852]\n",
      "[Epoch 0/200] [Batch 140/938] [D loss: 11.698828] [G loss: 8.329260]\n",
      "[Epoch 0/200] [Batch 145/938] [D loss: 11.987085] [G loss: 8.622613]\n",
      "[Epoch 0/200] [Batch 150/938] [D loss: 11.580432] [G loss: 9.502911]\n",
      "[Epoch 0/200] [Batch 155/938] [D loss: 11.889029] [G loss: 10.024224]\n",
      "[Epoch 0/200] [Batch 160/938] [D loss: 11.239803] [G loss: 10.754110]\n",
      "[Epoch 0/200] [Batch 165/938] [D loss: 10.755295] [G loss: 11.699653]\n",
      "[Epoch 0/200] [Batch 170/938] [D loss: 10.556808] [G loss: 12.304810]\n",
      "[Epoch 0/200] [Batch 175/938] [D loss: 10.915100] [G loss: 12.546267]\n",
      "[Epoch 0/200] [Batch 180/938] [D loss: 10.850412] [G loss: 12.803646]\n",
      "[Epoch 0/200] [Batch 185/938] [D loss: 10.735306] [G loss: 13.404688]\n",
      "[Epoch 0/200] [Batch 190/938] [D loss: 10.055363] [G loss: 14.177658]\n",
      "[Epoch 0/200] [Batch 195/938] [D loss: 9.126377] [G loss: 15.542232]\n",
      "[Epoch 0/200] [Batch 200/938] [D loss: 9.655758] [G loss: 15.314943]\n",
      "[Epoch 0/200] [Batch 205/938] [D loss: 9.260973] [G loss: 16.330856]\n",
      "[Epoch 0/200] [Batch 210/938] [D loss: 9.483524] [G loss: 15.587828]\n",
      "[Epoch 0/200] [Batch 215/938] [D loss: 8.543646] [G loss: 17.036474]\n",
      "[Epoch 0/200] [Batch 220/938] [D loss: 8.123098] [G loss: 17.702318]\n",
      "[Epoch 0/200] [Batch 225/938] [D loss: 7.674980] [G loss: 17.893669]\n",
      "[Epoch 0/200] [Batch 230/938] [D loss: 7.798750] [G loss: 18.207417]\n",
      "[Epoch 0/200] [Batch 235/938] [D loss: 8.171850] [G loss: 18.400982]\n",
      "[Epoch 0/200] [Batch 240/938] [D loss: 6.803463] [G loss: 19.038559]\n",
      "[Epoch 0/200] [Batch 245/938] [D loss: 6.984726] [G loss: 18.989344]\n",
      "[Epoch 0/200] [Batch 250/938] [D loss: 6.714510] [G loss: 18.882099]\n",
      "[Epoch 0/200] [Batch 255/938] [D loss: 6.341045] [G loss: 19.593201]\n",
      "[Epoch 0/200] [Batch 260/938] [D loss: 5.823666] [G loss: 19.852562]\n",
      "[Epoch 0/200] [Batch 265/938] [D loss: 6.013300] [G loss: 19.339079]\n",
      "[Epoch 0/200] [Batch 270/938] [D loss: 5.098658] [G loss: 20.482944]\n",
      "[Epoch 0/200] [Batch 275/938] [D loss: 5.683678] [G loss: 19.893145]\n",
      "[Epoch 0/200] [Batch 280/938] [D loss: 5.002783] [G loss: 20.346331]\n",
      "[Epoch 0/200] [Batch 285/938] [D loss: 4.670296] [G loss: 20.310263]\n",
      "[Epoch 0/200] [Batch 290/938] [D loss: 4.826910] [G loss: 20.012733]\n",
      "[Epoch 0/200] [Batch 295/938] [D loss: 4.410463] [G loss: 20.474491]\n",
      "[Epoch 0/200] [Batch 300/938] [D loss: 4.899511] [G loss: 20.057446]\n",
      "[Epoch 0/200] [Batch 305/938] [D loss: 5.686251] [G loss: 19.291904]\n",
      "[Epoch 0/200] [Batch 310/938] [D loss: 4.229698] [G loss: 20.389200]\n",
      "[Epoch 0/200] [Batch 315/938] [D loss: 4.620642] [G loss: 20.265858]\n",
      "[Epoch 0/200] [Batch 320/938] [D loss: 4.483011] [G loss: 20.036064]\n",
      "[Epoch 0/200] [Batch 325/938] [D loss: 3.770599] [G loss: 20.297188]\n",
      "[Epoch 0/200] [Batch 330/938] [D loss: 3.900852] [G loss: 20.084133]\n",
      "[Epoch 0/200] [Batch 335/938] [D loss: 3.876968] [G loss: 20.409332]\n",
      "[Epoch 0/200] [Batch 340/938] [D loss: 3.756041] [G loss: 20.044552]\n",
      "[Epoch 0/200] [Batch 345/938] [D loss: 3.912260] [G loss: 19.936192]\n",
      "[Epoch 0/200] [Batch 350/938] [D loss: 4.124107] [G loss: 19.570881]\n",
      "[Epoch 0/200] [Batch 355/938] [D loss: 3.445433] [G loss: 20.253845]\n",
      "[Epoch 0/200] [Batch 360/938] [D loss: 3.415451] [G loss: 20.168945]\n",
      "[Epoch 0/200] [Batch 365/938] [D loss: 3.511431] [G loss: 20.004271]\n",
      "[Epoch 0/200] [Batch 370/938] [D loss: 4.016651] [G loss: 19.638752]\n",
      "[Epoch 0/200] [Batch 375/938] [D loss: 3.195192] [G loss: 20.040754]\n",
      "[Epoch 0/200] [Batch 380/938] [D loss: 3.033978] [G loss: 20.027874]\n",
      "[Epoch 0/200] [Batch 385/938] [D loss: 3.455353] [G loss: 19.690989]\n",
      "[Epoch 0/200] [Batch 390/938] [D loss: 3.427425] [G loss: 19.633907]\n",
      "[Epoch 0/200] [Batch 395/938] [D loss: 3.282495] [G loss: 19.657574]\n",
      "[Epoch 0/200] [Batch 400/938] [D loss: 3.480589] [G loss: 19.462965]\n",
      "[Epoch 0/200] [Batch 405/938] [D loss: 2.567692] [G loss: 19.776855]\n",
      "[Epoch 0/200] [Batch 410/938] [D loss: 3.511700] [G loss: 19.009911]\n",
      "[Epoch 0/200] [Batch 415/938] [D loss: 3.416355] [G loss: 19.228899]\n",
      "[Epoch 0/200] [Batch 420/938] [D loss: 2.651428] [G loss: 19.387766]\n",
      "[Epoch 0/200] [Batch 425/938] [D loss: 2.971788] [G loss: 19.340414]\n",
      "[Epoch 0/200] [Batch 430/938] [D loss: 2.966654] [G loss: 19.310566]\n",
      "[Epoch 0/200] [Batch 435/938] [D loss: 2.741865] [G loss: 19.329004]\n",
      "[Epoch 0/200] [Batch 440/938] [D loss: 2.436035] [G loss: 19.372410]\n",
      "[Epoch 0/200] [Batch 445/938] [D loss: 3.118574] [G loss: 18.852242]\n",
      "[Epoch 0/200] [Batch 450/938] [D loss: 2.565727] [G loss: 18.913639]\n",
      "[Epoch 0/200] [Batch 455/938] [D loss: 2.633268] [G loss: 19.136284]\n",
      "[Epoch 0/200] [Batch 460/938] [D loss: 2.774479] [G loss: 18.770847]\n",
      "[Epoch 0/200] [Batch 465/938] [D loss: 2.756632] [G loss: 18.782085]\n",
      "[Epoch 0/200] [Batch 470/938] [D loss: 2.780960] [G loss: 18.531546]\n",
      "[Epoch 0/200] [Batch 475/938] [D loss: 2.560806] [G loss: 18.702892]\n",
      "[Epoch 0/200] [Batch 480/938] [D loss: 2.665960] [G loss: 18.218586]\n",
      "[Epoch 0/200] [Batch 485/938] [D loss: 2.538435] [G loss: 18.371161]\n",
      "[Epoch 0/200] [Batch 490/938] [D loss: 2.333286] [G loss: 18.374420]\n",
      "[Epoch 0/200] [Batch 495/938] [D loss: 2.412960] [G loss: 18.381607]\n",
      "[Epoch 0/200] [Batch 500/938] [D loss: 2.594820] [G loss: 18.179466]\n",
      "[Epoch 0/200] [Batch 505/938] [D loss: 2.346258] [G loss: 18.026714]\n",
      "[Epoch 0/200] [Batch 510/938] [D loss: 2.453524] [G loss: 17.923042]\n",
      "[Epoch 0/200] [Batch 515/938] [D loss: 2.286573] [G loss: 17.887306]\n",
      "[Epoch 0/200] [Batch 520/938] [D loss: 2.255856] [G loss: 17.967573]\n",
      "[Epoch 0/200] [Batch 525/938] [D loss: 2.214603] [G loss: 17.846807]\n",
      "[Epoch 0/200] [Batch 530/938] [D loss: 1.817635] [G loss: 17.648672]\n",
      "[Epoch 0/200] [Batch 535/938] [D loss: 1.868078] [G loss: 17.860569]\n",
      "[Epoch 0/200] [Batch 540/938] [D loss: 2.120693] [G loss: 17.727133]\n",
      "[Epoch 0/200] [Batch 545/938] [D loss: 2.229639] [G loss: 17.546455]\n",
      "[Epoch 0/200] [Batch 550/938] [D loss: 1.966902] [G loss: 17.727526]\n",
      "[Epoch 0/200] [Batch 555/938] [D loss: 2.029478] [G loss: 17.421864]\n",
      "[Epoch 0/200] [Batch 560/938] [D loss: 2.072958] [G loss: 17.176500]\n",
      "[Epoch 0/200] [Batch 565/938] [D loss: 2.111197] [G loss: 17.400448]\n",
      "[Epoch 0/200] [Batch 570/938] [D loss: 2.459276] [G loss: 17.192369]\n",
      "[Epoch 0/200] [Batch 575/938] [D loss: 1.757988] [G loss: 17.530247]\n",
      "[Epoch 0/200] [Batch 580/938] [D loss: 1.778828] [G loss: 17.177444]\n",
      "[Epoch 0/200] [Batch 585/938] [D loss: 1.807259] [G loss: 17.222927]\n",
      "[Epoch 0/200] [Batch 590/938] [D loss: 1.651745] [G loss: 16.927284]\n",
      "[Epoch 0/200] [Batch 595/938] [D loss: 1.357094] [G loss: 17.179295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 600/938] [D loss: 2.005661] [G loss: 16.794849]\n",
      "[Epoch 0/200] [Batch 605/938] [D loss: 1.424290] [G loss: 16.813429]\n",
      "[Epoch 0/200] [Batch 610/938] [D loss: 1.711176] [G loss: 16.794567]\n",
      "[Epoch 0/200] [Batch 615/938] [D loss: 1.892174] [G loss: 16.482193]\n",
      "[Epoch 0/200] [Batch 620/938] [D loss: 1.616594] [G loss: 16.689457]\n",
      "[Epoch 0/200] [Batch 625/938] [D loss: 1.696751] [G loss: 16.614529]\n",
      "[Epoch 0/200] [Batch 630/938] [D loss: 1.707897] [G loss: 16.563805]\n",
      "[Epoch 0/200] [Batch 635/938] [D loss: 1.563280] [G loss: 16.447937]\n",
      "[Epoch 0/200] [Batch 640/938] [D loss: 1.550278] [G loss: 16.469917]\n",
      "[Epoch 0/200] [Batch 645/938] [D loss: 1.439404] [G loss: 16.583298]\n",
      "[Epoch 0/200] [Batch 650/938] [D loss: 1.559813] [G loss: 16.467180]\n",
      "[Epoch 0/200] [Batch 655/938] [D loss: 1.863800] [G loss: 16.289307]\n",
      "[Epoch 0/200] [Batch 660/938] [D loss: 1.277176] [G loss: 16.379204]\n",
      "[Epoch 0/200] [Batch 665/938] [D loss: 1.632572] [G loss: 16.097008]\n",
      "[Epoch 0/200] [Batch 670/938] [D loss: 1.340261] [G loss: 15.995932]\n",
      "[Epoch 0/200] [Batch 675/938] [D loss: 1.452614] [G loss: 16.059505]\n",
      "[Epoch 0/200] [Batch 680/938] [D loss: 0.877031] [G loss: 16.014812]\n",
      "[Epoch 0/200] [Batch 685/938] [D loss: 1.302853] [G loss: 15.974876]\n",
      "[Epoch 0/200] [Batch 690/938] [D loss: 1.308855] [G loss: 15.970854]\n",
      "[Epoch 0/200] [Batch 695/938] [D loss: 1.296518] [G loss: 15.974012]\n",
      "[Epoch 0/200] [Batch 700/938] [D loss: 1.399736] [G loss: 15.879487]\n",
      "[Epoch 0/200] [Batch 705/938] [D loss: 0.858844] [G loss: 15.855976]\n",
      "[Epoch 0/200] [Batch 710/938] [D loss: 1.315506] [G loss: 15.781944]\n",
      "[Epoch 0/200] [Batch 715/938] [D loss: 1.276379] [G loss: 15.704586]\n",
      "[Epoch 0/200] [Batch 720/938] [D loss: 1.539164] [G loss: 15.632914]\n",
      "[Epoch 0/200] [Batch 725/938] [D loss: 1.165855] [G loss: 15.601143]\n",
      "[Epoch 0/200] [Batch 730/938] [D loss: 1.397911] [G loss: 15.617065]\n",
      "[Epoch 0/200] [Batch 735/938] [D loss: 1.322786] [G loss: 15.535957]\n",
      "[Epoch 0/200] [Batch 740/938] [D loss: 1.203757] [G loss: 15.505647]\n",
      "[Epoch 0/200] [Batch 745/938] [D loss: 1.372889] [G loss: 15.395992]\n",
      "[Epoch 0/200] [Batch 750/938] [D loss: 1.181685] [G loss: 15.313703]\n",
      "[Epoch 0/200] [Batch 755/938] [D loss: 1.370129] [G loss: 15.229518]\n",
      "[Epoch 0/200] [Batch 760/938] [D loss: 1.505800] [G loss: 15.173225]\n",
      "[Epoch 0/200] [Batch 765/938] [D loss: 1.542362] [G loss: 15.219156]\n",
      "[Epoch 0/200] [Batch 770/938] [D loss: 1.221550] [G loss: 15.049372]\n",
      "[Epoch 0/200] [Batch 775/938] [D loss: 1.205522] [G loss: 15.173798]\n",
      "[Epoch 0/200] [Batch 780/938] [D loss: 1.154447] [G loss: 15.131437]\n",
      "[Epoch 0/200] [Batch 785/938] [D loss: 1.023741] [G loss: 15.099646]\n",
      "[Epoch 0/200] [Batch 790/938] [D loss: 1.353988] [G loss: 14.884005]\n",
      "[Epoch 0/200] [Batch 795/938] [D loss: 0.718145] [G loss: 15.005386]\n",
      "[Epoch 0/200] [Batch 800/938] [D loss: 1.090958] [G loss: 14.889675]\n",
      "[Epoch 0/200] [Batch 805/938] [D loss: 1.092215] [G loss: 14.900278]\n",
      "[Epoch 0/200] [Batch 810/938] [D loss: 1.208199] [G loss: 14.786826]\n",
      "[Epoch 0/200] [Batch 815/938] [D loss: 1.076818] [G loss: 14.811582]\n",
      "[Epoch 0/200] [Batch 820/938] [D loss: 1.143734] [G loss: 14.783228]\n",
      "[Epoch 0/200] [Batch 825/938] [D loss: 0.802962] [G loss: 14.785965]\n",
      "[Epoch 0/200] [Batch 830/938] [D loss: 1.279721] [G loss: 14.732409]\n",
      "[Epoch 0/200] [Batch 835/938] [D loss: 1.102630] [G loss: 14.653299]\n",
      "[Epoch 0/200] [Batch 840/938] [D loss: 1.295968] [G loss: 14.634596]\n",
      "[Epoch 0/200] [Batch 845/938] [D loss: 1.011737] [G loss: 14.604818]\n",
      "[Epoch 0/200] [Batch 850/938] [D loss: 0.787832] [G loss: 14.584862]\n",
      "[Epoch 0/200] [Batch 855/938] [D loss: 1.042889] [G loss: 14.598560]\n",
      "[Epoch 0/200] [Batch 860/938] [D loss: 1.059515] [G loss: 14.483304]\n",
      "[Epoch 0/200] [Batch 865/938] [D loss: 1.009544] [G loss: 14.547096]\n",
      "[Epoch 0/200] [Batch 870/938] [D loss: 0.879178] [G loss: 14.474413]\n",
      "[Epoch 0/200] [Batch 875/938] [D loss: 1.172400] [G loss: 14.380600]\n",
      "[Epoch 0/200] [Batch 880/938] [D loss: 0.960342] [G loss: 14.432818]\n",
      "[Epoch 0/200] [Batch 885/938] [D loss: 0.799850] [G loss: 14.396721]\n",
      "[Epoch 0/200] [Batch 890/938] [D loss: 1.065288] [G loss: 14.386757]\n",
      "[Epoch 0/200] [Batch 895/938] [D loss: 0.983996] [G loss: 14.253513]\n",
      "[Epoch 0/200] [Batch 900/938] [D loss: 0.747616] [G loss: 14.322010]\n",
      "[Epoch 0/200] [Batch 905/938] [D loss: 1.056694] [G loss: 14.250656]\n",
      "[Epoch 0/200] [Batch 910/938] [D loss: 0.847685] [G loss: 14.249414]\n",
      "[Epoch 0/200] [Batch 915/938] [D loss: 0.876871] [G loss: 14.204313]\n",
      "[Epoch 0/200] [Batch 920/938] [D loss: 0.852291] [G loss: 14.206177]\n",
      "[Epoch 0/200] [Batch 925/938] [D loss: 0.931720] [G loss: 14.203805]\n",
      "[Epoch 0/200] [Batch 930/938] [D loss: 0.909826] [G loss: 14.185349]\n",
      "[Epoch 0/200] [Batch 935/938] [D loss: 0.820045] [G loss: 14.198752]\n",
      "[Epoch 1/200] [Batch 0/938] [D loss: 0.892321] [G loss: 14.213022]\n",
      "[Epoch 1/200] [Batch 5/938] [D loss: 1.066345] [G loss: 14.136319]\n",
      "[Epoch 1/200] [Batch 10/938] [D loss: 0.745986] [G loss: 14.144167]\n",
      "[Epoch 1/200] [Batch 15/938] [D loss: 0.908766] [G loss: 14.018085]\n",
      "[Epoch 1/200] [Batch 20/938] [D loss: 0.739338] [G loss: 14.204605]\n",
      "[Epoch 1/200] [Batch 25/938] [D loss: 0.551655] [G loss: 14.121535]\n",
      "[Epoch 1/200] [Batch 30/938] [D loss: 0.611433] [G loss: 14.160282]\n",
      "[Epoch 1/200] [Batch 35/938] [D loss: 1.015514] [G loss: 14.092865]\n",
      "[Epoch 1/200] [Batch 40/938] [D loss: 0.744229] [G loss: 14.080725]\n",
      "[Epoch 1/200] [Batch 45/938] [D loss: 0.776193] [G loss: 14.040562]\n",
      "[Epoch 1/200] [Batch 50/938] [D loss: 0.774494] [G loss: 14.024900]\n",
      "[Epoch 1/200] [Batch 55/938] [D loss: 0.380838] [G loss: 14.124290]\n",
      "[Epoch 1/200] [Batch 60/938] [D loss: 0.847856] [G loss: 14.081546]\n",
      "[Epoch 1/200] [Batch 65/938] [D loss: 0.470588] [G loss: 14.125748]\n",
      "[Epoch 1/200] [Batch 70/938] [D loss: 0.488711] [G loss: 14.129724]\n",
      "[Epoch 1/200] [Batch 75/938] [D loss: 0.540724] [G loss: 14.072719]\n",
      "[Epoch 1/200] [Batch 80/938] [D loss: 0.543719] [G loss: 13.982515]\n",
      "[Epoch 1/200] [Batch 85/938] [D loss: 0.623811] [G loss: 13.988029]\n",
      "[Epoch 1/200] [Batch 90/938] [D loss: 0.673218] [G loss: 14.058544]\n",
      "[Epoch 1/200] [Batch 95/938] [D loss: 0.764313] [G loss: 14.013689]\n",
      "[Epoch 1/200] [Batch 100/938] [D loss: 0.495358] [G loss: 14.115005]\n",
      "[Epoch 1/200] [Batch 105/938] [D loss: 0.552753] [G loss: 14.056014]\n",
      "[Epoch 1/200] [Batch 110/938] [D loss: 0.581511] [G loss: 13.997149]\n",
      "[Epoch 1/200] [Batch 115/938] [D loss: 0.503229] [G loss: 14.022968]\n",
      "[Epoch 1/200] [Batch 120/938] [D loss: 0.628382] [G loss: 13.966043]\n",
      "[Epoch 1/200] [Batch 125/938] [D loss: 0.532687] [G loss: 14.027665]\n",
      "[Epoch 1/200] [Batch 130/938] [D loss: 0.371029] [G loss: 14.010626]\n",
      "[Epoch 1/200] [Batch 135/938] [D loss: 0.738353] [G loss: 13.963656]\n",
      "[Epoch 1/200] [Batch 140/938] [D loss: 0.346387] [G loss: 13.919356]\n",
      "[Epoch 1/200] [Batch 145/938] [D loss: 0.546366] [G loss: 13.906158]\n",
      "[Epoch 1/200] [Batch 150/938] [D loss: 0.397967] [G loss: 13.983054]\n",
      "[Epoch 1/200] [Batch 155/938] [D loss: 0.420472] [G loss: 13.970949]\n",
      "[Epoch 1/200] [Batch 160/938] [D loss: 0.466753] [G loss: 13.899057]\n",
      "[Epoch 1/200] [Batch 165/938] [D loss: 0.514542] [G loss: 13.955637]\n",
      "[Epoch 1/200] [Batch 170/938] [D loss: 0.533710] [G loss: 13.880638]\n",
      "[Epoch 1/200] [Batch 175/938] [D loss: 0.308240] [G loss: 13.946947]\n",
      "[Epoch 1/200] [Batch 180/938] [D loss: 0.349656] [G loss: 13.916174]\n",
      "[Epoch 1/200] [Batch 185/938] [D loss: 0.504576] [G loss: 13.859349]\n",
      "[Epoch 1/200] [Batch 190/938] [D loss: 0.477493] [G loss: 13.822334]\n",
      "[Epoch 1/200] [Batch 195/938] [D loss: 0.605554] [G loss: 13.862410]\n",
      "[Epoch 1/200] [Batch 200/938] [D loss: 0.341196] [G loss: 13.874521]\n",
      "[Epoch 1/200] [Batch 205/938] [D loss: 0.482152] [G loss: 13.737347]\n",
      "[Epoch 1/200] [Batch 210/938] [D loss: 0.489345] [G loss: 13.798317]\n",
      "[Epoch 1/200] [Batch 215/938] [D loss: 0.506773] [G loss: 13.679424]\n",
      "[Epoch 1/200] [Batch 220/938] [D loss: 0.298231] [G loss: 13.760201]\n",
      "[Epoch 1/200] [Batch 225/938] [D loss: 0.499254] [G loss: 13.693089]\n",
      "[Epoch 1/200] [Batch 230/938] [D loss: 0.222297] [G loss: 13.815108]\n",
      "[Epoch 1/200] [Batch 235/938] [D loss: 0.395267] [G loss: 13.658901]\n",
      "[Epoch 1/200] [Batch 240/938] [D loss: 0.259150] [G loss: 13.643912]\n",
      "[Epoch 1/200] [Batch 245/938] [D loss: 0.468534] [G loss: 13.666836]\n",
      "[Epoch 1/200] [Batch 250/938] [D loss: 0.394093] [G loss: 13.613962]\n",
      "[Epoch 1/200] [Batch 255/938] [D loss: 0.519047] [G loss: 13.614751]\n",
      "[Epoch 1/200] [Batch 260/938] [D loss: 0.439989] [G loss: 13.490744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 265/938] [D loss: 0.325077] [G loss: 13.498137]\n",
      "[Epoch 1/200] [Batch 270/938] [D loss: 0.168543] [G loss: 13.522017]\n",
      "[Epoch 1/200] [Batch 275/938] [D loss: 0.377774] [G loss: 13.482162]\n",
      "[Epoch 1/200] [Batch 280/938] [D loss: 0.283166] [G loss: 13.452322]\n",
      "[Epoch 1/200] [Batch 285/938] [D loss: 0.646639] [G loss: 13.294157]\n",
      "[Epoch 1/200] [Batch 290/938] [D loss: 0.439073] [G loss: 13.395706]\n",
      "[Epoch 1/200] [Batch 295/938] [D loss: 0.310261] [G loss: 13.367146]\n",
      "[Epoch 1/200] [Batch 300/938] [D loss: 0.474146] [G loss: 13.289360]\n",
      "[Epoch 1/200] [Batch 305/938] [D loss: 0.291006] [G loss: 13.304443]\n",
      "[Epoch 1/200] [Batch 310/938] [D loss: 0.367512] [G loss: 13.274711]\n",
      "[Epoch 1/200] [Batch 315/938] [D loss: 0.218348] [G loss: 13.291154]\n",
      "[Epoch 1/200] [Batch 320/938] [D loss: 0.368296] [G loss: 13.245365]\n",
      "[Epoch 1/200] [Batch 325/938] [D loss: 0.305426] [G loss: 13.219190]\n",
      "[Epoch 1/200] [Batch 330/938] [D loss: 0.420334] [G loss: 13.151430]\n",
      "[Epoch 1/200] [Batch 335/938] [D loss: 0.399452] [G loss: 13.136097]\n",
      "[Epoch 1/200] [Batch 340/938] [D loss: 0.398458] [G loss: 13.056696]\n",
      "[Epoch 1/200] [Batch 345/938] [D loss: 0.527018] [G loss: 13.016491]\n",
      "[Epoch 1/200] [Batch 350/938] [D loss: 0.484577] [G loss: 13.001526]\n",
      "[Epoch 1/200] [Batch 355/938] [D loss: 0.369273] [G loss: 13.005634]\n",
      "[Epoch 1/200] [Batch 360/938] [D loss: 0.495815] [G loss: 12.895388]\n",
      "[Epoch 1/200] [Batch 365/938] [D loss: 0.327267] [G loss: 12.931028]\n",
      "[Epoch 1/200] [Batch 370/938] [D loss: 0.286909] [G loss: 12.892920]\n",
      "[Epoch 1/200] [Batch 375/938] [D loss: 0.357550] [G loss: 12.885895]\n",
      "[Epoch 1/200] [Batch 380/938] [D loss: 0.369184] [G loss: 12.849215]\n",
      "[Epoch 1/200] [Batch 385/938] [D loss: 0.336315] [G loss: 12.844360]\n",
      "[Epoch 1/200] [Batch 390/938] [D loss: 0.342156] [G loss: 12.732882]\n",
      "[Epoch 1/200] [Batch 395/938] [D loss: 0.372769] [G loss: 12.759155]\n",
      "[Epoch 1/200] [Batch 400/938] [D loss: 0.329438] [G loss: 12.711281]\n",
      "[Epoch 1/200] [Batch 405/938] [D loss: 0.367648] [G loss: 12.682346]\n",
      "[Epoch 1/200] [Batch 410/938] [D loss: 0.256783] [G loss: 12.653806]\n",
      "[Epoch 1/200] [Batch 415/938] [D loss: 0.339515] [G loss: 12.613476]\n",
      "[Epoch 1/200] [Batch 420/938] [D loss: 0.284601] [G loss: 12.589214]\n",
      "[Epoch 1/200] [Batch 425/938] [D loss: 0.318741] [G loss: 12.557766]\n",
      "[Epoch 1/200] [Batch 430/938] [D loss: 0.260031] [G loss: 12.548559]\n",
      "[Epoch 1/200] [Batch 435/938] [D loss: 0.357264] [G loss: 12.522881]\n",
      "[Epoch 1/200] [Batch 440/938] [D loss: 0.364992] [G loss: 12.463772]\n",
      "[Epoch 1/200] [Batch 445/938] [D loss: 0.401408] [G loss: 12.535622]\n",
      "[Epoch 1/200] [Batch 450/938] [D loss: 0.288639] [G loss: 12.499580]\n",
      "[Epoch 1/200] [Batch 455/938] [D loss: 0.232996] [G loss: 12.462768]\n",
      "[Epoch 1/200] [Batch 460/938] [D loss: 0.347825] [G loss: 12.418650]\n",
      "[Epoch 1/200] [Batch 465/938] [D loss: 0.302963] [G loss: 12.380400]\n",
      "[Epoch 1/200] [Batch 470/938] [D loss: 0.341030] [G loss: 12.383944]\n",
      "[Epoch 1/200] [Batch 475/938] [D loss: 0.463961] [G loss: 12.389155]\n",
      "[Epoch 1/200] [Batch 480/938] [D loss: 0.379597] [G loss: 12.370107]\n",
      "[Epoch 1/200] [Batch 485/938] [D loss: 0.224530] [G loss: 12.328995]\n",
      "[Epoch 1/200] [Batch 490/938] [D loss: 0.293107] [G loss: 12.322512]\n",
      "[Epoch 1/200] [Batch 495/938] [D loss: 0.183321] [G loss: 12.329794]\n",
      "[Epoch 1/200] [Batch 500/938] [D loss: 0.442762] [G loss: 12.275198]\n",
      "[Epoch 1/200] [Batch 505/938] [D loss: 0.361400] [G loss: 12.244785]\n",
      "[Epoch 1/200] [Batch 510/938] [D loss: 0.163771] [G loss: 12.257020]\n",
      "[Epoch 1/200] [Batch 515/938] [D loss: 0.280944] [G loss: 12.295315]\n",
      "[Epoch 1/200] [Batch 520/938] [D loss: 0.242986] [G loss: 12.259028]\n",
      "[Epoch 1/200] [Batch 525/938] [D loss: 0.286484] [G loss: 12.242624]\n",
      "[Epoch 1/200] [Batch 530/938] [D loss: 0.354623] [G loss: 12.203038]\n",
      "[Epoch 1/200] [Batch 535/938] [D loss: 0.276177] [G loss: 12.147269]\n",
      "[Epoch 1/200] [Batch 540/938] [D loss: 0.327919] [G loss: 12.168364]\n",
      "[Epoch 1/200] [Batch 545/938] [D loss: 0.325518] [G loss: 12.134790]\n",
      "[Epoch 1/200] [Batch 550/938] [D loss: 0.138940] [G loss: 12.139208]\n",
      "[Epoch 1/200] [Batch 555/938] [D loss: 0.217327] [G loss: 12.131731]\n",
      "[Epoch 1/200] [Batch 560/938] [D loss: 0.165618] [G loss: 12.147358]\n",
      "[Epoch 1/200] [Batch 565/938] [D loss: 0.134346] [G loss: 12.122644]\n",
      "[Epoch 1/200] [Batch 570/938] [D loss: 0.182613] [G loss: 12.147409]\n",
      "[Epoch 1/200] [Batch 575/938] [D loss: 0.232959] [G loss: 12.145540]\n",
      "[Epoch 1/200] [Batch 580/938] [D loss: 0.284393] [G loss: 12.173750]\n",
      "[Epoch 1/200] [Batch 585/938] [D loss: 0.218540] [G loss: 12.132230]\n",
      "[Epoch 1/200] [Batch 590/938] [D loss: 0.081136] [G loss: 12.115203]\n",
      "[Epoch 1/200] [Batch 595/938] [D loss: 0.132240] [G loss: 12.100893]\n",
      "[Epoch 1/200] [Batch 600/938] [D loss: 0.218663] [G loss: 12.077688]\n",
      "[Epoch 1/200] [Batch 605/938] [D loss: 0.301816] [G loss: 12.139149]\n",
      "[Epoch 1/200] [Batch 610/938] [D loss: 0.042106] [G loss: 12.139507]\n",
      "[Epoch 1/200] [Batch 615/938] [D loss: 0.242450] [G loss: 12.158626]\n",
      "[Epoch 1/200] [Batch 620/938] [D loss: 0.126453] [G loss: 12.185683]\n",
      "[Epoch 1/200] [Batch 625/938] [D loss: 0.085509] [G loss: 12.148414]\n",
      "[Epoch 1/200] [Batch 630/938] [D loss: 0.112561] [G loss: 12.142356]\n",
      "[Epoch 1/200] [Batch 635/938] [D loss: 0.147683] [G loss: 12.133623]\n",
      "[Epoch 1/200] [Batch 640/938] [D loss: 0.063757] [G loss: 12.178469]\n",
      "[Epoch 1/200] [Batch 645/938] [D loss: 0.067109] [G loss: 12.156044]\n",
      "[Epoch 1/200] [Batch 650/938] [D loss: 0.077998] [G loss: 12.173279]\n",
      "[Epoch 1/200] [Batch 655/938] [D loss: 0.207810] [G loss: 12.230627]\n",
      "[Epoch 1/200] [Batch 660/938] [D loss: 0.233766] [G loss: 12.214657]\n",
      "[Epoch 1/200] [Batch 665/938] [D loss: 0.148219] [G loss: 12.184961]\n",
      "[Epoch 1/200] [Batch 670/938] [D loss: 0.073710] [G loss: 12.231864]\n",
      "[Epoch 1/200] [Batch 675/938] [D loss: 0.120909] [G loss: 12.232535]\n",
      "[Epoch 1/200] [Batch 680/938] [D loss: 0.137866] [G loss: 12.274777]\n",
      "[Epoch 1/200] [Batch 685/938] [D loss: 0.003074] [G loss: 12.223738]\n",
      "[Epoch 1/200] [Batch 690/938] [D loss: 0.061461] [G loss: 12.212539]\n",
      "[Epoch 1/200] [Batch 695/938] [D loss: 0.178954] [G loss: 12.261564]\n",
      "[Epoch 1/200] [Batch 700/938] [D loss: 0.097940] [G loss: 12.217981]\n",
      "[Epoch 1/200] [Batch 705/938] [D loss: 0.095926] [G loss: 12.240847]\n",
      "[Epoch 1/200] [Batch 710/938] [D loss: 0.085635] [G loss: 12.288757]\n",
      "[Epoch 1/200] [Batch 715/938] [D loss: 0.218575] [G loss: 12.351053]\n",
      "[Epoch 1/200] [Batch 720/938] [D loss: 0.163008] [G loss: 12.332792]\n",
      "[Epoch 1/200] [Batch 725/938] [D loss: 0.160681] [G loss: 12.350386]\n",
      "[Epoch 1/200] [Batch 730/938] [D loss: 0.132470] [G loss: 12.340012]\n",
      "[Epoch 1/200] [Batch 735/938] [D loss: 0.132580] [G loss: 12.341854]\n",
      "[Epoch 1/200] [Batch 740/938] [D loss: 0.169312] [G loss: 12.396099]\n",
      "[Epoch 1/200] [Batch 745/938] [D loss: 0.147078] [G loss: 12.395086]\n",
      "[Epoch 1/200] [Batch 750/938] [D loss: 0.109272] [G loss: 12.416950]\n",
      "[Epoch 1/200] [Batch 755/938] [D loss: 0.175566] [G loss: 12.417465]\n",
      "[Epoch 1/200] [Batch 760/938] [D loss: 0.198137] [G loss: 12.441892]\n",
      "[Epoch 1/200] [Batch 765/938] [D loss: 0.225727] [G loss: 12.453146]\n",
      "[Epoch 1/200] [Batch 770/938] [D loss: 0.242666] [G loss: 12.444168]\n",
      "[Epoch 1/200] [Batch 775/938] [D loss: 0.155035] [G loss: 12.430542]\n",
      "[Epoch 1/200] [Batch 780/938] [D loss: 0.047802] [G loss: 12.456285]\n",
      "[Epoch 1/200] [Batch 785/938] [D loss: 0.119144] [G loss: 12.452509]\n",
      "[Epoch 1/200] [Batch 790/938] [D loss: 0.261754] [G loss: 12.393446]\n",
      "[Epoch 1/200] [Batch 795/938] [D loss: 0.198401] [G loss: 12.335882]\n",
      "[Epoch 1/200] [Batch 800/938] [D loss: 0.088887] [G loss: 12.373525]\n",
      "[Epoch 1/200] [Batch 805/938] [D loss: 0.179676] [G loss: 12.400661]\n",
      "[Epoch 1/200] [Batch 810/938] [D loss: 0.229821] [G loss: 12.391010]\n",
      "[Epoch 1/200] [Batch 815/938] [D loss: 0.180360] [G loss: 12.418274]\n",
      "[Epoch 1/200] [Batch 820/938] [D loss: 0.162859] [G loss: 12.474721]\n",
      "[Epoch 1/200] [Batch 825/938] [D loss: 0.182644] [G loss: 12.510201]\n",
      "[Epoch 1/200] [Batch 830/938] [D loss: 0.146892] [G loss: 12.462538]\n",
      "[Epoch 1/200] [Batch 835/938] [D loss: 0.254841] [G loss: 12.461670]\n",
      "[Epoch 1/200] [Batch 840/938] [D loss: 0.195784] [G loss: 12.484617]\n",
      "[Epoch 1/200] [Batch 845/938] [D loss: 0.196341] [G loss: 12.483664]\n",
      "[Epoch 1/200] [Batch 850/938] [D loss: 0.247385] [G loss: 12.533428]\n",
      "[Epoch 1/200] [Batch 855/938] [D loss: 0.192024] [G loss: 12.540098]\n",
      "[Epoch 1/200] [Batch 860/938] [D loss: 0.164107] [G loss: 12.561442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 865/938] [D loss: 0.230275] [G loss: 12.540371]\n",
      "[Epoch 1/200] [Batch 870/938] [D loss: 0.236594] [G loss: 12.528528]\n",
      "[Epoch 1/200] [Batch 875/938] [D loss: 0.186902] [G loss: 12.472450]\n",
      "[Epoch 1/200] [Batch 880/938] [D loss: 0.250137] [G loss: 12.547741]\n",
      "[Epoch 1/200] [Batch 885/938] [D loss: 0.200026] [G loss: 12.562500]\n",
      "[Epoch 1/200] [Batch 890/938] [D loss: 0.159545] [G loss: 12.559885]\n",
      "[Epoch 1/200] [Batch 895/938] [D loss: 0.231613] [G loss: 12.627895]\n",
      "[Epoch 1/200] [Batch 900/938] [D loss: 0.146267] [G loss: 12.601877]\n",
      "[Epoch 1/200] [Batch 905/938] [D loss: 0.126176] [G loss: 12.658211]\n",
      "[Epoch 1/200] [Batch 910/938] [D loss: 0.145391] [G loss: 12.638365]\n",
      "[Epoch 1/200] [Batch 915/938] [D loss: 0.146534] [G loss: 12.671419]\n",
      "[Epoch 1/200] [Batch 920/938] [D loss: 0.213681] [G loss: 12.618069]\n",
      "[Epoch 1/200] [Batch 925/938] [D loss: 0.164080] [G loss: 12.741311]\n",
      "[Epoch 1/200] [Batch 930/938] [D loss: 0.135478] [G loss: 12.718567]\n",
      "[Epoch 1/200] [Batch 935/938] [D loss: 0.154056] [G loss: 12.649529]\n",
      "[Epoch 2/200] [Batch 0/938] [D loss: 0.146398] [G loss: 12.697279]\n",
      "[Epoch 2/200] [Batch 5/938] [D loss: 0.158204] [G loss: 12.704388]\n",
      "[Epoch 2/200] [Batch 10/938] [D loss: 0.150608] [G loss: 12.669532]\n",
      "[Epoch 2/200] [Batch 15/938] [D loss: 0.071498] [G loss: 12.685757]\n",
      "[Epoch 2/200] [Batch 20/938] [D loss: 0.062790] [G loss: 12.646490]\n",
      "[Epoch 2/200] [Batch 25/938] [D loss: 0.068792] [G loss: 12.634998]\n",
      "[Epoch 2/200] [Batch 30/938] [D loss: 0.128167] [G loss: 12.628242]\n",
      "[Epoch 2/200] [Batch 35/938] [D loss: 0.036891] [G loss: 12.635433]\n",
      "[Epoch 2/200] [Batch 40/938] [D loss: 0.209311] [G loss: 12.581095]\n",
      "[Epoch 2/200] [Batch 45/938] [D loss: 0.126453] [G loss: 12.689927]\n",
      "[Epoch 2/200] [Batch 50/938] [D loss: 0.062676] [G loss: 12.662028]\n",
      "[Epoch 2/200] [Batch 55/938] [D loss: 0.143574] [G loss: 12.662439]\n",
      "[Epoch 2/200] [Batch 60/938] [D loss: 0.068340] [G loss: 12.606258]\n",
      "[Epoch 2/200] [Batch 65/938] [D loss: 0.099556] [G loss: 12.608460]\n",
      "[Epoch 2/200] [Batch 70/938] [D loss: 0.116825] [G loss: 12.521294]\n",
      "[Epoch 2/200] [Batch 75/938] [D loss: 0.106945] [G loss: 12.504463]\n",
      "[Epoch 2/200] [Batch 80/938] [D loss: 0.079341] [G loss: 12.439676]\n",
      "[Epoch 2/200] [Batch 85/938] [D loss: 0.140156] [G loss: 12.456550]\n",
      "[Epoch 2/200] [Batch 90/938] [D loss: 0.078785] [G loss: 12.466429]\n",
      "[Epoch 2/200] [Batch 95/938] [D loss: 0.011016] [G loss: 12.482109]\n",
      "[Epoch 2/200] [Batch 100/938] [D loss: 0.015394] [G loss: 12.271296]\n",
      "[Epoch 2/200] [Batch 105/938] [D loss: 0.079318] [G loss: 12.233740]\n",
      "[Epoch 2/200] [Batch 110/938] [D loss: 0.039248] [G loss: 12.144829]\n",
      "[Epoch 2/200] [Batch 115/938] [D loss: -0.015016] [G loss: 12.136890]\n",
      "[Epoch 2/200] [Batch 120/938] [D loss: 0.025710] [G loss: 11.922275]\n",
      "[Epoch 2/200] [Batch 125/938] [D loss: 0.018871] [G loss: 11.913048]\n",
      "[Epoch 2/200] [Batch 130/938] [D loss: -0.008801] [G loss: 11.897569]\n",
      "[Epoch 2/200] [Batch 135/938] [D loss: 0.083263] [G loss: 11.846858]\n",
      "[Epoch 2/200] [Batch 140/938] [D loss: 0.045125] [G loss: 11.820468]\n",
      "[Epoch 2/200] [Batch 145/938] [D loss: 0.069142] [G loss: 11.777512]\n",
      "[Epoch 2/200] [Batch 150/938] [D loss: 0.061093] [G loss: 11.785604]\n",
      "[Epoch 2/200] [Batch 155/938] [D loss: 0.047850] [G loss: 11.753614]\n",
      "[Epoch 2/200] [Batch 160/938] [D loss: 0.050586] [G loss: 11.633955]\n",
      "[Epoch 2/200] [Batch 165/938] [D loss: 0.072832] [G loss: 11.673903]\n",
      "[Epoch 2/200] [Batch 170/938] [D loss: 0.086369] [G loss: 11.589271]\n",
      "[Epoch 2/200] [Batch 175/938] [D loss: 0.110176] [G loss: 11.583397]\n",
      "[Epoch 2/200] [Batch 180/938] [D loss: 0.104917] [G loss: 11.573246]\n",
      "[Epoch 2/200] [Batch 185/938] [D loss: 0.116314] [G loss: 11.607966]\n",
      "[Epoch 2/200] [Batch 190/938] [D loss: 0.063557] [G loss: 11.540209]\n",
      "[Epoch 2/200] [Batch 195/938] [D loss: 0.144755] [G loss: 11.477350]\n",
      "[Epoch 2/200] [Batch 200/938] [D loss: 0.124944] [G loss: 11.465578]\n",
      "[Epoch 2/200] [Batch 205/938] [D loss: 0.041456] [G loss: 11.428940]\n",
      "[Epoch 2/200] [Batch 210/938] [D loss: 0.087933] [G loss: 11.377533]\n",
      "[Epoch 2/200] [Batch 215/938] [D loss: 0.133818] [G loss: 11.328739]\n",
      "[Epoch 2/200] [Batch 220/938] [D loss: 0.135436] [G loss: 11.261656]\n",
      "[Epoch 2/200] [Batch 225/938] [D loss: 0.118370] [G loss: 11.263201]\n",
      "[Epoch 2/200] [Batch 230/938] [D loss: 0.140974] [G loss: 11.209474]\n",
      "[Epoch 2/200] [Batch 235/938] [D loss: 0.190936] [G loss: 11.147963]\n",
      "[Epoch 2/200] [Batch 240/938] [D loss: 0.095440] [G loss: 11.109078]\n",
      "[Epoch 2/200] [Batch 245/938] [D loss: 0.089223] [G loss: 11.073497]\n",
      "[Epoch 2/200] [Batch 250/938] [D loss: 0.200363] [G loss: 11.015505]\n",
      "[Epoch 2/200] [Batch 255/938] [D loss: 0.153931] [G loss: 10.977850]\n",
      "[Epoch 2/200] [Batch 260/938] [D loss: 0.108284] [G loss: 10.933546]\n",
      "[Epoch 2/200] [Batch 265/938] [D loss: 0.147424] [G loss: 10.877569]\n",
      "[Epoch 2/200] [Batch 270/938] [D loss: 0.204611] [G loss: 10.891127]\n",
      "[Epoch 2/200] [Batch 275/938] [D loss: 0.087110] [G loss: 10.862024]\n",
      "[Epoch 2/200] [Batch 280/938] [D loss: 0.178613] [G loss: 10.869314]\n",
      "[Epoch 2/200] [Batch 285/938] [D loss: 0.212093] [G loss: 10.762352]\n",
      "[Epoch 2/200] [Batch 290/938] [D loss: 0.090812] [G loss: 10.758533]\n",
      "[Epoch 2/200] [Batch 295/938] [D loss: 0.157927] [G loss: 10.785736]\n",
      "[Epoch 2/200] [Batch 300/938] [D loss: 0.098189] [G loss: 10.780535]\n",
      "[Epoch 2/200] [Batch 305/938] [D loss: 0.134308] [G loss: 10.736174]\n",
      "[Epoch 2/200] [Batch 310/938] [D loss: 0.123643] [G loss: 10.748878]\n",
      "[Epoch 2/200] [Batch 315/938] [D loss: 0.175362] [G loss: 10.719341]\n",
      "[Epoch 2/200] [Batch 320/938] [D loss: 0.106179] [G loss: 10.681376]\n",
      "[Epoch 2/200] [Batch 325/938] [D loss: 0.126188] [G loss: 10.683570]\n",
      "[Epoch 2/200] [Batch 330/938] [D loss: 0.138377] [G loss: 10.641819]\n",
      "[Epoch 2/200] [Batch 335/938] [D loss: 0.194275] [G loss: 10.609207]\n",
      "[Epoch 2/200] [Batch 340/938] [D loss: 0.118165] [G loss: 10.564960]\n",
      "[Epoch 2/200] [Batch 345/938] [D loss: 0.052968] [G loss: 10.624670]\n",
      "[Epoch 2/200] [Batch 350/938] [D loss: 0.097215] [G loss: 10.681978]\n",
      "[Epoch 2/200] [Batch 355/938] [D loss: -0.006824] [G loss: 10.697608]\n",
      "[Epoch 2/200] [Batch 360/938] [D loss: 0.128691] [G loss: 10.668610]\n",
      "[Epoch 2/200] [Batch 365/938] [D loss: 0.027704] [G loss: 10.703841]\n",
      "[Epoch 2/200] [Batch 370/938] [D loss: 0.056019] [G loss: 10.770273]\n",
      "[Epoch 2/200] [Batch 375/938] [D loss: 0.054088] [G loss: 10.760891]\n",
      "[Epoch 2/200] [Batch 380/938] [D loss: 0.041799] [G loss: 10.732891]\n",
      "[Epoch 2/200] [Batch 385/938] [D loss: 0.141791] [G loss: 10.726801]\n",
      "[Epoch 2/200] [Batch 390/938] [D loss: 0.125708] [G loss: 10.737388]\n",
      "[Epoch 2/200] [Batch 395/938] [D loss: 0.070322] [G loss: 10.750994]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ea1212e57c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisdom_plotter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, lr, nepochs, clip_tresh, num_critic, sample_interval, save_interval, load_states, save_states, verbose, visdom_plotter)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# Generate a batch of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mfake_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;31m# Adversarial loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mdata_parallel\u001b[0;34m(module, inputs, device_ids, output_device, dim, module_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mused_device_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_device_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_device_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0m_start_new_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_active_limbo_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "WGAN.train(dataloader, visdom_plotter=VP, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
