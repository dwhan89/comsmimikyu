{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmikyu import visualization as covis\n",
    "from cosmikyu import gan, config\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import mlflow\n",
    "import torchsummary\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config.default_data_dir\n",
    "mnist_dir = os.path.join(data_dir, 'mnist')\n",
    "cuda = True\n",
    "shape = (1,32,32)\n",
    "latent_dim = 64\n",
    "sample_interval = 1000\n",
    "save_interval = 50000\n",
    "batch_size = 64\n",
    "nepochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        mnist_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.Resize(shape[-1]), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0ba28a967be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmlflow_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-04\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     )\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, nepochs, ncritics, sample_interval, save_interval, load_states, save_states, verbose, mlflow_run, lr, betas)\u001b[0m\n\u001b[1;32m    358\u001b[0m                       \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                       \u001b[0mmlflow_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                       lr=lr, betas=betas)\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, nepochs, ncritics, sample_interval, save_interval, load_states, save_states, verbose, mlflow_run, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# Generate a batch of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;31m# Adversarial loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mdata_parallel\u001b[0;34m(module, inputs, device_ids, output_device, dim, module_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mused_device_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_device_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_device_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "COSMOGAN = gan.COSMOGAN(\"mnist_cosmogan\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(COSMOGAN.identifier)          \n",
    "with mlflow.start_run(experiment_id=COSMOGAN.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    COSMOGAN.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=1,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "saving states\n",
      "saving states\n"
     ]
    }
   ],
   "source": [
    "DCGAN = gan.DCGAN(\"mnist_cosmogan\", shape, latent_dim, cuda=cuda, ngpu=4, nconv_layer_gen=2, nconv_layer_disc=2, nconv_fcgen=32, nconv_fcdis=32)\n",
    "mlflow.set_experiment(DCGAN.identifier)          \n",
    "with mlflow.start_run(experiment_id=DCGAN.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    DCGAN.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=1,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=False,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "[Epoch 0/2] [Batch 0/938] [D loss: 8.338694] [G loss: -0.034286]\n",
      "saving states\n",
      "[Epoch 0/2] [Batch 5/938] [D loss: 4.228947] [G loss: -0.042754]\n",
      "[Epoch 0/2] [Batch 10/938] [D loss: -5.872320] [G loss: -0.080434]\n",
      "[Epoch 0/2] [Batch 15/938] [D loss: -20.855030] [G loss: -0.205500]\n",
      "[Epoch 0/2] [Batch 20/938] [D loss: -33.967487] [G loss: -0.467806]\n",
      "[Epoch 0/2] [Batch 25/938] [D loss: -40.171349] [G loss: -0.804005]\n",
      "[Epoch 0/2] [Batch 30/938] [D loss: -40.587364] [G loss: -1.150115]\n",
      "[Epoch 0/2] [Batch 35/938] [D loss: -40.527969] [G loss: -1.461487]\n",
      "[Epoch 0/2] [Batch 40/938] [D loss: -40.401794] [G loss: -1.855785]\n",
      "[Epoch 0/2] [Batch 45/938] [D loss: -40.378300] [G loss: -2.148134]\n",
      "[Epoch 0/2] [Batch 50/938] [D loss: -40.284805] [G loss: -2.520683]\n",
      "[Epoch 0/2] [Batch 55/938] [D loss: -40.028637] [G loss: -3.047812]\n",
      "[Epoch 0/2] [Batch 60/938] [D loss: -38.714119] [G loss: -3.503300]\n",
      "[Epoch 0/2] [Batch 65/938] [D loss: -37.910328] [G loss: -4.069277]\n",
      "[Epoch 0/2] [Batch 70/938] [D loss: -37.648849] [G loss: -4.739200]\n",
      "[Epoch 0/2] [Batch 75/938] [D loss: -37.061741] [G loss: -5.076282]\n",
      "[Epoch 0/2] [Batch 80/938] [D loss: -36.824337] [G loss: -5.819731]\n",
      "[Epoch 0/2] [Batch 85/938] [D loss: -35.766335] [G loss: -6.519988]\n",
      "[Epoch 0/2] [Batch 90/938] [D loss: -35.752903] [G loss: -7.202643]\n",
      "[Epoch 0/2] [Batch 95/938] [D loss: -35.513973] [G loss: -7.904232]\n",
      "[Epoch 0/2] [Batch 100/938] [D loss: -33.304680] [G loss: -8.591360]\n",
      "[Epoch 0/2] [Batch 105/938] [D loss: -32.242382] [G loss: -9.875055]\n",
      "[Epoch 0/2] [Batch 110/938] [D loss: -31.910048] [G loss: -10.296494]\n",
      "[Epoch 0/2] [Batch 115/938] [D loss: -29.356503] [G loss: -12.148636]\n",
      "[Epoch 0/2] [Batch 120/938] [D loss: -28.035076] [G loss: -12.698895]\n",
      "[Epoch 0/2] [Batch 125/938] [D loss: -27.409222] [G loss: -13.712619]\n",
      "[Epoch 0/2] [Batch 130/938] [D loss: -24.848330] [G loss: -16.090828]\n",
      "[Epoch 0/2] [Batch 135/938] [D loss: -24.328352] [G loss: -15.801664]\n",
      "[Epoch 0/2] [Batch 140/938] [D loss: -22.568621] [G loss: -17.480202]\n",
      "[Epoch 0/2] [Batch 145/938] [D loss: -19.760496] [G loss: -19.025223]\n",
      "[Epoch 0/2] [Batch 150/938] [D loss: -17.417137] [G loss: -20.483814]\n",
      "[Epoch 0/2] [Batch 155/938] [D loss: -15.609505] [G loss: -21.571438]\n",
      "[Epoch 0/2] [Batch 160/938] [D loss: -14.957306] [G loss: -21.442455]\n",
      "[Epoch 0/2] [Batch 165/938] [D loss: -12.895464] [G loss: -22.278170]\n",
      "[Epoch 0/2] [Batch 170/938] [D loss: -13.316248] [G loss: -22.098095]\n",
      "[Epoch 0/2] [Batch 175/938] [D loss: -11.226737] [G loss: -22.183609]\n",
      "[Epoch 0/2] [Batch 180/938] [D loss: -10.327666] [G loss: -22.306385]\n",
      "[Epoch 0/2] [Batch 185/938] [D loss: -9.960020] [G loss: -21.625710]\n",
      "[Epoch 0/2] [Batch 190/938] [D loss: -6.689660] [G loss: -22.814354]\n",
      "[Epoch 0/2] [Batch 195/938] [D loss: -7.795908] [G loss: -21.929047]\n",
      "[Epoch 0/2] [Batch 200/938] [D loss: -7.178296] [G loss: -22.692795]\n",
      "[Epoch 0/2] [Batch 205/938] [D loss: -6.319777] [G loss: -23.164906]\n",
      "[Epoch 0/2] [Batch 210/938] [D loss: -6.001019] [G loss: -22.532600]\n",
      "[Epoch 0/2] [Batch 215/938] [D loss: -5.886445] [G loss: -22.094719]\n",
      "[Epoch 0/2] [Batch 220/938] [D loss: -5.359752] [G loss: -21.886631]\n",
      "[Epoch 0/2] [Batch 225/938] [D loss: -4.590196] [G loss: -21.895649]\n",
      "[Epoch 0/2] [Batch 230/938] [D loss: -2.605791] [G loss: -23.217205]\n",
      "[Epoch 0/2] [Batch 235/938] [D loss: -4.759184] [G loss: -21.041559]\n",
      "[Epoch 0/2] [Batch 240/938] [D loss: -3.538959] [G loss: -21.532726]\n",
      "[Epoch 0/2] [Batch 245/938] [D loss: -3.446065] [G loss: -20.849655]\n",
      "[Epoch 0/2] [Batch 250/938] [D loss: -2.892324] [G loss: -21.364138]\n",
      "[Epoch 0/2] [Batch 255/938] [D loss: -2.526625] [G loss: -20.860134]\n",
      "[Epoch 0/2] [Batch 260/938] [D loss: -2.930706] [G loss: -19.991760]\n",
      "[Epoch 0/2] [Batch 265/938] [D loss: -2.804740] [G loss: -19.961784]\n",
      "[Epoch 0/2] [Batch 270/938] [D loss: -2.389486] [G loss: -19.648443]\n",
      "[Epoch 0/2] [Batch 275/938] [D loss: -2.894202] [G loss: -19.844204]\n",
      "[Epoch 0/2] [Batch 280/938] [D loss: -2.616924] [G loss: -19.902477]\n",
      "[Epoch 0/2] [Batch 285/938] [D loss: -1.841976] [G loss: -20.406311]\n",
      "[Epoch 0/2] [Batch 290/938] [D loss: -1.730466] [G loss: -20.541855]\n",
      "[Epoch 0/2] [Batch 295/938] [D loss: -2.270609] [G loss: -19.312397]\n",
      "[Epoch 0/2] [Batch 300/938] [D loss: -2.030986] [G loss: -18.686295]\n",
      "[Epoch 0/2] [Batch 305/938] [D loss: -2.339816] [G loss: -18.290859]\n",
      "[Epoch 0/2] [Batch 310/938] [D loss: -1.703847] [G loss: -18.160919]\n",
      "[Epoch 0/2] [Batch 315/938] [D loss: -1.537574] [G loss: -17.746056]\n",
      "[Epoch 0/2] [Batch 320/938] [D loss: -1.912237] [G loss: -17.341221]\n",
      "[Epoch 0/2] [Batch 325/938] [D loss: -1.827331] [G loss: -17.739052]\n",
      "[Epoch 0/2] [Batch 330/938] [D loss: -1.964961] [G loss: -17.412518]\n",
      "[Epoch 0/2] [Batch 335/938] [D loss: -2.039624] [G loss: -17.772097]\n",
      "[Epoch 0/2] [Batch 340/938] [D loss: -1.845324] [G loss: -17.575214]\n",
      "[Epoch 0/2] [Batch 345/938] [D loss: -1.952794] [G loss: -17.738697]\n",
      "[Epoch 0/2] [Batch 350/938] [D loss: -1.996680] [G loss: -18.063885]\n",
      "[Epoch 0/2] [Batch 355/938] [D loss: -1.866315] [G loss: -17.212334]\n",
      "[Epoch 0/2] [Batch 360/938] [D loss: -2.182642] [G loss: -17.279190]\n",
      "[Epoch 0/2] [Batch 365/938] [D loss: -2.083092] [G loss: -16.953430]\n",
      "[Epoch 0/2] [Batch 370/938] [D loss: -1.660792] [G loss: -16.777285]\n",
      "[Epoch 0/2] [Batch 375/938] [D loss: -1.778948] [G loss: -16.714958]\n",
      "[Epoch 0/2] [Batch 380/938] [D loss: -2.168504] [G loss: -15.823299]\n",
      "[Epoch 0/2] [Batch 385/938] [D loss: -2.080781] [G loss: -14.716057]\n",
      "[Epoch 0/2] [Batch 390/938] [D loss: -2.440908] [G loss: -13.888050]\n",
      "[Epoch 0/2] [Batch 395/938] [D loss: -2.560229] [G loss: -13.183527]\n",
      "[Epoch 0/2] [Batch 400/938] [D loss: -2.408148] [G loss: -11.894108]\n",
      "[Epoch 0/2] [Batch 405/938] [D loss: -2.502193] [G loss: -12.226818]\n",
      "[Epoch 0/2] [Batch 410/938] [D loss: -2.740974] [G loss: -11.554929]\n",
      "[Epoch 0/2] [Batch 415/938] [D loss: -2.569653] [G loss: -11.457790]\n",
      "[Epoch 0/2] [Batch 420/938] [D loss: -2.355341] [G loss: -11.310226]\n",
      "[Epoch 0/2] [Batch 425/938] [D loss: -2.827200] [G loss: -10.731745]\n",
      "[Epoch 0/2] [Batch 430/938] [D loss: -3.081847] [G loss: -10.170351]\n",
      "[Epoch 0/2] [Batch 435/938] [D loss: -3.375508] [G loss: -9.252472]\n",
      "[Epoch 0/2] [Batch 440/938] [D loss: -3.978550] [G loss: -8.838686]\n",
      "[Epoch 0/2] [Batch 445/938] [D loss: -3.093725] [G loss: -8.079851]\n",
      "[Epoch 0/2] [Batch 450/938] [D loss: -3.221455] [G loss: -7.447429]\n",
      "[Epoch 0/2] [Batch 455/938] [D loss: -3.116718] [G loss: -7.506154]\n",
      "[Epoch 0/2] [Batch 460/938] [D loss: -2.987880] [G loss: -6.959658]\n",
      "[Epoch 0/2] [Batch 465/938] [D loss: -2.999018] [G loss: -6.119071]\n",
      "[Epoch 0/2] [Batch 470/938] [D loss: -2.837936] [G loss: -5.599665]\n",
      "[Epoch 0/2] [Batch 475/938] [D loss: -3.513690] [G loss: -4.948877]\n",
      "[Epoch 0/2] [Batch 480/938] [D loss: -3.296412] [G loss: -5.479145]\n",
      "[Epoch 0/2] [Batch 485/938] [D loss: -3.233527] [G loss: -5.881733]\n",
      "[Epoch 0/2] [Batch 490/938] [D loss: -2.960421] [G loss: -5.110722]\n",
      "[Epoch 0/2] [Batch 495/938] [D loss: -2.802124] [G loss: -5.647234]\n",
      "[Epoch 0/2] [Batch 500/938] [D loss: -3.028879] [G loss: -6.456769]\n",
      "[Epoch 0/2] [Batch 505/938] [D loss: -2.664004] [G loss: -7.227755]\n",
      "[Epoch 0/2] [Batch 510/938] [D loss: -2.957281] [G loss: -6.785128]\n",
      "[Epoch 0/2] [Batch 515/938] [D loss: -2.097003] [G loss: -7.901213]\n",
      "[Epoch 0/2] [Batch 520/938] [D loss: -2.047248] [G loss: -7.659676]\n",
      "[Epoch 0/2] [Batch 525/938] [D loss: -2.496207] [G loss: -7.347693]\n",
      "[Epoch 0/2] [Batch 530/938] [D loss: -2.734726] [G loss: -9.080148]\n",
      "[Epoch 0/2] [Batch 535/938] [D loss: -2.054167] [G loss: -10.255278]\n",
      "[Epoch 0/2] [Batch 540/938] [D loss: -1.953777] [G loss: -11.015913]\n",
      "[Epoch 0/2] [Batch 545/938] [D loss: -1.872422] [G loss: -10.875689]\n",
      "[Epoch 0/2] [Batch 550/938] [D loss: -1.795615] [G loss: -11.424109]\n",
      "[Epoch 0/2] [Batch 555/938] [D loss: -2.191548] [G loss: -11.189116]\n",
      "[Epoch 0/2] [Batch 560/938] [D loss: -2.188637] [G loss: -10.079863]\n",
      "[Epoch 0/2] [Batch 565/938] [D loss: -1.944234] [G loss: -10.707929]\n",
      "[Epoch 0/2] [Batch 570/938] [D loss: -2.544803] [G loss: -10.114130]\n",
      "[Epoch 0/2] [Batch 575/938] [D loss: -1.994725] [G loss: -10.082064]\n",
      "[Epoch 0/2] [Batch 580/938] [D loss: -2.617417] [G loss: -9.826572]\n",
      "[Epoch 0/2] [Batch 585/938] [D loss: -2.713253] [G loss: -8.856424]\n",
      "[Epoch 0/2] [Batch 590/938] [D loss: -2.237371] [G loss: -7.794139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 595/938] [D loss: -2.071856] [G loss: -8.411453]\n",
      "[Epoch 0/2] [Batch 600/938] [D loss: -2.789547] [G loss: -8.496975]\n",
      "[Epoch 0/2] [Batch 605/938] [D loss: -2.851047] [G loss: -7.051051]\n",
      "[Epoch 0/2] [Batch 610/938] [D loss: -3.361418] [G loss: -5.348888]\n",
      "[Epoch 0/2] [Batch 615/938] [D loss: -3.393899] [G loss: -4.635007]\n",
      "[Epoch 0/2] [Batch 620/938] [D loss: -4.211488] [G loss: -3.774219]\n",
      "[Epoch 0/2] [Batch 625/938] [D loss: -3.995700] [G loss: -3.650753]\n",
      "[Epoch 0/2] [Batch 630/938] [D loss: -4.427218] [G loss: -3.384097]\n",
      "[Epoch 0/2] [Batch 635/938] [D loss: -4.509789] [G loss: -3.663091]\n",
      "[Epoch 0/2] [Batch 640/938] [D loss: -4.757484] [G loss: -4.708852]\n",
      "[Epoch 0/2] [Batch 645/938] [D loss: -4.678022] [G loss: -3.275721]\n",
      "[Epoch 0/2] [Batch 650/938] [D loss: -5.438917] [G loss: -1.587640]\n",
      "[Epoch 0/2] [Batch 655/938] [D loss: -5.786448] [G loss: -0.101482]\n",
      "[Epoch 0/2] [Batch 660/938] [D loss: -5.072834] [G loss: -1.108147]\n",
      "[Epoch 0/2] [Batch 665/938] [D loss: -6.825358] [G loss: -1.888292]\n",
      "[Epoch 0/2] [Batch 670/938] [D loss: -6.444347] [G loss: -0.790479]\n",
      "[Epoch 0/2] [Batch 675/938] [D loss: -6.695073] [G loss: 0.206401]\n",
      "[Epoch 0/2] [Batch 680/938] [D loss: -6.388170] [G loss: -0.436391]\n",
      "[Epoch 0/2] [Batch 685/938] [D loss: -6.587983] [G loss: 1.875804]\n",
      "[Epoch 0/2] [Batch 690/938] [D loss: -6.344804] [G loss: 0.389893]\n",
      "[Epoch 0/2] [Batch 695/938] [D loss: -6.103579] [G loss: 0.383865]\n",
      "[Epoch 0/2] [Batch 700/938] [D loss: -5.749359] [G loss: -0.498238]\n",
      "[Epoch 0/2] [Batch 705/938] [D loss: -5.215789] [G loss: 0.535849]\n",
      "[Epoch 0/2] [Batch 710/938] [D loss: -5.203118] [G loss: -2.204902]\n",
      "[Epoch 0/2] [Batch 715/938] [D loss: -4.520353] [G loss: -1.616009]\n",
      "[Epoch 0/2] [Batch 720/938] [D loss: -5.172393] [G loss: -0.248117]\n",
      "[Epoch 0/2] [Batch 725/938] [D loss: -4.541009] [G loss: -1.767151]\n",
      "[Epoch 0/2] [Batch 730/938] [D loss: -4.701463] [G loss: -0.241944]\n",
      "[Epoch 0/2] [Batch 735/938] [D loss: -4.144712] [G loss: -0.465271]\n",
      "[Epoch 0/2] [Batch 740/938] [D loss: -3.860660] [G loss: -1.036889]\n",
      "[Epoch 0/2] [Batch 745/938] [D loss: -4.035075] [G loss: -1.241728]\n",
      "[Epoch 0/2] [Batch 750/938] [D loss: -3.751750] [G loss: -1.633067]\n",
      "[Epoch 0/2] [Batch 755/938] [D loss: -4.698187] [G loss: -1.319301]\n",
      "[Epoch 0/2] [Batch 760/938] [D loss: -3.599304] [G loss: -2.131111]\n",
      "[Epoch 0/2] [Batch 765/938] [D loss: -4.079500] [G loss: -3.564310]\n",
      "[Epoch 0/2] [Batch 770/938] [D loss: -4.416444] [G loss: -3.356620]\n",
      "[Epoch 0/2] [Batch 775/938] [D loss: -3.955032] [G loss: -1.293344]\n",
      "[Epoch 0/2] [Batch 780/938] [D loss: -4.166749] [G loss: -2.383329]\n",
      "[Epoch 0/2] [Batch 785/938] [D loss: -4.514307] [G loss: -2.846625]\n",
      "[Epoch 0/2] [Batch 790/938] [D loss: -4.182762] [G loss: -1.792458]\n",
      "[Epoch 0/2] [Batch 795/938] [D loss: -4.618309] [G loss: -1.534476]\n",
      "[Epoch 0/2] [Batch 800/938] [D loss: -4.531162] [G loss: -2.906873]\n",
      "[Epoch 0/2] [Batch 805/938] [D loss: -4.639615] [G loss: -3.711765]\n",
      "[Epoch 0/2] [Batch 810/938] [D loss: -5.198573] [G loss: -2.075146]\n",
      "[Epoch 0/2] [Batch 815/938] [D loss: -4.338860] [G loss: -2.143463]\n",
      "[Epoch 0/2] [Batch 820/938] [D loss: -5.112293] [G loss: -4.696926]\n",
      "[Epoch 0/2] [Batch 825/938] [D loss: -4.666640] [G loss: -1.719136]\n",
      "[Epoch 0/2] [Batch 830/938] [D loss: -4.941491] [G loss: -2.226312]\n",
      "[Epoch 0/2] [Batch 835/938] [D loss: -5.689618] [G loss: -2.532398]\n",
      "[Epoch 0/2] [Batch 840/938] [D loss: -5.450089] [G loss: -2.467215]\n",
      "[Epoch 0/2] [Batch 845/938] [D loss: -6.350683] [G loss: -1.413208]\n",
      "[Epoch 0/2] [Batch 850/938] [D loss: -5.612807] [G loss: -3.227636]\n",
      "[Epoch 0/2] [Batch 855/938] [D loss: -5.811343] [G loss: -2.835763]\n",
      "[Epoch 0/2] [Batch 860/938] [D loss: -5.715771] [G loss: -2.457493]\n",
      "[Epoch 0/2] [Batch 865/938] [D loss: -5.852928] [G loss: -3.048442]\n",
      "[Epoch 0/2] [Batch 870/938] [D loss: -6.110232] [G loss: -1.329326]\n",
      "[Epoch 0/2] [Batch 875/938] [D loss: -6.300032] [G loss: -2.099556]\n",
      "[Epoch 0/2] [Batch 880/938] [D loss: -6.638946] [G loss: -1.253429]\n",
      "[Epoch 0/2] [Batch 885/938] [D loss: -6.739577] [G loss: -0.486704]\n",
      "[Epoch 0/2] [Batch 890/938] [D loss: -5.614257] [G loss: -2.144598]\n",
      "[Epoch 0/2] [Batch 895/938] [D loss: -5.798145] [G loss: -0.337252]\n",
      "[Epoch 0/2] [Batch 900/938] [D loss: -6.091087] [G loss: -0.074364]\n",
      "[Epoch 0/2] [Batch 905/938] [D loss: -6.302378] [G loss: -1.134620]\n",
      "[Epoch 0/2] [Batch 910/938] [D loss: -6.344786] [G loss: -0.416448]\n",
      "[Epoch 0/2] [Batch 915/938] [D loss: -6.826219] [G loss: 0.909511]\n",
      "[Epoch 0/2] [Batch 920/938] [D loss: -6.913748] [G loss: -1.326056]\n",
      "[Epoch 0/2] [Batch 925/938] [D loss: -6.561090] [G loss: 1.320065]\n",
      "[Epoch 0/2] [Batch 930/938] [D loss: -6.879379] [G loss: -0.087481]\n",
      "[Epoch 0/2] [Batch 935/938] [D loss: -6.446486] [G loss: 0.163925]\n",
      "[Epoch 1/2] [Batch 0/938] [D loss: -6.473720] [G loss: -1.365338]\n",
      "[Epoch 1/2] [Batch 5/938] [D loss: -6.274610] [G loss: -1.791014]\n",
      "[Epoch 1/2] [Batch 10/938] [D loss: -6.078816] [G loss: -1.640179]\n",
      "[Epoch 1/2] [Batch 15/938] [D loss: -5.895504] [G loss: -1.030275]\n",
      "[Epoch 1/2] [Batch 20/938] [D loss: -6.279131] [G loss: -0.957900]\n",
      "[Epoch 1/2] [Batch 25/938] [D loss: -5.948658] [G loss: -0.426707]\n",
      "[Epoch 1/2] [Batch 30/938] [D loss: -5.840714] [G loss: -1.157318]\n",
      "[Epoch 1/2] [Batch 35/938] [D loss: -5.670975] [G loss: -1.642864]\n",
      "[Epoch 1/2] [Batch 40/938] [D loss: -5.875427] [G loss: -1.822059]\n",
      "[Epoch 1/2] [Batch 45/938] [D loss: -5.950736] [G loss: -1.290356]\n",
      "[Epoch 1/2] [Batch 50/938] [D loss: -5.260320] [G loss: -2.265312]\n",
      "[Epoch 1/2] [Batch 55/938] [D loss: -5.719100] [G loss: -0.961764]\n",
      "[Epoch 1/2] [Batch 60/938] [D loss: -5.671422] [G loss: -1.612506]\n",
      "[Epoch 1/2] [Batch 65/938] [D loss: -5.512917] [G loss: -1.495101]\n",
      "[Epoch 1/2] [Batch 70/938] [D loss: -4.905881] [G loss: -1.046158]\n",
      "[Epoch 1/2] [Batch 75/938] [D loss: -4.401551] [G loss: -1.079491]\n",
      "[Epoch 1/2] [Batch 80/938] [D loss: -4.842525] [G loss: -1.241586]\n",
      "[Epoch 1/2] [Batch 85/938] [D loss: -4.996294] [G loss: -2.228697]\n",
      "[Epoch 1/2] [Batch 90/938] [D loss: -4.856845] [G loss: -1.222997]\n",
      "[Epoch 1/2] [Batch 95/938] [D loss: -4.967445] [G loss: -2.961858]\n",
      "[Epoch 1/2] [Batch 100/938] [D loss: -5.257007] [G loss: -1.093919]\n",
      "[Epoch 1/2] [Batch 105/938] [D loss: -5.445892] [G loss: -2.617728]\n",
      "[Epoch 1/2] [Batch 110/938] [D loss: -4.768134] [G loss: -4.115655]\n",
      "[Epoch 1/2] [Batch 115/938] [D loss: -5.502114] [G loss: -2.244662]\n",
      "[Epoch 1/2] [Batch 120/938] [D loss: -4.911240] [G loss: -2.128094]\n",
      "[Epoch 1/2] [Batch 125/938] [D loss: -5.924218] [G loss: -2.603533]\n",
      "[Epoch 1/2] [Batch 130/938] [D loss: -5.848382] [G loss: -1.948466]\n",
      "[Epoch 1/2] [Batch 135/938] [D loss: -5.536429] [G loss: -3.496452]\n",
      "[Epoch 1/2] [Batch 140/938] [D loss: -5.775795] [G loss: -1.953364]\n",
      "[Epoch 1/2] [Batch 145/938] [D loss: -5.757039] [G loss: -2.189678]\n",
      "[Epoch 1/2] [Batch 150/938] [D loss: -6.051434] [G loss: -3.086678]\n",
      "[Epoch 1/2] [Batch 155/938] [D loss: -5.718350] [G loss: -2.945686]\n",
      "[Epoch 1/2] [Batch 160/938] [D loss: -6.145065] [G loss: -2.405854]\n",
      "[Epoch 1/2] [Batch 165/938] [D loss: -6.216078] [G loss: -2.378306]\n",
      "[Epoch 1/2] [Batch 170/938] [D loss: -6.428545] [G loss: -1.185234]\n",
      "[Epoch 1/2] [Batch 175/938] [D loss: -6.308614] [G loss: -1.690479]\n",
      "[Epoch 1/2] [Batch 180/938] [D loss: -6.130778] [G loss: -1.046076]\n",
      "[Epoch 1/2] [Batch 185/938] [D loss: -6.210643] [G loss: -1.633115]\n",
      "[Epoch 1/2] [Batch 190/938] [D loss: -7.008743] [G loss: -2.055834]\n",
      "[Epoch 1/2] [Batch 195/938] [D loss: -6.671205] [G loss: -2.677014]\n",
      "[Epoch 1/2] [Batch 200/938] [D loss: -5.930390] [G loss: -0.980969]\n",
      "[Epoch 1/2] [Batch 205/938] [D loss: -6.718262] [G loss: -0.878927]\n",
      "[Epoch 1/2] [Batch 210/938] [D loss: -6.048558] [G loss: -1.625337]\n",
      "[Epoch 1/2] [Batch 215/938] [D loss: -6.634489] [G loss: -1.450295]\n",
      "[Epoch 1/2] [Batch 220/938] [D loss: -6.252270] [G loss: 0.116876]\n",
      "[Epoch 1/2] [Batch 225/938] [D loss: -6.726415] [G loss: 0.795174]\n",
      "[Epoch 1/2] [Batch 230/938] [D loss: -7.512703] [G loss: -1.176307]\n",
      "[Epoch 1/2] [Batch 235/938] [D loss: -6.838535] [G loss: -0.166460]\n",
      "[Epoch 1/2] [Batch 240/938] [D loss: -7.003109] [G loss: -0.448112]\n",
      "[Epoch 1/2] [Batch 245/938] [D loss: -7.528896] [G loss: 1.421265]\n",
      "[Epoch 1/2] [Batch 250/938] [D loss: -7.265149] [G loss: 1.049847]\n",
      "[Epoch 1/2] [Batch 255/938] [D loss: -8.346029] [G loss: 1.888138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 260/938] [D loss: -7.769081] [G loss: 2.431551]\n",
      "[Epoch 1/2] [Batch 265/938] [D loss: -7.737829] [G loss: 1.941904]\n",
      "[Epoch 1/2] [Batch 270/938] [D loss: -8.286416] [G loss: 0.872480]\n",
      "[Epoch 1/2] [Batch 275/938] [D loss: -8.277871] [G loss: 2.604989]\n",
      "[Epoch 1/2] [Batch 280/938] [D loss: -7.735622] [G loss: 1.397768]\n",
      "[Epoch 1/2] [Batch 285/938] [D loss: -7.826842] [G loss: 2.137001]\n",
      "[Epoch 1/2] [Batch 290/938] [D loss: -8.062252] [G loss: 2.631724]\n",
      "[Epoch 1/2] [Batch 295/938] [D loss: -8.121384] [G loss: 3.448383]\n",
      "[Epoch 1/2] [Batch 300/938] [D loss: -7.908410] [G loss: 2.361703]\n",
      "[Epoch 1/2] [Batch 305/938] [D loss: -7.580414] [G loss: 2.177536]\n",
      "[Epoch 1/2] [Batch 310/938] [D loss: -7.574720] [G loss: 2.219851]\n",
      "[Epoch 1/2] [Batch 315/938] [D loss: -8.639702] [G loss: 2.847414]\n",
      "[Epoch 1/2] [Batch 320/938] [D loss: -7.442295] [G loss: 1.425089]\n",
      "[Epoch 1/2] [Batch 325/938] [D loss: -7.513917] [G loss: 2.230259]\n",
      "[Epoch 1/2] [Batch 330/938] [D loss: -7.097714] [G loss: 3.058722]\n",
      "[Epoch 1/2] [Batch 335/938] [D loss: -6.937126] [G loss: 1.502080]\n",
      "[Epoch 1/2] [Batch 340/938] [D loss: -7.062911] [G loss: 2.414003]\n",
      "[Epoch 1/2] [Batch 345/938] [D loss: -6.742111] [G loss: 1.361063]\n",
      "[Epoch 1/2] [Batch 350/938] [D loss: -7.070194] [G loss: 2.043804]\n",
      "[Epoch 1/2] [Batch 355/938] [D loss: -6.395718] [G loss: 0.346513]\n",
      "[Epoch 1/2] [Batch 360/938] [D loss: -6.768584] [G loss: 0.537741]\n",
      "[Epoch 1/2] [Batch 365/938] [D loss: -7.230500] [G loss: 0.629008]\n",
      "[Epoch 1/2] [Batch 370/938] [D loss: -7.266190] [G loss: 1.016253]\n",
      "[Epoch 1/2] [Batch 375/938] [D loss: -6.423029] [G loss: 0.776599]\n",
      "[Epoch 1/2] [Batch 380/938] [D loss: -5.849438] [G loss: 0.351075]\n",
      "[Epoch 1/2] [Batch 385/938] [D loss: -6.268460] [G loss: 1.098255]\n",
      "[Epoch 1/2] [Batch 390/938] [D loss: -7.388983] [G loss: 0.550546]\n",
      "[Epoch 1/2] [Batch 395/938] [D loss: -5.856889] [G loss: 0.063063]\n",
      "[Epoch 1/2] [Batch 400/938] [D loss: -6.553790] [G loss: 2.275502]\n",
      "[Epoch 1/2] [Batch 405/938] [D loss: -6.886234] [G loss: 1.946911]\n",
      "[Epoch 1/2] [Batch 410/938] [D loss: -6.469579] [G loss: 1.773823]\n",
      "[Epoch 1/2] [Batch 415/938] [D loss: -5.825880] [G loss: 0.884835]\n",
      "[Epoch 1/2] [Batch 420/938] [D loss: -6.142368] [G loss: 0.518643]\n",
      "[Epoch 1/2] [Batch 425/938] [D loss: -6.601505] [G loss: 0.625613]\n",
      "[Epoch 1/2] [Batch 430/938] [D loss: -5.951575] [G loss: 1.128479]\n",
      "[Epoch 1/2] [Batch 435/938] [D loss: -6.564803] [G loss: 1.205590]\n",
      "[Epoch 1/2] [Batch 440/938] [D loss: -5.723730] [G loss: 1.728863]\n",
      "[Epoch 1/2] [Batch 445/938] [D loss: -6.371482] [G loss: 1.410799]\n",
      "[Epoch 1/2] [Batch 450/938] [D loss: -7.016449] [G loss: 1.748267]\n",
      "[Epoch 1/2] [Batch 455/938] [D loss: -6.531258] [G loss: 1.117271]\n",
      "[Epoch 1/2] [Batch 460/938] [D loss: -7.187558] [G loss: 3.242369]\n",
      "[Epoch 1/2] [Batch 465/938] [D loss: -6.585850] [G loss: 3.132654]\n",
      "[Epoch 1/2] [Batch 470/938] [D loss: -6.890323] [G loss: 2.838510]\n",
      "[Epoch 1/2] [Batch 475/938] [D loss: -7.181892] [G loss: 2.314723]\n",
      "[Epoch 1/2] [Batch 480/938] [D loss: -6.833644] [G loss: 3.016963]\n",
      "[Epoch 1/2] [Batch 485/938] [D loss: -6.815055] [G loss: 3.147958]\n",
      "[Epoch 1/2] [Batch 490/938] [D loss: -7.151147] [G loss: 3.485329]\n",
      "[Epoch 1/2] [Batch 495/938] [D loss: -6.632734] [G loss: 2.584672]\n",
      "[Epoch 1/2] [Batch 500/938] [D loss: -6.722710] [G loss: 2.081159]\n",
      "[Epoch 1/2] [Batch 505/938] [D loss: -6.740452] [G loss: 1.451847]\n",
      "[Epoch 1/2] [Batch 510/938] [D loss: -6.719914] [G loss: 1.482701]\n",
      "[Epoch 1/2] [Batch 515/938] [D loss: -6.762058] [G loss: 1.821401]\n",
      "[Epoch 1/2] [Batch 520/938] [D loss: -7.262864] [G loss: 2.350829]\n",
      "[Epoch 1/2] [Batch 525/938] [D loss: -6.848550] [G loss: 1.069358]\n",
      "[Epoch 1/2] [Batch 530/938] [D loss: -6.599458] [G loss: 2.524543]\n",
      "[Epoch 1/2] [Batch 535/938] [D loss: -6.689142] [G loss: 1.937934]\n",
      "[Epoch 1/2] [Batch 540/938] [D loss: -6.933022] [G loss: 1.316161]\n",
      "[Epoch 1/2] [Batch 545/938] [D loss: -6.502259] [G loss: 1.953490]\n",
      "[Epoch 1/2] [Batch 550/938] [D loss: -6.624879] [G loss: 1.160598]\n",
      "[Epoch 1/2] [Batch 555/938] [D loss: -7.363887] [G loss: 2.287171]\n",
      "[Epoch 1/2] [Batch 560/938] [D loss: -7.376893] [G loss: 2.884756]\n",
      "[Epoch 1/2] [Batch 565/938] [D loss: -6.725694] [G loss: 1.604723]\n",
      "[Epoch 1/2] [Batch 570/938] [D loss: -7.149812] [G loss: 1.213482]\n",
      "[Epoch 1/2] [Batch 575/938] [D loss: -7.395140] [G loss: -0.812314]\n",
      "[Epoch 1/2] [Batch 580/938] [D loss: -7.960702] [G loss: 1.427670]\n",
      "[Epoch 1/2] [Batch 585/938] [D loss: -7.462648] [G loss: 1.611014]\n",
      "[Epoch 1/2] [Batch 590/938] [D loss: -6.721190] [G loss: 0.061991]\n",
      "[Epoch 1/2] [Batch 595/938] [D loss: -6.493615] [G loss: 0.151565]\n",
      "[Epoch 1/2] [Batch 600/938] [D loss: -7.228000] [G loss: 1.417518]\n",
      "[Epoch 1/2] [Batch 605/938] [D loss: -6.688182] [G loss: 1.897537]\n",
      "[Epoch 1/2] [Batch 610/938] [D loss: -7.456656] [G loss: 1.745146]\n",
      "[Epoch 1/2] [Batch 615/938] [D loss: -7.242574] [G loss: 0.422931]\n",
      "[Epoch 1/2] [Batch 620/938] [D loss: -6.963799] [G loss: 0.316212]\n",
      "[Epoch 1/2] [Batch 625/938] [D loss: -6.955939] [G loss: 1.466016]\n",
      "[Epoch 1/2] [Batch 630/938] [D loss: -7.656867] [G loss: 0.641035]\n",
      "[Epoch 1/2] [Batch 635/938] [D loss: -7.046708] [G loss: 0.353221]\n",
      "[Epoch 1/2] [Batch 640/938] [D loss: -6.043639] [G loss: 1.547276]\n",
      "[Epoch 1/2] [Batch 645/938] [D loss: -6.940955] [G loss: 0.023016]\n",
      "[Epoch 1/2] [Batch 650/938] [D loss: -6.710904] [G loss: -0.155578]\n",
      "[Epoch 1/2] [Batch 655/938] [D loss: -7.292138] [G loss: 0.856733]\n",
      "[Epoch 1/2] [Batch 660/938] [D loss: -7.221932] [G loss: 0.029362]\n",
      "[Epoch 1/2] [Batch 665/938] [D loss: -6.867052] [G loss: -1.154269]\n",
      "[Epoch 1/2] [Batch 670/938] [D loss: -7.283349] [G loss: -0.588057]\n",
      "[Epoch 1/2] [Batch 675/938] [D loss: -6.340334] [G loss: -0.181335]\n",
      "[Epoch 1/2] [Batch 680/938] [D loss: -6.650313] [G loss: -0.748479]\n",
      "[Epoch 1/2] [Batch 685/938] [D loss: -6.480456] [G loss: -0.044027]\n",
      "[Epoch 1/2] [Batch 690/938] [D loss: -6.405941] [G loss: 0.438510]\n",
      "[Epoch 1/2] [Batch 695/938] [D loss: -6.962685] [G loss: 0.536785]\n",
      "[Epoch 1/2] [Batch 700/938] [D loss: -6.911115] [G loss: -0.680500]\n",
      "[Epoch 1/2] [Batch 705/938] [D loss: -6.696776] [G loss: 0.606293]\n",
      "[Epoch 1/2] [Batch 710/938] [D loss: -6.682258] [G loss: 0.501012]\n",
      "[Epoch 1/2] [Batch 715/938] [D loss: -6.078262] [G loss: -0.110263]\n",
      "[Epoch 1/2] [Batch 720/938] [D loss: -7.383561] [G loss: -0.807478]\n",
      "[Epoch 1/2] [Batch 725/938] [D loss: -7.189339] [G loss: -0.190122]\n",
      "[Epoch 1/2] [Batch 730/938] [D loss: -7.298747] [G loss: 0.726319]\n",
      "[Epoch 1/2] [Batch 735/938] [D loss: -7.439102] [G loss: 0.737941]\n",
      "[Epoch 1/2] [Batch 740/938] [D loss: -7.486451] [G loss: -0.836494]\n",
      "[Epoch 1/2] [Batch 745/938] [D loss: -7.471307] [G loss: 0.019287]\n",
      "[Epoch 1/2] [Batch 750/938] [D loss: -7.042436] [G loss: 0.763198]\n",
      "[Epoch 1/2] [Batch 755/938] [D loss: -7.895307] [G loss: 0.198115]\n",
      "[Epoch 1/2] [Batch 760/938] [D loss: -8.190918] [G loss: 0.636063]\n",
      "[Epoch 1/2] [Batch 765/938] [D loss: -7.526474] [G loss: 1.094278]\n",
      "[Epoch 1/2] [Batch 770/938] [D loss: -8.059800] [G loss: 0.433945]\n",
      "[Epoch 1/2] [Batch 775/938] [D loss: -8.568893] [G loss: 1.142701]\n",
      "[Epoch 1/2] [Batch 780/938] [D loss: -8.103965] [G loss: 1.721447]\n",
      "[Epoch 1/2] [Batch 785/938] [D loss: -7.276075] [G loss: 1.464725]\n",
      "[Epoch 1/2] [Batch 790/938] [D loss: -8.080319] [G loss: 1.572016]\n",
      "[Epoch 1/2] [Batch 795/938] [D loss: -7.737835] [G loss: 0.442892]\n",
      "[Epoch 1/2] [Batch 800/938] [D loss: -7.290009] [G loss: 1.645587]\n",
      "[Epoch 1/2] [Batch 805/938] [D loss: -7.267824] [G loss: 0.604532]\n",
      "[Epoch 1/2] [Batch 810/938] [D loss: -7.038824] [G loss: 0.172247]\n",
      "[Epoch 1/2] [Batch 815/938] [D loss: -6.241683] [G loss: 1.053211]\n",
      "[Epoch 1/2] [Batch 820/938] [D loss: -7.128381] [G loss: 2.320239]\n",
      "[Epoch 1/2] [Batch 825/938] [D loss: -6.709228] [G loss: 1.814316]\n",
      "[Epoch 1/2] [Batch 830/938] [D loss: -6.779689] [G loss: 1.046649]\n",
      "[Epoch 1/2] [Batch 835/938] [D loss: -6.909092] [G loss: 0.212865]\n",
      "[Epoch 1/2] [Batch 840/938] [D loss: -7.417290] [G loss: 1.145615]\n",
      "[Epoch 1/2] [Batch 845/938] [D loss: -7.656610] [G loss: 2.991806]\n",
      "[Epoch 1/2] [Batch 850/938] [D loss: -7.584050] [G loss: 1.966804]\n",
      "[Epoch 1/2] [Batch 855/938] [D loss: -6.935921] [G loss: 2.610863]\n",
      "[Epoch 1/2] [Batch 860/938] [D loss: -7.256659] [G loss: 2.427115]\n",
      "[Epoch 1/2] [Batch 865/938] [D loss: -6.283935] [G loss: 1.506878]\n",
      "[Epoch 1/2] [Batch 870/938] [D loss: -6.545705] [G loss: 1.587834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] [Batch 875/938] [D loss: -7.223490] [G loss: 1.878277]\n",
      "[Epoch 1/2] [Batch 880/938] [D loss: -6.724697] [G loss: 0.206166]\n",
      "[Epoch 1/2] [Batch 885/938] [D loss: -7.005715] [G loss: -0.040606]\n",
      "[Epoch 1/2] [Batch 890/938] [D loss: -6.943243] [G loss: 0.243583]\n",
      "[Epoch 1/2] [Batch 895/938] [D loss: -6.715596] [G loss: 0.986187]\n",
      "[Epoch 1/2] [Batch 900/938] [D loss: -6.676334] [G loss: 0.705724]\n",
      "[Epoch 1/2] [Batch 905/938] [D loss: -6.932789] [G loss: -0.405977]\n",
      "[Epoch 1/2] [Batch 910/938] [D loss: -7.614096] [G loss: 0.143837]\n",
      "[Epoch 1/2] [Batch 915/938] [D loss: -7.184932] [G loss: -0.453341]\n",
      "[Epoch 1/2] [Batch 920/938] [D loss: -6.908195] [G loss: -0.900278]\n",
      "[Epoch 1/2] [Batch 925/938] [D loss: -7.018968] [G loss: -0.819533]\n",
      "[Epoch 1/2] [Batch 930/938] [D loss: -6.879057] [G loss: -1.081206]\n",
      "[Epoch 1/2] [Batch 935/938] [D loss: -6.603237] [G loss: -0.498918]\n",
      "saving states\n"
     ]
    }
   ],
   "source": [
    "WGAN_GP = gan.WGAN_GP(\"mnist_wgan_gp\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(WGAN_GP.identifier)\n",
    "with mlflow.start_run(experiment_id=WGAN_GP.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    WGAN_GP.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=5,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999),\n",
    "        lambda_gp=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 0/938] [D loss: -0.153472] [G loss: 0.008971]\n",
      "saving states\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 5/938] [D loss: -3.337174] [G loss: -0.109996]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 10/938] [D loss: -11.381778] [G loss: -1.197862]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 15/938] [D loss: -17.959133] [G loss: -3.988242]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 20/938] [D loss: -20.941551] [G loss: -9.015030]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 25/938] [D loss: -16.763559] [G loss: -15.928257]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 30/938] [D loss: -11.602097] [G loss: -21.835014]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 35/938] [D loss: -7.243771] [G loss: -24.877367]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 40/938] [D loss: -5.482590] [G loss: -25.894108]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 45/938] [D loss: -4.161812] [G loss: -26.630390]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 50/938] [D loss: -3.595358] [G loss: -26.353476]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 55/938] [D loss: -2.554901] [G loss: -26.468969]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 60/938] [D loss: -2.800861] [G loss: -25.212341]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 65/938] [D loss: -2.685793] [G loss: -24.808342]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 70/938] [D loss: -1.893850] [G loss: -24.944801]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 75/938] [D loss: -2.068167] [G loss: -24.741451]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 80/938] [D loss: -1.501621] [G loss: -23.990265]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 85/938] [D loss: -1.294212] [G loss: -24.051445]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 90/938] [D loss: -1.314966] [G loss: -23.514004]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 95/938] [D loss: -1.308331] [G loss: -23.250635]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 100/938] [D loss: -1.420706] [G loss: -22.857712]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 105/938] [D loss: -1.523470] [G loss: -22.463097]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 110/938] [D loss: -1.493233] [G loss: -22.153099]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 115/938] [D loss: -1.490765] [G loss: -21.846312]\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "[Epoch 0/2] [Batch 120/938] [D loss: -1.579718] [G loss: -21.669949]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4e0b88b7a521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmlflow_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-04\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mclip_tresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     )\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, nepochs, ncritics, sample_interval, save_interval, load_states, save_states, verbose, mlflow_run, lr, clip_tresh)\u001b[0m\n\u001b[1;32m    179\u001b[0m                       \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                       \u001b[0mmlflow_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                       lr=lr, clip_tresh=clip_tresh)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, nepochs, ncritics, sample_interval, save_interval, load_states, save_states, verbose, mlflow_run, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mbatches_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mreal_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \"\"\"\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "WGAN = gan.WGAN(\"mnist_wgan\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(WGAN.identifier)\n",
    "with mlflow.start_run(experiment_id=WGAN.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    WGAN.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=5,\n",
    "        sample_interval=1000,\n",
    "        save_interval=10000,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        clip_tresh=0.01,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 1, 1, 2048]         133,120\n",
      "            Linear-2           [-1, 1, 1, 2048]         133,120\n",
      "           Reshape-3            [-1, 512, 2, 2]               0\n",
      "           Reshape-4            [-1, 512, 2, 2]               0\n",
      "       BatchNorm2d-5            [-1, 512, 2, 2]           1,024\n",
      "       BatchNorm2d-6            [-1, 512, 2, 2]           1,024\n",
      "         LeakyReLU-7            [-1, 512, 2, 2]               0\n",
      "         LeakyReLU-8            [-1, 512, 2, 2]               0\n",
      "   ConvTranspose2d-9            [-1, 256, 4, 4]       3,277,056\n",
      "  ConvTranspose2d-10            [-1, 256, 4, 4]       3,277,056\n",
      "      BatchNorm2d-11            [-1, 256, 4, 4]             512\n",
      "      BatchNorm2d-12            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-13            [-1, 256, 4, 4]               0\n",
      "        LeakyReLU-14            [-1, 256, 4, 4]               0\n",
      "  ConvTranspose2d-15            [-1, 128, 8, 8]         819,328\n",
      "  ConvTranspose2d-16            [-1, 128, 8, 8]         819,328\n",
      "      BatchNorm2d-17            [-1, 128, 8, 8]             256\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "        LeakyReLU-19            [-1, 128, 8, 8]               0\n",
      "        LeakyReLU-20            [-1, 128, 8, 8]               0\n",
      "  ConvTranspose2d-21           [-1, 64, 16, 16]         204,864\n",
      "  ConvTranspose2d-22           [-1, 64, 16, 16]         204,864\n",
      "      BatchNorm2d-23           [-1, 64, 16, 16]             128\n",
      "      BatchNorm2d-24           [-1, 64, 16, 16]             128\n",
      "        LeakyReLU-25           [-1, 64, 16, 16]               0\n",
      "        LeakyReLU-26           [-1, 64, 16, 16]               0\n",
      "  ConvTranspose2d-27            [-1, 1, 32, 32]           1,601\n",
      "  ConvTranspose2d-28            [-1, 1, 32, 32]           1,601\n",
      "             Tanh-29            [-1, 1, 32, 32]               0\n",
      "             Tanh-30            [-1, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 8,875,778\n",
      "Trainable params: 8,875,778\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.47\n",
      "Params size (MB): 33.86\n",
      "Estimated Total Size (MB): 35.33\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           1,664\n",
      "         LeakyReLU-2           [-1, 64, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]           1,664\n",
      "            Conv2d-4            [-1, 128, 8, 8]         204,928\n",
      "         LeakyReLU-5           [-1, 64, 16, 16]               0\n",
      "       BatchNorm2d-6            [-1, 128, 8, 8]             256\n",
      "            Conv2d-7            [-1, 128, 8, 8]         204,928\n",
      "         LeakyReLU-8            [-1, 128, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 4, 4]         819,456\n",
      "      BatchNorm2d-10            [-1, 128, 8, 8]             256\n",
      "      BatchNorm2d-11            [-1, 256, 4, 4]             512\n",
      "        LeakyReLU-12            [-1, 128, 8, 8]               0\n",
      "        LeakyReLU-13            [-1, 256, 4, 4]               0\n",
      "           Conv2d-14            [-1, 512, 2, 2]       3,277,312\n",
      "           Conv2d-15            [-1, 256, 4, 4]         819,456\n",
      "      BatchNorm2d-16            [-1, 512, 2, 2]           1,024\n",
      "        LeakyReLU-17            [-1, 512, 2, 2]               0\n",
      "      BatchNorm2d-18            [-1, 256, 4, 4]             512\n",
      "          Reshape-19                 [-1, 2048]               0\n",
      "           Linear-20                    [-1, 1]           2,049\n",
      "        LeakyReLU-21            [-1, 256, 4, 4]               0\n",
      "          Sigmoid-22                    [-1, 1]               0\n",
      "           Conv2d-23            [-1, 512, 2, 2]       3,277,312\n",
      "      BatchNorm2d-24            [-1, 512, 2, 2]           1,024\n",
      "        LeakyReLU-25            [-1, 512, 2, 2]               0\n",
      "          Reshape-26                 [-1, 2048]               0\n",
      "           Linear-27                    [-1, 1]           2,049\n",
      "          Sigmoid-28                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 8,614,402\n",
      "Trainable params: 8,614,402\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.19\n",
      "Params size (MB): 32.86\n",
      "Estimated Total Size (MB): 34.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "shape = (1, 32, 32)\n",
    "DCGAN = gan.DCGAN(\"mnist_dcgan\", shape, latent_dim, cuda=cuda, ngpu=4, nconv_layer_gen=4, nconv_layer_disc=4, nconv_fcgen=64,\n",
    "                  nconv_fcdis=64, kernal_size=5, stride=2, padding=2, output_padding=1)\n",
    "torchsummary.summary(DCGAN.generator, (1,1,latent_dim,))\n",
    "torchsummary.summary(DCGAN.discriminator, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
