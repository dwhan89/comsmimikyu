{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from orphics import sehgal, maps\n",
    "import healpy as hp\n",
    "from pixell import utils, enmap, curvedsky, enplot, wcsutils\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lmdb\n",
    "from cosmikyu import datasets, transforms, config, stats\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config.default_data_dir\n",
    "sehgal_dir = os.path.join(data_dir, 'sehgal')\n",
    "def data_path(x):\n",
    "    return os.path.join(sehgal_dir, x)\n",
    "SDS_validation = datasets.SehgalDataSet(sehgal_dir, data_type=\"validation141020\", transforms=[], dummy_label=False)\n",
    "data = np.zeros((5, 128, 128*len(SDS_validation)))\n",
    "compts = [\"kappa\", \"ksz\", \"tsz\", \"ir_pts\", \"rad_pts\"]\n",
    "\n",
    "for i in range(len(SDS_validation)):\n",
    "#for i in range(1000):\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_validation[i]\n",
    "    \n",
    "def sehgal_path(x):\n",
    "    return os.path.join(sehgal_dir, x)\n",
    "\n",
    "#enplot.pshow(data[:,:128,:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zfact = 1\n",
    "def log_normalize(emap, pos=True, neg=True):\n",
    "    temp = emap.copy()\n",
    "    #loc = np.where(emap!=0)\n",
    "    std = np.std(temp)\n",
    "    if pos:\n",
    "        loc = np.where(emap>=0)\n",
    "        temp[loc] = np.log(temp[loc]/std+1)\n",
    "    if neg:\n",
    "        loc = np.where(emap<0)\n",
    "        temp[loc] = -1*np.log(np.abs(temp[loc]/std)+1)\n",
    "\n",
    "    return temp\n",
    "\n",
    "\n",
    "def z_normalize(emap, zfact = zfact):\n",
    "    mean, std = emap.mean(), emap.std()   \n",
    "    return (emap-mean)/(std*zfact), [mean, std]\n",
    "\n",
    "def minmax(emap):\n",
    "    maxval, minval = emap.max(), emap.min()\n",
    "    valrange = (maxval-minval)\n",
    "    midval = (maxval+minval)/2\n",
    "    return (emap-midval)/valrange*2, [minval, maxval]\n",
    "\n",
    "\n",
    "freq_idx = 148\n",
    "'''\n",
    "ns = {\"kappa\": z_normalize,\n",
    "      \"ksz\": z_normalize,\n",
    "      \"ir_pts\": lambda x: minmax(log_normalize(x, neg=True)),\n",
    "      \"rad_pts\": lambda x: minmax(log_normalize(x, neg=True)),\n",
    "      \"tsz\": lambda x: minmax(log_normalize(x, pos=True)),\n",
    "     }\n",
    "'''\n",
    "ns = {\"kappa\": z_normalize,\n",
    "      \"ksz\": z_normalize,\n",
    "      \"ir_pts\": lambda x: z_normalize(log_normalize(x, neg=False)),\n",
    "      \"rad_pts\": lambda x: z_normalize(log_normalize(x, neg=False)),\n",
    "      \"tsz\": lambda x: z_normalize(log_normalize(x, pos=True)),\n",
    "     }\n",
    "\n",
    "ns = {\"kappa\": lambda x: tanh(z_normalize(x)),\n",
    "      \"ksz\": lambda x: tanh(z_normalize(x)),\n",
    "      \"ir_pts\": lambda x: tanh(log_normalize(x, neg=True)),\n",
    "      \"rad_pts\": lambda x: tanh(log_normalize(x, neg=True)),\n",
    "      \"tsz\": lambda x: tanh(log_normalize(x, neg=True)),\n",
    "     }\n",
    "\n",
    "ns = {\"kappa\": lambda x: minmax(x),\n",
    "      \"ksz\": lambda x: minmax(x),\n",
    "      \"ir_pts\": lambda x: minmax(log_normalize(x, neg=True)),\n",
    "      \"rad_pts\": lambda x: minmax(log_normalize(x, neg=True)),\n",
    "      \"tsz\": lambda x: minmax(log_normalize(x, neg=True)),\n",
    "     }\n",
    "\n",
    "norm_info_validation = {}\n",
    "hist_org_validation = {}\n",
    "hist_norm_validation = {}\n",
    "compts = [\"kappa\", \"ksz\", \"tsz\", \"ir_pts\", \"rad_pts\"]\n",
    "\n",
    "\n",
    "for i, compt_idx in enumerate(compts):\n",
    "    print(compt_idx)\n",
    "    #if i < 3: continue\n",
    "\n",
    "    temp = data[i].copy() \n",
    "    norm_info_validation[compt_idx] = []\n",
    "    norm_info_validation[compt_idx] += [temp.min(), temp.std()]\n",
    "    #minval, maxval = temp.min(), temp.max()\n",
    "    \n",
    "    nbins = 1024\n",
    "    hist, bins = np.histogram(data[i].copy(), bins=1024)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    hist_org_validation[compt_idx] = (hist, bins)\n",
    "    bin_center = (bins[:-1]+bins[1:])/2.\n",
    "    plt.plot(bin_center, hist/np.sum(hist), label=compt_idx)\n",
    "    plt.legend()\n",
    "    plt.axvline(x=1, ls=\"--\", color=\"k\")\n",
    "    plt.axvline(x=-1, ls=\"--\", color=\"k\")\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xlim(-5,5)\n",
    "    #plt.xscale(\"symlog\")\n",
    "    plt.show()\n",
    "    \n",
    "    ndata, temp = ns[compt_idx](data[i].copy())\n",
    "    norm_info_validation[compt_idx] += temp\n",
    "    print(norm_info_validation[compt_idx])\n",
    "    hist, bins = np.histogram(ndata, bins=1024)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    hist_norm_validation[compt_idx] = (hist, bins)\n",
    "    bin_center = (bins[:-1]+bins[1:])/2.\n",
    "    plt.plot(bin_center, hist/np.sum(hist), label=compt_idx)\n",
    "    plt.axvline(x=1, ls=\"--\", color=\"k\")\n",
    "    plt.axvline(x=-1, ls=\"--\", color=\"k\")\n",
    "    plt.axhline(y=1e-5, ls=\"--\", color=\"k\")\n",
    "    plt.legend()\n",
    "    #plt.xlim(-12,12)\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xscale(\"symlog\")\n",
    "    plt.show()\n",
    "    \n",
    "    hist, bins = np.histogram(ndata, bins=1024)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(bin_center, hist/np.sum(hist), label=compt_idx)\n",
    "    plt.axvline(x=1, ls=\"--\", color=\"k\")\n",
    "    plt.axvline(x=-1, ls=\"--\", color=\"k\")\n",
    "    plt.axhline(y=1e-5, ls=\"--\", color=\"k\")\n",
    "    plt.legend()\n",
    "    #plt.xlim(-12,12)\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xscale(\"symlog\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa {'min': -0.6806576117720182, 'std': 0.07407179512283714, 'logmean': -2.6458898250364806e-05, 'logstd': 0.07407179512283714}\n",
      "ksz {'min': -37.412660533440295, 'std': 2.1445520917184044, 'logmean': -0.00406070836384978, 'logstd': 2.1445520917184044}\n",
      "tsz {'min': -290.8268366090156, 'std': 2.567613946408688, 'logmean': -0.6697793761660281, 'logstd': 0.27506589295912703}\n",
      "ir_pts {'min': -3.9728085209285857, 'std': 6.573228652867444, 'logmean': 1.2275226201566654, 'logstd': 0.2578566082552369}\n",
      "rad_pts {'min': -2.6336878229445273, 'std': 3.6703679499683948, 'logmean': 0.03511814342501448, 'logstd': 0.18265126946443766}\n"
     ]
    }
   ],
   "source": [
    "norm_info_validation_out = {} \n",
    "\n",
    "for idx in norm_info_validation.keys():\n",
    "    norm_info_validation_out[idx] = {\"min\":float(norm_info_validation[idx][0]), \"std\":float(norm_info_validation[idx][1]),\n",
    "                          \"logmean\":float(norm_info_validation[idx][2]), \"logstd\":float(norm_info_validation[idx][3])}\n",
    "    \n",
    "    print(idx, norm_info_validation_out[idx])\n",
    "hist_org_validation_out = {} \n",
    "for idx in hist_org_validation.keys():\n",
    "    hist_org_validation_out[idx] = {}\n",
    "    hist_org_validation_out[idx][\"hist\"] = hist_org_validation[idx][0]\n",
    "    bin_edges =  hist_org_validation[idx][1]\n",
    "    hist_org_validation_out[idx][\"bin_centers\"] = (bin_edges[:-1]+bin_edges[1:])/2.\n",
    "    hist_org_validation_out[idx][\"bin_edges\"] = bin_edges\n",
    "    \n",
    "\n",
    "\n",
    "np.savez(data_path(\"141020_normalization_info_validation.npz\"), **norm_info_validation_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-04fa8b70ccf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnorm_info_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/dwhan89/workspace/cosmikyu/data/sehgal/141020_normalization_info_validation.npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSDN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSehgalDataNormalizerScaledLogZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mSDS_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSehgalDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msehgal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation141020\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSDN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDS_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "norm_info_file = \"/home/dwhan89/workspace/cosmikyu/data/sehgal/141020_normalization_info_validation.npz\"\n",
    "SDN = transforms.SehgalDataNormalizerScaledLogZ(norm_info_file)\n",
    "SDS_validation = datasets.SehgalDataSet(sehgal_dir, data_type=\"validation141020\", transforms=[SDN], dummy_label=False)\n",
    "\n",
    "nsample = len(SDS_validation)\n",
    "data = np.zeros((5, 128, 128*nsample))\n",
    "nbins = 10000\n",
    "\n",
    "for i in range(nsample):\n",
    "    if i % 5000 == 0: print(i)\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_validation[i]\n",
    "print(data.min(), data.max(), data.mean())\n",
    "print(\"start binning\")\n",
    "MB = stats.FastMultBinner((-30,30), nbins, data.shape[0])\n",
    "MB.bin(data)\n",
    "    \n",
    "ret = MB.get_info()\n",
    "out = {}\n",
    "for key in range(5):\n",
    "    print(key)\n",
    "    out[SDN.channel_idxes[key]] = ret[key].copy()\n",
    "ret = out\n",
    "np.savez(sehgal_path(\"141020_normalized_histogram_validation_{}.npz\".format(nbins)), **out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "-17.451651082817836 28.086762952427456 0.01014514060865161\n",
      "start binning\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sehgal_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-25634ce22929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSDN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_idxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msehgal_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"141020_normalized_histogram_train_{}.npz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sehgal_path' is not defined"
     ]
    }
   ],
   "source": [
    "norm_info_file = \"/home/dwhan89/workspace/cosmikyu/data/sehgal/141020_normalization_info_validation.npz\"\n",
    "SDN = transforms.SehgalDataNormalizerScaledLogZ(norm_info_file)\n",
    "SDS_train = datasets.SehgalDataSet(sehgal_dir, data_type=\"train141020\", transforms=[SDN], dummy_label=False)\n",
    "\n",
    "nsample = len(SDS_train)\n",
    "data = np.zeros((5, 128, 128*nsample))\n",
    "\n",
    "nbins = 10000\n",
    "for i in range(nsample):\n",
    "    if i % 5000 == 0: print(i)\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_train[i]\n",
    "print(data.min(), data.max(), data.mean())\n",
    "print(\"start binning\")\n",
    "MB = stats.FastMultBinner((-30,30), nbins, data.shape[0])\n",
    "MB.bin(data)\n",
    "    \n",
    "ret = MB.get_info()\n",
    "out = {}\n",
    "for key in range(5):\n",
    "    print(key)\n",
    "    out[SDN.channel_idxes[key]] = ret[key].copy()\n",
    "ret = out\n",
    "np.savez(sehgal_path(\"141020_normalized_histogram_train_{}.npz\".format(nbins)), **out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "-17.451651082817836 28.078867012023945 0.009773964663625364\n",
      "start binning\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "norm_info_file = \"/home/dwhan89/workspace/cosmikyu/data/sehgal/141020_normalization_info_validation.npz\"\n",
    "SDN = transforms.SehgalDataNormalizerScaledLogZ(norm_info_file)\n",
    "SDS_test = datasets.SehgalDataSet(sehgal_dir, data_type=\"test141020\", transforms=[SDN], dummy_label=False)\n",
    "\n",
    "nsample = len(SDS_test)\n",
    "data = np.zeros((5, 128, 128*nsample))\n",
    "SDS_test\n",
    "nbins = 10000\n",
    "for i in range(nsample):\n",
    "    if i % 5000 == 0: print(i)\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_test[i]\n",
    "print(data.min(), data.max(), data.mean())\n",
    "print(\"start binning\")\n",
    "MB = stats.FastMultBinner((-30,30), nbins, data.shape[0])\n",
    "MB.bin(data)\n",
    "    \n",
    "ret = MB.get_info()\n",
    "out = {}\n",
    "for key in range(5):\n",
    "    print(key)\n",
    "    out[SDN.channel_idxes[key]] = ret[key].copy()\n",
    "ret = out\n",
    "np.savez(sehgal_path(\"141020_normalized_histogram_test_{}.npz\".format(nbins)), **out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "-290.7731033193691 803.6106114930507 2.849090983757404\n",
      "start binning\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "norm_info_file = \"/home/dwhan89/workspace/cosmikyu/data/sehgal/141020_normalization_info_validation.npz\"\n",
    "SDN = transforms.SehgalDataNormalizerScaledLogZ(norm_info_file)\n",
    "SDS_test = datasets.SehgalDataSet(sehgal_dir, data_type=\"test141020\", transforms=[], dummy_label=False)\n",
    "\n",
    "nsample = len(SDS_test)\n",
    "data = np.zeros((5, 128, 128*nsample))\n",
    "\n",
    "nbins = 10000\n",
    "for i in range(nsample):\n",
    "    if i % 5000 == 0: print(i)\n",
    "    sidx = 128*i\n",
    "    data[...,sidx: sidx+128] = SDS_test[i]\n",
    "print(data.min(), data.max(), data.mean())\n",
    "print(\"start binning\")\n",
    "MB = stats.FastMultBinner((-30,30), nbins, data.shape[0])\n",
    "MB.bin(data)\n",
    "    \n",
    "ret = MB.get_info()\n",
    "out = {}\n",
    "for key in range(5):\n",
    "    print(key)\n",
    "    out[SDN.channel_idxes[key]] = ret[key].copy()\n",
    "ret = out\n",
    "np.savez(sehgal_path(\"141020_raw_histogram_test_{}.npz\".format(nbins)), **out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
