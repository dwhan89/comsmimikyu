{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmikyu import visualization as covis\n",
    "from cosmikyu import gan, config, datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as pytransforms\n",
    "#from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import mlflow\n",
    "import torchsummary\n",
    "from orphics import maps\n",
    "from pixell import enplot, enmap\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwhan89/.miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "data_dir = config.default_data_dir\n",
    "sehgal_dir = os.path.join(data_dir, 'sehgal')\n",
    "cuda = True\n",
    "compt_idxes = [0]#,1,2,3,4]\n",
    "shape = (len(compt_idxes),128,128)\n",
    "#shape = (1, 256, 256)\n",
    "latent_dim = 64\n",
    "sample_interval = 200\n",
    "save_interval = 1\n",
    "batch_size = 256\n",
    "nepochs=2\n",
    "norm_info_file = \"/home/dwhan89/workspace/cosmikyu/data/sehgal/normalization_info_fullv3.npz\"\n",
    "\n",
    "_, wcs = maps.rect_geometry(width_arcmin=64., px_res_arcmin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwhan89/.miniconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Configure data loader\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(sehgal_dir, exist_ok=True)\n",
    "SDN = transforms.SehgalDataNormalizer(norm_info_file, zfact=4)\n",
    "SC = transforms.SehgalSubcomponets(compt_idxes)\n",
    "SUBS = transforms.UnBlockShape(shape)\n",
    "RF = transforms.RandomFlips(p_v=0.5, p_h=0.5)\n",
    "SDS_train = datasets.SehgalDataSet(sehgal_dir, data_type=\"testv3\", transforms=[SDN, RF, SC], dummy_label=True)\n",
    "\n",
    "#enplot.pshow(enmap.enmap(SDS_train[0], wcs))\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    SDS_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states \n",
      "failed to load saved states\n",
      "saving states _0\n",
      "[Epoch 0/2] [Batch 0/118] [D loss: 9.691091] [G loss: 0.069002]\n",
      "[Epoch 0/2] [Batch 5/118] [D loss: 1.258224] [G loss: 7.962967]\n",
      "[Epoch 0/2] [Batch 10/118] [D loss: -18.068144] [G loss: 15.143276]\n",
      "[Epoch 0/2] [Batch 15/118] [D loss: -27.405598] [G loss: 11.840870]\n",
      "[Epoch 0/2] [Batch 20/118] [D loss: -30.031334] [G loss: -2.861681]\n",
      "[Epoch 0/2] [Batch 25/118] [D loss: -38.956486] [G loss: -2.083562]\n",
      "[Epoch 0/2] [Batch 30/118] [D loss: -39.216759] [G loss: 12.190394]\n",
      "[Epoch 0/2] [Batch 35/118] [D loss: -37.839333] [G loss: 16.398941]\n",
      "[Epoch 0/2] [Batch 40/118] [D loss: -37.521881] [G loss: 13.663698]\n",
      "[Epoch 0/2] [Batch 45/118] [D loss: -36.576408] [G loss: 2.040830]\n",
      "[Epoch 0/2] [Batch 50/118] [D loss: -36.568169] [G loss: -9.365112]\n",
      "[Epoch 0/2] [Batch 55/118] [D loss: -36.363953] [G loss: -18.450888]\n",
      "[Epoch 0/2] [Batch 60/118] [D loss: -38.329052] [G loss: -33.054813]\n",
      "[Epoch 0/2] [Batch 65/118] [D loss: -38.041367] [G loss: -44.351837]\n",
      "[Epoch 0/2] [Batch 70/118] [D loss: -37.829311] [G loss: -40.877281]\n",
      "[Epoch 0/2] [Batch 75/118] [D loss: -38.915993] [G loss: -50.763016]\n",
      "[Epoch 0/2] [Batch 80/118] [D loss: -36.928104] [G loss: -46.939060]\n",
      "[Epoch 0/2] [Batch 85/118] [D loss: -37.990723] [G loss: -53.085007]\n",
      "[Epoch 0/2] [Batch 90/118] [D loss: -36.452477] [G loss: -58.074173]\n",
      "[Epoch 0/2] [Batch 95/118] [D loss: -36.294964] [G loss: -64.550323]\n",
      "[Epoch 0/2] [Batch 100/118] [D loss: -33.657837] [G loss: -59.298378]\n",
      "[Epoch 0/2] [Batch 105/118] [D loss: -35.269695] [G loss: -65.130318]\n",
      "[Epoch 0/2] [Batch 110/118] [D loss: -33.122189] [G loss: -65.892365]\n",
      "[Epoch 0/2] [Batch 115/118] [D loss: -30.567678] [G loss: -71.693405]\n",
      "saving states _1\n",
      "[Epoch 1/2] [Batch 0/118] [D loss: -27.990973] [G loss: -72.172165]\n",
      "[Epoch 1/2] [Batch 5/118] [D loss: -30.533554] [G loss: -63.971817]\n",
      "[Epoch 1/2] [Batch 10/118] [D loss: -26.979111] [G loss: -73.621078]\n",
      "[Epoch 1/2] [Batch 15/118] [D loss: -30.678593] [G loss: -71.606735]\n",
      "[Epoch 1/2] [Batch 20/118] [D loss: -25.785166] [G loss: -65.232712]\n",
      "[Epoch 1/2] [Batch 25/118] [D loss: -26.495693] [G loss: -52.851669]\n",
      "[Epoch 1/2] [Batch 30/118] [D loss: -29.193142] [G loss: -54.542442]\n",
      "[Epoch 1/2] [Batch 35/118] [D loss: -25.443954] [G loss: -56.395020]\n",
      "[Epoch 1/2] [Batch 40/118] [D loss: -27.021976] [G loss: -60.726624]\n",
      "[Epoch 1/2] [Batch 45/118] [D loss: -24.590298] [G loss: -59.652016]\n",
      "[Epoch 1/2] [Batch 50/118] [D loss: -26.849123] [G loss: -60.602318]\n",
      "[Epoch 1/2] [Batch 55/118] [D loss: -24.301426] [G loss: -63.598942]\n",
      "[Epoch 1/2] [Batch 60/118] [D loss: -28.601776] [G loss: -47.009815]\n",
      "[Epoch 1/2] [Batch 65/118] [D loss: -23.549267] [G loss: -60.439602]\n",
      "[Epoch 1/2] [Batch 70/118] [D loss: -32.235172] [G loss: -42.018528]\n",
      "[Epoch 1/2] [Batch 75/118] [D loss: -24.695963] [G loss: -53.730331]\n",
      "[Epoch 1/2] [Batch 80/118] [D loss: -22.917919] [G loss: -54.641571]\n",
      "[Epoch 1/2] [Batch 85/118] [D loss: -24.062504] [G loss: -56.369804]\n",
      "[Epoch 1/2] [Batch 90/118] [D loss: -29.861315] [G loss: -58.668606]\n",
      "[Epoch 1/2] [Batch 95/118] [D loss: -23.202522] [G loss: -57.386627]\n",
      "[Epoch 1/2] [Batch 100/118] [D loss: -24.041561] [G loss: -49.161781]\n",
      "[Epoch 1/2] [Batch 105/118] [D loss: -26.932434] [G loss: -34.021919]\n",
      "[Epoch 1/2] [Batch 110/118] [D loss: -23.910141] [G loss: -36.674110]\n",
      "[Epoch 1/2] [Batch 115/118] [D loss: -23.380499] [G loss: -45.860916]\n",
      "saving states _2\n"
     ]
    }
   ],
   "source": [
    "COSMOGAN_WGAP = gan.COSMOGAN_WGP(\"sehgal_cosmoganwgpv3\", shape, latent_dim, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(COSMOGAN_WGAP.identifier)\n",
    "with mlflow.start_run(experiment_id=COSMOGAN_WGAP.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    COSMOGAN_WGAP.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=5,\n",
    "        sample_interval=sample_interval,\n",
    "        save_interval=save_interval,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999),\n",
    "        lambda_gp=10.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7b8992e75712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCOSMOGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOSMOGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sehgal_cosmogan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnconv_fcdis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOSMOGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOSMOGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmlflow_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     COSMOGAN.train(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gan' is not defined"
     ]
    }
   ],
   "source": [
    "COSMOGAN = gan.COSMOGAN(\"sehgal_cosmogan\", shape, latent_dim, cuda=cuda, nconv_fcdis=64, ngpu=4)\n",
    "mlflow.set_experiment(COSMOGAN.identifier)          \n",
    "with mlflow.start_run(experiment_id=COSMOGAN.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    COSMOGAN.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=1,\n",
    "        sample_interval=sample_interval,\n",
    "        save_interval=save_interval,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved states\n",
      "failed to load saved states\n",
      "[Epoch 0/2] [Batch 0/782] [D loss: 9.425166] [G loss: 0.477536]\n",
      "saving states\n",
      "[Epoch 0/2] [Batch 1/782] [D loss: -1967.577271] [G loss: -24.084686]\n",
      "[Epoch 0/2] [Batch 2/782] [D loss: -7624.934082] [G loss: -147.843201]\n",
      "[Epoch 0/2] [Batch 3/782] [D loss: -18027.080078] [G loss: -651.585876]\n",
      "[Epoch 0/2] [Batch 4/782] [D loss: -33443.070312] [G loss: -2314.534912]\n",
      "[Epoch 0/2] [Batch 5/782] [D loss: -51354.609375] [G loss: -6002.318359]\n",
      "[Epoch 0/2] [Batch 6/782] [D loss: -71186.335938] [G loss: -10608.253906]\n",
      "[Epoch 0/2] [Batch 7/782] [D loss: -91638.570312] [G loss: -13889.488281]\n",
      "[Epoch 0/2] [Batch 8/782] [D loss: -103577.054688] [G loss: -15213.735352]\n",
      "[Epoch 0/2] [Batch 9/782] [D loss: -102160.531250] [G loss: -15305.935547]\n",
      "[Epoch 0/2] [Batch 10/782] [D loss: -101209.531250] [G loss: -14895.144531]\n",
      "[Epoch 0/2] [Batch 11/782] [D loss: -105000.171875] [G loss: -14445.365234]\n",
      "[Epoch 0/2] [Batch 12/782] [D loss: -105017.781250] [G loss: -14261.939453]\n",
      "[Epoch 0/2] [Batch 13/782] [D loss: -104825.890625] [G loss: -14451.591797]\n",
      "[Epoch 0/2] [Batch 14/782] [D loss: -105878.632812] [G loss: -14781.209961]\n",
      "[Epoch 0/2] [Batch 15/782] [D loss: -103789.343750] [G loss: -14852.852539]\n",
      "[Epoch 0/2] [Batch 16/782] [D loss: -105058.781250] [G loss: -14878.988281]\n",
      "[Epoch 0/2] [Batch 17/782] [D loss: -102775.296875] [G loss: -14747.185547]\n",
      "[Epoch 0/2] [Batch 18/782] [D loss: -103023.031250] [G loss: -14577.638672]\n",
      "[Epoch 0/2] [Batch 19/782] [D loss: -103186.640625] [G loss: -14565.466797]\n",
      "[Epoch 0/2] [Batch 20/782] [D loss: -104826.492188] [G loss: -14807.478516]\n",
      "[Epoch 0/2] [Batch 21/782] [D loss: -102428.031250] [G loss: -14782.138672]\n",
      "[Epoch 0/2] [Batch 22/782] [D loss: -104150.062500] [G loss: -14836.566406]\n",
      "[Epoch 0/2] [Batch 23/782] [D loss: -105497.156250] [G loss: -14901.806641]\n",
      "[Epoch 0/2] [Batch 24/782] [D loss: -103210.750000] [G loss: -14726.863281]\n",
      "[Epoch 0/2] [Batch 25/782] [D loss: -105780.703125] [G loss: -14929.611328]\n",
      "[Epoch 0/2] [Batch 26/782] [D loss: -104098.890625] [G loss: -14883.347656]\n",
      "[Epoch 0/2] [Batch 27/782] [D loss: -105396.468750] [G loss: -14895.442383]\n",
      "[Epoch 0/2] [Batch 28/782] [D loss: -104806.062500] [G loss: -14828.833984]\n",
      "[Epoch 0/2] [Batch 29/782] [D loss: -105786.085938] [G loss: -14902.796875]\n",
      "[Epoch 0/2] [Batch 30/782] [D loss: -103712.898438] [G loss: -14860.178711]\n",
      "[Epoch 0/2] [Batch 31/782] [D loss: -104767.742188] [G loss: -14847.080078]\n",
      "[Epoch 0/2] [Batch 32/782] [D loss: -106270.328125] [G loss: -14938.793945]\n",
      "[Epoch 0/2] [Batch 33/782] [D loss: -105381.414062] [G loss: -14968.007812]\n",
      "[Epoch 0/2] [Batch 34/782] [D loss: -105595.460938] [G loss: -14915.140625]\n",
      "[Epoch 0/2] [Batch 35/782] [D loss: -104769.625000] [G loss: -14888.300781]\n",
      "[Epoch 0/2] [Batch 36/782] [D loss: -102532.906250] [G loss: -14711.089844]\n",
      "[Epoch 0/2] [Batch 37/782] [D loss: -104685.812500] [G loss: -14813.435547]\n",
      "[Epoch 0/2] [Batch 38/782] [D loss: -105100.460938] [G loss: -15056.578125]\n",
      "[Epoch 0/2] [Batch 39/782] [D loss: -104892.218750] [G loss: -14949.931641]\n",
      "[Epoch 0/2] [Batch 40/782] [D loss: -105100.125000] [G loss: -14792.064453]\n",
      "[Epoch 0/2] [Batch 41/782] [D loss: -104171.546875] [G loss: -14815.914062]\n",
      "[Epoch 0/2] [Batch 42/782] [D loss: -104479.414062] [G loss: -14937.093750]\n",
      "[Epoch 0/2] [Batch 43/782] [D loss: -104434.062500] [G loss: -14875.914062]\n",
      "[Epoch 0/2] [Batch 44/782] [D loss: -105552.867188] [G loss: -15014.700195]\n",
      "[Epoch 0/2] [Batch 45/782] [D loss: -103933.562500] [G loss: -14922.878906]\n",
      "[Epoch 0/2] [Batch 46/782] [D loss: -103798.273438] [G loss: -14734.886719]\n",
      "[Epoch 0/2] [Batch 47/782] [D loss: -103847.625000] [G loss: -14800.256836]\n",
      "[Epoch 0/2] [Batch 48/782] [D loss: -105490.476562] [G loss: -15013.367188]\n",
      "[Epoch 0/2] [Batch 49/782] [D loss: -104716.914062] [G loss: -14985.134766]\n",
      "[Epoch 0/2] [Batch 50/782] [D loss: -103922.218750] [G loss: -14758.298828]\n",
      "[Epoch 0/2] [Batch 51/782] [D loss: -105029.828125] [G loss: -14880.260742]\n",
      "[Epoch 0/2] [Batch 52/782] [D loss: -103897.523438] [G loss: -14899.800781]\n",
      "[Epoch 0/2] [Batch 53/782] [D loss: -104052.914062] [G loss: -14838.682617]\n",
      "[Epoch 0/2] [Batch 54/782] [D loss: -104188.281250] [G loss: -14975.207031]\n",
      "[Epoch 0/2] [Batch 55/782] [D loss: -104396.445312] [G loss: -14883.349609]\n",
      "[Epoch 0/2] [Batch 56/782] [D loss: -105256.531250] [G loss: -14963.654297]\n",
      "[Epoch 0/2] [Batch 57/782] [D loss: -105056.343750] [G loss: -14963.550781]\n",
      "[Epoch 0/2] [Batch 58/782] [D loss: -105769.804688] [G loss: -15019.378906]\n",
      "[Epoch 0/2] [Batch 59/782] [D loss: -104200.593750] [G loss: -14832.464844]\n",
      "[Epoch 0/2] [Batch 60/782] [D loss: -103835.695312] [G loss: -14834.619141]\n",
      "[Epoch 0/2] [Batch 61/782] [D loss: -104851.000000] [G loss: -15025.216797]\n",
      "[Epoch 0/2] [Batch 62/782] [D loss: -106653.578125] [G loss: -15198.546875]\n",
      "[Epoch 0/2] [Batch 63/782] [D loss: -102705.179688] [G loss: -14613.477539]\n",
      "[Epoch 0/2] [Batch 64/782] [D loss: -105345.203125] [G loss: -14987.316406]\n",
      "[Epoch 0/2] [Batch 65/782] [D loss: -104685.945312] [G loss: -15184.404297]\n",
      "[Epoch 0/2] [Batch 66/782] [D loss: -104116.257812] [G loss: -14840.771484]\n",
      "[Epoch 0/2] [Batch 67/782] [D loss: -104886.960938] [G loss: -14875.652344]\n",
      "[Epoch 0/2] [Batch 68/782] [D loss: -103564.117188] [G loss: -14806.383789]\n",
      "[Epoch 0/2] [Batch 69/782] [D loss: -104627.945312] [G loss: -15030.492188]\n",
      "[Epoch 0/2] [Batch 70/782] [D loss: -104891.507812] [G loss: -14956.381836]\n",
      "[Epoch 0/2] [Batch 71/782] [D loss: -105221.625000] [G loss: -14942.140625]\n",
      "[Epoch 0/2] [Batch 72/782] [D loss: -106428.203125] [G loss: -15136.638672]\n",
      "[Epoch 0/2] [Batch 73/782] [D loss: -106644.250000] [G loss: -15188.345703]\n",
      "[Epoch 0/2] [Batch 74/782] [D loss: -105244.710938] [G loss: -14830.134766]\n",
      "[Epoch 0/2] [Batch 75/782] [D loss: -104328.390625] [G loss: -14781.683594]\n",
      "[Epoch 0/2] [Batch 76/782] [D loss: -104677.593750] [G loss: -14999.412109]\n",
      "[Epoch 0/2] [Batch 77/782] [D loss: -103868.000000] [G loss: -14858.259766]\n",
      "[Epoch 0/2] [Batch 78/782] [D loss: -107019.578125] [G loss: -15252.572266]\n",
      "[Epoch 0/2] [Batch 79/782] [D loss: -102777.710938] [G loss: -14567.794922]\n",
      "[Epoch 0/2] [Batch 80/782] [D loss: -106837.062500] [G loss: -15169.079102]\n",
      "[Epoch 0/2] [Batch 81/782] [D loss: -105395.937500] [G loss: -15136.398438]\n",
      "[Epoch 0/2] [Batch 82/782] [D loss: -104404.984375] [G loss: -14766.666016]\n",
      "[Epoch 0/2] [Batch 83/782] [D loss: -104254.757812] [G loss: -14837.867188]\n",
      "[Epoch 0/2] [Batch 84/782] [D loss: -105538.656250] [G loss: -15158.642578]\n",
      "[Epoch 0/2] [Batch 85/782] [D loss: -102982.500000] [G loss: -14592.018555]\n",
      "[Epoch 0/2] [Batch 86/782] [D loss: -103825.796875] [G loss: -14824.776367]\n",
      "[Epoch 0/2] [Batch 87/782] [D loss: -104172.062500] [G loss: -15099.513672]\n",
      "[Epoch 0/2] [Batch 88/782] [D loss: -106741.640625] [G loss: -15262.445312]\n",
      "[Epoch 0/2] [Batch 89/782] [D loss: -103859.343750] [G loss: -14528.550781]\n",
      "[Epoch 0/2] [Batch 90/782] [D loss: -103383.304688] [G loss: -14713.186523]\n",
      "[Epoch 0/2] [Batch 91/782] [D loss: -104238.148438] [G loss: -15210.161133]\n",
      "[Epoch 0/2] [Batch 92/782] [D loss: -104540.031250] [G loss: -14970.363281]\n",
      "[Epoch 0/2] [Batch 93/782] [D loss: -104427.687500] [G loss: -14793.777344]\n",
      "[Epoch 0/2] [Batch 94/782] [D loss: -105287.609375] [G loss: -15074.171875]\n",
      "[Epoch 0/2] [Batch 95/782] [D loss: -106993.921875] [G loss: -15247.834961]\n",
      "[Epoch 0/2] [Batch 96/782] [D loss: -106127.617188] [G loss: -14924.101562]\n",
      "[Epoch 0/2] [Batch 97/782] [D loss: -104630.984375] [G loss: -14818.877930]\n",
      "[Epoch 0/2] [Batch 98/782] [D loss: -104457.093750] [G loss: -14943.335938]\n",
      "[Epoch 0/2] [Batch 99/782] [D loss: -104616.960938] [G loss: -14918.648438]\n",
      "[Epoch 0/2] [Batch 100/782] [D loss: -103957.140625] [G loss: -14832.322266]\n",
      "[Epoch 0/2] [Batch 101/782] [D loss: -103948.515625] [G loss: -14980.662109]\n",
      "[Epoch 0/2] [Batch 102/782] [D loss: -106212.890625] [G loss: -15271.997070]\n",
      "[Epoch 0/2] [Batch 103/782] [D loss: -103031.921875] [G loss: -14448.087891]\n",
      "[Epoch 0/2] [Batch 104/782] [D loss: -104488.078125] [G loss: -15073.912109]\n",
      "[Epoch 0/2] [Batch 105/782] [D loss: -104476.578125] [G loss: -15164.814453]\n",
      "[Epoch 0/2] [Batch 106/782] [D loss: -105756.304688] [G loss: -14934.161133]\n",
      "[Epoch 0/2] [Batch 107/782] [D loss: -105235.023438] [G loss: -14890.150391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 108/782] [D loss: -103720.000000] [G loss: -14728.732422]\n",
      "[Epoch 0/2] [Batch 109/782] [D loss: -104101.984375] [G loss: -14960.045898]\n",
      "[Epoch 0/2] [Batch 110/782] [D loss: -105426.093750] [G loss: -15155.130859]\n",
      "[Epoch 0/2] [Batch 111/782] [D loss: -104824.515625] [G loss: -14788.333984]\n",
      "[Epoch 0/2] [Batch 112/782] [D loss: -105270.812500] [G loss: -15101.629883]\n",
      "[Epoch 0/2] [Batch 113/782] [D loss: -104917.531250] [G loss: -14978.191406]\n",
      "[Epoch 0/2] [Batch 114/782] [D loss: -103643.453125] [G loss: -14668.988281]\n",
      "[Epoch 0/2] [Batch 115/782] [D loss: -105388.109375] [G loss: -15202.030273]\n",
      "[Epoch 0/2] [Batch 116/782] [D loss: -105031.992188] [G loss: -14873.798828]\n",
      "[Epoch 0/2] [Batch 117/782] [D loss: -104367.859375] [G loss: -14836.804688]\n",
      "[Epoch 0/2] [Batch 118/782] [D loss: -105327.656250] [G loss: -15196.566406]\n",
      "[Epoch 0/2] [Batch 119/782] [D loss: -102216.656250] [G loss: -14314.955078]\n",
      "[Epoch 0/2] [Batch 120/782] [D loss: -105578.132812] [G loss: -15453.474609]\n",
      "[Epoch 0/2] [Batch 121/782] [D loss: -104567.835938] [G loss: -14745.505859]\n",
      "[Epoch 0/2] [Batch 122/782] [D loss: -107090.593750] [G loss: -15341.041016]\n",
      "[Epoch 0/2] [Batch 123/782] [D loss: -104317.828125] [G loss: -14653.062500]\n",
      "[Epoch 0/2] [Batch 124/782] [D loss: -102837.156250] [G loss: -14709.175781]\n",
      "[Epoch 0/2] [Batch 125/782] [D loss: -105695.882812] [G loss: -15429.957031]\n",
      "[Epoch 0/2] [Batch 126/782] [D loss: -103090.750000] [G loss: -14285.191406]\n",
      "[Epoch 0/2] [Batch 127/782] [D loss: -104583.703125] [G loss: -15264.892578]\n",
      "[Epoch 0/2] [Batch 128/782] [D loss: -103524.281250] [G loss: -14780.037109]\n",
      "[Epoch 0/2] [Batch 129/782] [D loss: -105549.382812] [G loss: -15103.731445]\n",
      "[Epoch 0/2] [Batch 130/782] [D loss: -104965.843750] [G loss: -14889.432617]\n",
      "[Epoch 0/2] [Batch 131/782] [D loss: -104885.117188] [G loss: -14936.620117]\n",
      "[Epoch 0/2] [Batch 132/782] [D loss: -104527.679688] [G loss: -14918.744141]\n",
      "[Epoch 0/2] [Batch 133/782] [D loss: -106176.734375] [G loss: -15189.986328]\n",
      "[Epoch 0/2] [Batch 134/782] [D loss: -105831.000000] [G loss: -14842.674805]\n",
      "[Epoch 0/2] [Batch 135/782] [D loss: -106788.867188] [G loss: -15276.249023]\n",
      "[Epoch 0/2] [Batch 136/782] [D loss: -104090.203125] [G loss: -14530.472656]\n",
      "[Epoch 0/2] [Batch 137/782] [D loss: -103767.976562] [G loss: -15031.855469]\n",
      "[Epoch 0/2] [Batch 138/782] [D loss: -105557.468750] [G loss: -15239.417969]\n",
      "[Epoch 0/2] [Batch 139/782] [D loss: -105386.312500] [G loss: -14730.882812]\n",
      "[Epoch 0/2] [Batch 140/782] [D loss: -104345.734375] [G loss: -15000.404297]\n",
      "[Epoch 0/2] [Batch 141/782] [D loss: -105479.507812] [G loss: -15206.335938]\n",
      "[Epoch 0/2] [Batch 142/782] [D loss: -104660.757812] [G loss: -14665.725586]\n",
      "[Epoch 0/2] [Batch 143/782] [D loss: -105075.875000] [G loss: -15221.953125]\n",
      "[Epoch 0/2] [Batch 144/782] [D loss: -105934.937500] [G loss: -15031.212891]\n",
      "[Epoch 0/2] [Batch 145/782] [D loss: -104918.031250] [G loss: -14781.697266]\n",
      "[Epoch 0/2] [Batch 146/782] [D loss: -102090.867188] [G loss: -14612.792969]\n",
      "[Epoch 0/2] [Batch 147/782] [D loss: -103570.859375] [G loss: -15179.545898]\n",
      "[Epoch 0/2] [Batch 148/782] [D loss: -105727.210938] [G loss: -15023.014648]\n",
      "[Epoch 0/2] [Batch 149/782] [D loss: -106384.914062] [G loss: -15124.380859]\n",
      "[Epoch 0/2] [Batch 150/782] [D loss: -105304.046875] [G loss: -14990.412109]\n",
      "[Epoch 0/2] [Batch 151/782] [D loss: -103137.570312] [G loss: -14705.294922]\n",
      "[Epoch 0/2] [Batch 152/782] [D loss: -104880.679688] [G loss: -15420.710938]\n",
      "[Epoch 0/2] [Batch 153/782] [D loss: -104600.140625] [G loss: -14526.724609]\n",
      "[Epoch 0/2] [Batch 154/782] [D loss: -106171.890625] [G loss: -15511.291992]\n",
      "[Epoch 0/2] [Batch 155/782] [D loss: -102978.226562] [G loss: -14081.789062]\n",
      "[Epoch 0/2] [Batch 156/782] [D loss: -103675.781250] [G loss: -15497.535156]\n",
      "[Epoch 0/2] [Batch 157/782] [D loss: -105232.539062] [G loss: -14772.584961]\n",
      "[Epoch 0/2] [Batch 158/782] [D loss: -102416.703125] [G loss: -14376.014648]\n",
      "[Epoch 0/2] [Batch 159/782] [D loss: -105440.484375] [G loss: -15844.789062]\n",
      "[Epoch 0/2] [Batch 160/782] [D loss: -104276.921875] [G loss: -14110.774414]\n",
      "[Epoch 0/2] [Batch 161/782] [D loss: -103243.523438] [G loss: -15389.126953]\n",
      "[Epoch 0/2] [Batch 162/782] [D loss: -104753.882812] [G loss: -14889.524414]\n",
      "[Epoch 0/2] [Batch 163/782] [D loss: -106387.257812] [G loss: -15089.598633]\n",
      "[Epoch 0/2] [Batch 164/782] [D loss: -106361.468750] [G loss: -15062.995117]\n",
      "[Epoch 0/2] [Batch 165/782] [D loss: -104215.000000] [G loss: -14603.090820]\n",
      "[Epoch 0/2] [Batch 166/782] [D loss: -105375.421875] [G loss: -15369.982422]\n",
      "[Epoch 0/2] [Batch 167/782] [D loss: -104534.703125] [G loss: -14362.243164]\n",
      "[Epoch 0/2] [Batch 168/782] [D loss: -102074.007812] [G loss: -14598.177734]\n",
      "[Epoch 0/2] [Batch 169/782] [D loss: -104895.679688] [G loss: -15411.738281]\n",
      "[Epoch 0/2] [Batch 170/782] [D loss: -105170.335938] [G loss: -14183.050781]\n",
      "[Epoch 0/2] [Batch 171/782] [D loss: -105630.398438] [G loss: -15538.433594]\n",
      "[Epoch 0/2] [Batch 172/782] [D loss: -103988.906250] [G loss: -14058.011719]\n",
      "[Epoch 0/2] [Batch 173/782] [D loss: -103973.648438] [G loss: -15483.128906]\n",
      "[Epoch 0/2] [Batch 174/782] [D loss: -103733.375000] [G loss: -14356.444336]\n",
      "[Epoch 0/2] [Batch 175/782] [D loss: -105223.835938] [G loss: -15352.900391]\n",
      "[Epoch 0/2] [Batch 176/782] [D loss: -105261.781250] [G loss: -14619.953125]\n",
      "[Epoch 0/2] [Batch 177/782] [D loss: -106853.492188] [G loss: -15498.169922]\n",
      "[Epoch 0/2] [Batch 178/782] [D loss: -103831.093750] [G loss: -14068.900391]\n",
      "[Epoch 0/2] [Batch 179/782] [D loss: -104974.109375] [G loss: -15708.117188]\n",
      "[Epoch 0/2] [Batch 180/782] [D loss: -106009.859375] [G loss: -14421.641602]\n",
      "[Epoch 0/2] [Batch 181/782] [D loss: -104444.484375] [G loss: -15047.495117]\n",
      "[Epoch 0/2] [Batch 182/782] [D loss: -106164.750000] [G loss: -15241.283203]\n",
      "[Epoch 0/2] [Batch 183/782] [D loss: -103909.671875] [G loss: -14220.974609]\n",
      "[Epoch 0/2] [Batch 184/782] [D loss: -104517.023438] [G loss: -15652.432617]\n",
      "[Epoch 0/2] [Batch 185/782] [D loss: -105680.625000] [G loss: -14521.974609]\n",
      "[Epoch 0/2] [Batch 186/782] [D loss: -103725.171875] [G loss: -14903.163086]\n",
      "[Epoch 0/2] [Batch 187/782] [D loss: -104407.984375] [G loss: -15100.773438]\n",
      "[Epoch 0/2] [Batch 188/782] [D loss: -104137.335938] [G loss: -14617.833008]\n",
      "[Epoch 0/2] [Batch 189/782] [D loss: -105167.078125] [G loss: -15387.023438]\n",
      "[Epoch 0/2] [Batch 190/782] [D loss: -103908.898438] [G loss: -14306.236328]\n",
      "[Epoch 0/2] [Batch 191/782] [D loss: -104452.984375] [G loss: -15482.248047]\n",
      "[Epoch 0/2] [Batch 192/782] [D loss: -104276.515625] [G loss: -14440.878906]\n",
      "[Epoch 0/2] [Batch 193/782] [D loss: -105861.484375] [G loss: -15628.251953]\n",
      "[Epoch 0/2] [Batch 194/782] [D loss: -103378.226562] [G loss: -13980.984375]\n",
      "[Epoch 0/2] [Batch 195/782] [D loss: -105416.671875] [G loss: -16083.287109]\n",
      "[Epoch 0/2] [Batch 196/782] [D loss: -107776.859375] [G loss: -14464.230469]\n",
      "[Epoch 0/2] [Batch 197/782] [D loss: -106503.406250] [G loss: -15216.414062]\n",
      "[Epoch 0/2] [Batch 198/782] [D loss: -105199.359375] [G loss: -14656.185547]\n",
      "[Epoch 0/2] [Batch 199/782] [D loss: -103871.250000] [G loss: -14735.855469]\n",
      "[Epoch 0/2] [Batch 200/782] [D loss: -104321.250000] [G loss: -14990.889648]\n",
      "[Epoch 0/2] [Batch 201/782] [D loss: -104897.406250] [G loss: -14595.789062]\n",
      "[Epoch 0/2] [Batch 202/782] [D loss: -106060.578125] [G loss: -15134.321289]\n",
      "[Epoch 0/2] [Batch 203/782] [D loss: -105572.132812] [G loss: -14457.000000]\n",
      "[Epoch 0/2] [Batch 204/782] [D loss: -106637.359375] [G loss: -15346.184570]\n",
      "[Epoch 0/2] [Batch 205/782] [D loss: -102923.046875] [G loss: -13987.980469]\n",
      "[Epoch 0/2] [Batch 206/782] [D loss: -104700.406250] [G loss: -15960.158203]\n",
      "[Epoch 0/2] [Batch 207/782] [D loss: -104517.625000] [G loss: -13784.610352]\n",
      "[Epoch 0/2] [Batch 208/782] [D loss: -104067.312500] [G loss: -15629.894531]\n",
      "[Epoch 0/2] [Batch 209/782] [D loss: -103511.390625] [G loss: -14086.744141]\n",
      "[Epoch 0/2] [Batch 210/782] [D loss: -104196.523438] [G loss: -15384.776367]\n",
      "[Epoch 0/2] [Batch 211/782] [D loss: -104920.132812] [G loss: -14586.992188]\n",
      "[Epoch 0/2] [Batch 212/782] [D loss: -104358.757812] [G loss: -14912.392578]\n",
      "[Epoch 0/2] [Batch 213/782] [D loss: -105041.031250] [G loss: -15043.639648]\n",
      "[Epoch 0/2] [Batch 214/782] [D loss: -103484.734375] [G loss: -14419.939453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2] [Batch 215/782] [D loss: -104408.437500] [G loss: -15447.058594]\n",
      "[Epoch 0/2] [Batch 216/782] [D loss: -105750.265625] [G loss: -14609.261719]\n",
      "[Epoch 0/2] [Batch 217/782] [D loss: -104904.406250] [G loss: -14993.843750]\n",
      "[Epoch 0/2] [Batch 218/782] [D loss: -104094.921875] [G loss: -14690.384766]\n",
      "[Epoch 0/2] [Batch 219/782] [D loss: -107085.031250] [G loss: -15593.631836]\n",
      "[Epoch 0/2] [Batch 220/782] [D loss: -105142.750000] [G loss: -14119.686523]\n",
      "[Epoch 0/2] [Batch 221/782] [D loss: -103292.890625] [G loss: -15481.070312]\n",
      "[Epoch 0/2] [Batch 222/782] [D loss: -106182.765625] [G loss: -14916.398438]\n",
      "[Epoch 0/2] [Batch 223/782] [D loss: -104183.531250] [G loss: -14499.426758]\n",
      "[Epoch 0/2] [Batch 224/782] [D loss: -106385.828125] [G loss: -15711.740234]\n",
      "[Epoch 0/2] [Batch 225/782] [D loss: -107195.078125] [G loss: -14327.558594]\n",
      "[Epoch 0/2] [Batch 226/782] [D loss: -103183.328125] [G loss: -15040.777344]\n",
      "[Epoch 0/2] [Batch 227/782] [D loss: -106237.062500] [G loss: -15516.451172]\n",
      "[Epoch 0/2] [Batch 228/782] [D loss: -104159.531250] [G loss: -14047.910156]\n",
      "[Epoch 0/2] [Batch 229/782] [D loss: -104384.781250] [G loss: -15826.688477]\n",
      "[Epoch 0/2] [Batch 230/782] [D loss: -104104.312500] [G loss: -13881.105469]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3545bbb3d3e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlambda_gp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, nepochs, ncritics, sample_interval, save_interval, load_states, save_states, verbose, mlflow_run, lr, betas, lambda_gp)\u001b[0m\n\u001b[1;32m    242\u001b[0m                       \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                       \u001b[0mmlflow_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                       lr=lr, betas=betas, lambda_gp=lambda_gp)\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/gan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, nepochs, ncritics, sample_interval, save_interval, load_states, save_states, verbose, mlflow_run, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mbatches_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mreal_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/cosmikyu/cosmikyu/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstr_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:08}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmdb_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "WGAN_GP = gan.WGAN_GP(\"sehgal_wgan_gp\", shape, latent_dim, p_fliplabel=0.01, cuda=cuda, ngpu=4)\n",
    "mlflow.set_experiment(WGAN_GP.identifier)\n",
    "with mlflow.start_run(experiment_id=WGAN_GP.experiment.experiment_id) as mlflow_run:\n",
    "    torch.cuda.empty_cache()\n",
    "    WGAN_GP.train(\n",
    "        dataloader,\n",
    "        nepochs=nepochs,\n",
    "        ncritics=5,\n",
    "        sample_interval=sample_interval,\n",
    "        save_interval=save_interval,\n",
    "        load_states=True,\n",
    "        save_states=True,\n",
    "        verbose=True,\n",
    "        mlflow_run=mlflow_run,\n",
    "        lr=2e-04,\n",
    "        betas=(0.5, 0.999),\n",
    "        lambda_gp=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
